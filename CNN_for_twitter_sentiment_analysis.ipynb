{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOi3jEa95zKcfSk5Wjse15Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ceydab/Python-Practice-Applications/blob/main/CNN_for_twitter_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRS1kMNIsEXM",
        "outputId": "a852c3bc-c5a7-43bf-b373-46a2b074c936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tweeteval'...\n",
            "remote: Enumerating objects: 370, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 370 (delta 13), reused 3 (delta 1), pack-reused 354\u001b[K\n",
            "Receiving objects: 100% (370/370), 8.49 MiB | 12.06 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cardiffnlp/tweeteval.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.utils.data as data"
      ],
      "metadata": {
        "id": "4u3XVspUt1yq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "QFgaQ6Yb0JU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00612b96-9727-4ae7-e4b6-f7df279ec156"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create the dataframes\n",
        "\n",
        "\n",
        "label_mapping = {}\n",
        "with open(\"tweeteval/datasets/emotion/mapping.txt\", 'r') as file:\n",
        "    for line in file:\n",
        "        label, emotion = line.strip().split('\\t')\n",
        "        label_mapping[label] = emotion\n",
        "\n",
        "\n",
        "# Load and process your data\n",
        "def load_and_filter_data(text_file, label_file):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    with open(text_file, 'r') as file1, open(label_file, 'r') as file2:\n",
        "        while True:\n",
        "            text = file1.readline().strip()\n",
        "            label = file2.readline().strip()\n",
        "\n",
        "            if not text or not label:\n",
        "                break\n",
        "\n",
        "            emotion = label_mapping.get(label, label)  # Map label to emotion using the mapping\n",
        "            texts.append(text)\n",
        "            labels.append(emotion)\n",
        "\n",
        "    return texts, labels\n",
        "\n",
        "\n",
        "train_df = pd.DataFrame()\n",
        "val_df = pd.DataFrame()\n",
        "test_df = pd.DataFrame()\n",
        "train_df[\"text\"], train_df[\"label\"] = load_and_filter_data(\"tweeteval/datasets/emotion/train_text.txt\", \"tweeteval/datasets/emotion/train_labels.txt\")\n",
        "val_df[\"text\"], val_df[\"label\"] = load_and_filter_data(\"tweeteval/datasets/emotion/val_text.txt\", \"tweeteval/datasets/emotion/val_labels.txt\")\n",
        "test_df[\"text\"], test_df[\"label\"] = load_and_filter_data(\"tweeteval/datasets/emotion/test_text.txt\", \"tweeteval/datasets/emotion/test_labels.txt\")\n",
        "train_df.drop_duplicates(inplace=True)\n",
        "\n",
        "X_train, y_train = train_df[\"text\"], train_df[\"label\"]\n",
        "X_val, y_val= val_df[\"text\"], val_df[\"label\"]\n",
        "X_test, y_test = test_df[\"text\"], test_df[\"label\"]"
      ],
      "metadata": {
        "id": "8FbKXtz5wXzn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess imports\n",
        "import nltk\n",
        "import string\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import string\n"
      ],
      "metadata": {
        "id": "-ddL425WyQnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70b8c48-432f-4e28-e6e9-bbc07bffb4ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(tweet_text):\n",
        "    tweet_text = tweet_text.lower()\n",
        "    tokenizer = TweetTokenizer()\n",
        "    tokens = tokenizer.tokenize(tweet_text)\n",
        "  # Remove stopwords, punctuation, hashtags, mentions, URLs\n",
        "    tokens = [token for token in tokens if token not in stopwords.words('english') and token not in string.punctuation and not token.startswith(\"#\") and not token.startswith(\"@\") and not token.startswith(\"http\")]\n",
        "\n",
        "#emojis\n",
        "    tokens = [token for token in tokens if token.isalnum() or token.isascii()]\n",
        "\n",
        "    processed_tweet = ' '.join(tokens)\n",
        "    return processed_tweet\n",
        "\n",
        "\n",
        "X_train = X_train.apply(preprocessing)\n",
        "X_val = X_val.apply(preprocessing)\n",
        "X_test = X_test.apply(preprocessing)\n"
      ],
      "metadata": {
        "id": "gIlQcDBz0Tsy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize, vectorize, and tensor\n",
        "vocab = set(X_train)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ix_to_word = {i: word for i, word in enumerate(vocab)}\n",
        "\n",
        "word_to_ix['<unk>'] = len(word_to_ix)\n",
        "ix_to_word[len(word_to_ix)] = '<unk>'\n",
        "\n",
        "def tokenize_and_index(text, word_to_ix):\n",
        "    tokens = text.split()\n",
        "    indexed_tokens = [word_to_ix.get(token, word_to_ix['<unk>']) for token in tokens]\n",
        "    return indexed_tokens\n",
        "\n",
        "# Apply tokenization and indexing\n",
        "X_train_indices = [tokenize_and_index(text, word_to_ix) for text in X_train]\n",
        "X_val_indices = [tokenize_and_index(text, word_to_ix) for text in X_val]\n",
        "X_test_indices = [tokenize_and_index(text, word_to_ix) for text in X_test]\n",
        "\n",
        "\n",
        "\n",
        "X_train_tensor = [torch.LongTensor(indices) for indices in X_train_indices]\n",
        "X_val_tensor = [torch.LongTensor(indices) for indices in X_val_indices]\n",
        "X_test_tensor = [torch.LongTensor(indices) for indices in X_test_indices]\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "X_train_tensor = pad_sequence([torch.LongTensor(indices) for indices in X_train_indices], batch_first=True)\n",
        "X_val_tensor = pad_sequence([torch.LongTensor(indices) for indices in X_val_indices], batch_first=True)\n",
        "X_test_tensor = pad_sequence([torch.LongTensor(indices) for indices in X_test_indices], batch_first=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VT4VZXf1Me9i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt3CXbKH9Uv1",
        "outputId": "2bbd1f27-ac8c-438b-f744-0cd4d94695fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anger       1400\n",
            "sadness      855\n",
            "joy          683\n",
            "optimism     294\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# manual labeling and encoding\n",
        "label_mapping = {'anger': 0, 'sadness': 1, 'joy':2, 'optimism':3}\n",
        "\n",
        "y_train_encoded = [label_mapping[label] for label in y_train]\n",
        "y_val_encoded = [label_mapping[label] for label in y_val]\n",
        "y_test_encoded = [label_mapping[label] for label in y_test]\n",
        "\n",
        "y_train_tensor = torch.Tensor(y_train_encoded).long()\n",
        "y_val_tensor = torch.Tensor(y_val_encoded).long()\n",
        "y_test_tensor = torch.Tensor(y_test_encoded).long()"
      ],
      "metadata": {
        "id": "XVksWG769-1D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN structure\n",
        "\n",
        "class SentimentCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, filter_sizes, num_filters,  output_dim, dropout):\n",
        "        super(SentimentCNN, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=nf, kernel_size=(fs, embedding_dim))\n",
        "            for nf, fs in zip(num_filters, filter_sizes)\n",
        "        ])\n",
        "        self.fc = nn.Linear(len(filter_sizes)*num_filters[0], output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "\n",
        "        return self.fc(cat)\n",
        "\n"
      ],
      "metadata": {
        "id": "JzCPDJob0Y31"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "0NVAKWEG2Aqv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the best number of filters\n",
        "\n",
        "import itertools\n",
        "numbers = [3, 4, 5]\n",
        "num_filters = [[150, 150,150], [200,200,200], [250,250,250]]\n",
        "filter_sizes = [3,4,5]\n",
        "# Initialize variables to keep track of the best hyperparameters and metrics\n",
        "best_hyperparameters = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Perform grid search\n",
        "for filter_size, num_filter,  in itertools.product(filter_sizes, num_filters):\n",
        "    batch_size = 128\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    # Create a new model with the current hyperparameters\n",
        "    model = SentimentCNN(\n",
        "        vocab_size=len(word_to_ix),\n",
        "        embedding_dim=500,\n",
        "        filter_sizes=filter_size,\n",
        "        num_filters=num_filter,\n",
        "        output_dim=4,\n",
        "        dropout=0.2\n",
        "    )\n",
        "\n",
        "    # Define the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor([1.0, 2.0, 2.0, 6.0]))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    num_epochs = 10  # Adjust the number of epochs as needed\n",
        "\n",
        "    # Training loop (similar to your existing code)\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      model.train()\n",
        "      total_loss = 0.0\n",
        "\n",
        "      for batch in train_loader:\n",
        "          inputs, labels = batch\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      # Calculate and print the average loss for this epoch\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f}')\n",
        "\n",
        "      # Validation\n",
        "      model.eval() #removes dropout\n",
        "      val_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      all_predictions = []\n",
        "      with torch.no_grad():\n",
        "          for batch in val_loader:\n",
        "              inputs, labels = batch\n",
        "              outputs = model(inputs)\n",
        "              loss = criterion(outputs, labels)\n",
        "              val_loss += loss.item()\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "              all_predictions.extend(predicted.tolist())\n",
        "      val_accuracy = 100 * correct / total\n",
        "      val_loss /= len(val_loader)\n",
        "\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}] - Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "    # Calculate accuracy and F1-macro scores\n",
        "    accuracy = accuracy_score(y_val_encoded, all_predictions)\n",
        "\n",
        "    # Keep track of the best hyperparameters\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_hyperparameters = (num_filter, filter_size)\n",
        "\n",
        "# Print the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(\"Number of filters:\", best_hyperparameters[0])\n",
        "print(\"Filter size:\", best_hyperparameters[1])\n",
        "print(\"Best Accuracy:\", best_accuracy)"
      ],
      "metadata": {
        "id": "BSoxBUc0DIrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534e067b-4e5d-43c8-c131-9777846d7b7f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [1/10] - Train Loss: 1.8774\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [1/10] - Validation Loss: 1.3835, Accuracy: 15.78%\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [2/10] - Train Loss: 1.4057\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [2/10] - Validation Loss: 1.3700, Accuracy: 42.25%\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [3/10] - Train Loss: 1.3494\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [3/10] - Validation Loss: 1.3399, Accuracy: 25.67%\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [4/10] - Train Loss: 1.3178\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [4/10] - Validation Loss: 1.3434, Accuracy: 20.32%\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [5/10] - Train Loss: 1.2768\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [5/10] - Validation Loss: 1.3468, Accuracy: 21.66%\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [6/10] - Train Loss: 1.2650\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [6/10] - Validation Loss: 1.3063, Accuracy: 25.13%\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [7/10] - Train Loss: 1.2495\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [7/10] - Validation Loss: 1.3171, Accuracy: 21.66%\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [8/10] - Train Loss: 1.2560\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [8/10] - Validation Loss: 1.3368, Accuracy: 24.33%\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [9/10] - Train Loss: 1.2479\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [9/10] - Validation Loss: 1.3275, Accuracy: 41.71%\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([32, 450])\n",
            "Epoch [10/10] - Train Loss: 1.2454\n",
            "torch.Size([128, 450])\n",
            "torch.Size([128, 450])\n",
            "torch.Size([118, 450])\n",
            "Epoch [10/10] - Validation Loss: 1.3159, Accuracy: 22.19%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [1/10] - Train Loss: 1.9755\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [1/10] - Validation Loss: 1.6703, Accuracy: 23.80%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [2/10] - Train Loss: 1.4242\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [2/10] - Validation Loss: 1.3358, Accuracy: 29.14%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [3/10] - Train Loss: 1.3520\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [3/10] - Validation Loss: 1.3284, Accuracy: 22.73%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [4/10] - Train Loss: 1.3209\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [4/10] - Validation Loss: 1.3118, Accuracy: 28.88%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [5/10] - Train Loss: 1.2897\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [5/10] - Validation Loss: 1.3437, Accuracy: 22.73%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [6/10] - Train Loss: 1.2791\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [6/10] - Validation Loss: 1.3300, Accuracy: 21.12%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [7/10] - Train Loss: 1.2650\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [7/10] - Validation Loss: 1.3140, Accuracy: 23.80%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [8/10] - Train Loss: 1.2464\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [8/10] - Validation Loss: 1.2972, Accuracy: 25.13%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [9/10] - Train Loss: 1.2477\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [9/10] - Validation Loss: 1.2950, Accuracy: 29.14%\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([32, 600])\n",
            "Epoch [10/10] - Train Loss: 1.2297\n",
            "torch.Size([128, 600])\n",
            "torch.Size([128, 600])\n",
            "torch.Size([118, 600])\n",
            "Epoch [10/10] - Validation Loss: 1.3126, Accuracy: 24.87%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [1/10] - Train Loss: 2.1264\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [1/10] - Validation Loss: 1.4742, Accuracy: 44.39%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [2/10] - Train Loss: 1.4008\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [2/10] - Validation Loss: 1.3502, Accuracy: 40.64%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [3/10] - Train Loss: 1.3350\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [3/10] - Validation Loss: 1.3322, Accuracy: 24.06%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [4/10] - Train Loss: 1.3044\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [4/10] - Validation Loss: 1.3480, Accuracy: 45.99%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [5/10] - Train Loss: 1.2996\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [5/10] - Validation Loss: 1.3235, Accuracy: 41.71%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [6/10] - Train Loss: 1.2832\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [6/10] - Validation Loss: 1.3203, Accuracy: 28.34%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [7/10] - Train Loss: 1.2659\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [7/10] - Validation Loss: 1.3053, Accuracy: 27.54%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [8/10] - Train Loss: 1.2518\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [8/10] - Validation Loss: 1.3398, Accuracy: 20.59%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [9/10] - Train Loss: 1.2416\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [9/10] - Validation Loss: 1.3386, Accuracy: 18.98%\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([32, 750])\n",
            "Epoch [10/10] - Train Loss: 1.2390\n",
            "torch.Size([128, 750])\n",
            "torch.Size([128, 750])\n",
            "torch.Size([118, 750])\n",
            "Epoch [10/10] - Validation Loss: 1.3219, Accuracy: 22.73%\n",
            "Best Hyperparameters:\n",
            "Number of filters: [200, 200, 200]\n",
            "Filter size: [3, 4, 5]\n",
            "Best Accuracy: 0.24866310160427807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "#get the best filter size\n",
        "numbers = [3, 4, 5]\n",
        "filter_sizes = [list(combination) for combination in itertools.product(numbers, repeat=3)]\n",
        "# Initialize variables to keep track of the best hyperparameters and metrics\n",
        "best_hyperparameters = None\n",
        "best_accuracy = 0.0\n",
        "i =0\n",
        "# Perform grid search\n",
        "for filter_size, in itertools.product(filter_sizes):\n",
        "    batch_size = 128\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    # Create a new model with the current hyperparameters\n",
        "    model = SentimentCNN(\n",
        "        vocab_size=len(word_to_ix),\n",
        "        embedding_dim=500,\n",
        "        filter_sizes=filter_size,\n",
        "        num_filters=[200,200,200],\n",
        "        output_dim=4,\n",
        "        dropout=0.2\n",
        "    )\n",
        "\n",
        "    # Define the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor([1.0, 2.0, 2.0, 6.0]))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    num_epochs = 10  # Adjust the number of epochs as needed\n",
        "\n",
        "    # Training loop (similar to your existing code)\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      model.train()\n",
        "      total_loss = 0.0\n",
        "\n",
        "      for batch in train_loader:\n",
        "          inputs, labels = batch\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      # Calculate and print the average loss for this epoch\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f}')\n",
        "\n",
        "      # Validation\n",
        "      model.eval() #removes dropout\n",
        "      val_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      all_predictions = []\n",
        "      with torch.no_grad():\n",
        "          for batch in val_loader:\n",
        "              inputs, labels = batch\n",
        "              outputs = model(inputs)\n",
        "              loss = criterion(outputs, labels)\n",
        "              val_loss += loss.item()\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "              all_predictions.extend(predicted.tolist())\n",
        "      val_accuracy = 100 * correct / total\n",
        "      val_loss /= len(val_loader)\n",
        "\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}] - Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "    # Calculate accuracy and F1-macro scores\n",
        "    accuracy = accuracy_score(y_val_encoded, all_predictions)\n",
        "\n",
        "    # Keep track of the best hyperparameters\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_hyperparameters = (filter_size)\n",
        "    i+=1\n",
        "    print(i)\n",
        "# Print the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(\"Filter size:\", best_hyperparameters[0])\n",
        "print(\"Best Accuracy:\", best_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuCsPVaET5ST",
        "outputId": "469af541-bda3-4d18-8157-aa30c4d6ad49"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Train Loss: 1.9817\n",
            "Epoch [1/10] - Validation Loss: 1.4632, Accuracy: 11.23%\n",
            "Epoch [2/10] - Train Loss: 1.3843\n",
            "Epoch [2/10] - Validation Loss: 1.3827, Accuracy: 25.67%\n",
            "Epoch [3/10] - Train Loss: 1.3270\n",
            "Epoch [3/10] - Validation Loss: 1.3270, Accuracy: 22.46%\n",
            "Epoch [4/10] - Train Loss: 1.3061\n",
            "Epoch [4/10] - Validation Loss: 1.3102, Accuracy: 32.62%\n",
            "Epoch [5/10] - Train Loss: 1.2785\n",
            "Epoch [5/10] - Validation Loss: 1.3315, Accuracy: 20.86%\n",
            "Epoch [6/10] - Train Loss: 1.2693\n",
            "Epoch [6/10] - Validation Loss: 1.3126, Accuracy: 22.73%\n",
            "Epoch [7/10] - Train Loss: 1.2621\n",
            "Epoch [7/10] - Validation Loss: 1.3300, Accuracy: 28.07%\n",
            "Epoch [8/10] - Train Loss: 1.2523\n",
            "Epoch [8/10] - Validation Loss: 1.3353, Accuracy: 28.88%\n",
            "Epoch [9/10] - Train Loss: 1.2575\n",
            "Epoch [9/10] - Validation Loss: 1.3361, Accuracy: 28.34%\n",
            "Epoch [10/10] - Train Loss: 1.2378\n",
            "Epoch [10/10] - Validation Loss: 1.3163, Accuracy: 25.94%\n",
            "1\n",
            "Epoch [1/10] - Train Loss: 2.0656\n",
            "Epoch [1/10] - Validation Loss: 1.3619, Accuracy: 18.18%\n",
            "Epoch [2/10] - Train Loss: 1.3897\n",
            "Epoch [2/10] - Validation Loss: 1.3866, Accuracy: 16.84%\n",
            "Epoch [3/10] - Train Loss: 1.3439\n",
            "Epoch [3/10] - Validation Loss: 1.3246, Accuracy: 27.81%\n",
            "Epoch [4/10] - Train Loss: 1.3045\n",
            "Epoch [4/10] - Validation Loss: 1.3080, Accuracy: 27.81%\n",
            "Epoch [5/10] - Train Loss: 1.2938\n",
            "Epoch [5/10] - Validation Loss: 1.3087, Accuracy: 24.87%\n",
            "Epoch [6/10] - Train Loss: 1.2671\n",
            "Epoch [6/10] - Validation Loss: 1.3080, Accuracy: 29.68%\n",
            "Epoch [7/10] - Train Loss: 1.2573\n",
            "Epoch [7/10] - Validation Loss: 1.2979, Accuracy: 31.55%\n",
            "Epoch [8/10] - Train Loss: 1.2436\n",
            "Epoch [8/10] - Validation Loss: 1.3137, Accuracy: 28.61%\n",
            "Epoch [9/10] - Train Loss: 1.2589\n",
            "Epoch [9/10] - Validation Loss: 1.3101, Accuracy: 26.20%\n",
            "Epoch [10/10] - Train Loss: 1.2501\n",
            "Epoch [10/10] - Validation Loss: 1.3038, Accuracy: 29.95%\n",
            "2\n",
            "Epoch [1/10] - Train Loss: 1.9694\n",
            "Epoch [1/10] - Validation Loss: 1.4468, Accuracy: 22.73%\n",
            "Epoch [2/10] - Train Loss: 1.3596\n",
            "Epoch [2/10] - Validation Loss: 1.3478, Accuracy: 45.19%\n",
            "Epoch [3/10] - Train Loss: 1.3389\n",
            "Epoch [3/10] - Validation Loss: 1.3599, Accuracy: 20.59%\n",
            "Epoch [4/10] - Train Loss: 1.2989\n",
            "Epoch [4/10] - Validation Loss: 1.3151, Accuracy: 28.61%\n",
            "Epoch [5/10] - Train Loss: 1.2785\n",
            "Epoch [5/10] - Validation Loss: 1.2995, Accuracy: 43.85%\n",
            "Epoch [6/10] - Train Loss: 1.2726\n",
            "Epoch [6/10] - Validation Loss: 1.3226, Accuracy: 28.88%\n",
            "Epoch [7/10] - Train Loss: 1.2478\n",
            "Epoch [7/10] - Validation Loss: 1.2995, Accuracy: 24.60%\n",
            "Epoch [8/10] - Train Loss: 1.2419\n",
            "Epoch [8/10] - Validation Loss: 1.3014, Accuracy: 25.67%\n",
            "Epoch [9/10] - Train Loss: 1.2336\n",
            "Epoch [9/10] - Validation Loss: 1.3348, Accuracy: 32.89%\n",
            "Epoch [10/10] - Train Loss: 1.2450\n",
            "Epoch [10/10] - Validation Loss: 1.3031, Accuracy: 27.54%\n",
            "3\n",
            "Epoch [1/10] - Train Loss: 1.9773\n",
            "Epoch [1/10] - Validation Loss: 1.5473, Accuracy: 24.06%\n",
            "Epoch [2/10] - Train Loss: 1.3943\n",
            "Epoch [2/10] - Validation Loss: 1.3758, Accuracy: 27.01%\n",
            "Epoch [3/10] - Train Loss: 1.3624\n",
            "Epoch [3/10] - Validation Loss: 1.3837, Accuracy: 18.18%\n",
            "Epoch [4/10] - Train Loss: 1.3112\n",
            "Epoch [4/10] - Validation Loss: 1.3006, Accuracy: 27.81%\n",
            "Epoch [5/10] - Train Loss: 1.2686\n",
            "Epoch [5/10] - Validation Loss: 1.3342, Accuracy: 21.66%\n",
            "Epoch [6/10] - Train Loss: 1.2650\n",
            "Epoch [6/10] - Validation Loss: 1.2916, Accuracy: 25.40%\n",
            "Epoch [7/10] - Train Loss: 1.2459\n",
            "Epoch [7/10] - Validation Loss: 1.3085, Accuracy: 44.65%\n",
            "Epoch [8/10] - Train Loss: 1.2530\n",
            "Epoch [8/10] - Validation Loss: 1.2933, Accuracy: 47.06%\n",
            "Epoch [9/10] - Train Loss: 1.2374\n",
            "Epoch [9/10] - Validation Loss: 1.3006, Accuracy: 30.75%\n",
            "Epoch [10/10] - Train Loss: 1.2309\n",
            "Epoch [10/10] - Validation Loss: 1.3089, Accuracy: 27.01%\n",
            "4\n",
            "Epoch [1/10] - Train Loss: 2.1581\n",
            "Epoch [1/10] - Validation Loss: 1.4988, Accuracy: 17.11%\n",
            "Epoch [2/10] - Train Loss: 1.4105\n",
            "Epoch [2/10] - Validation Loss: 1.3448, Accuracy: 25.67%\n",
            "Epoch [3/10] - Train Loss: 1.3405\n",
            "Epoch [3/10] - Validation Loss: 1.3578, Accuracy: 19.52%\n",
            "Epoch [4/10] - Train Loss: 1.3157\n",
            "Epoch [4/10] - Validation Loss: 1.3335, Accuracy: 22.19%\n",
            "Epoch [5/10] - Train Loss: 1.2876\n",
            "Epoch [5/10] - Validation Loss: 1.3562, Accuracy: 48.13%\n",
            "Epoch [6/10] - Train Loss: 1.2900\n",
            "Epoch [6/10] - Validation Loss: 1.3137, Accuracy: 23.53%\n",
            "Epoch [7/10] - Train Loss: 1.2608\n",
            "Epoch [7/10] - Validation Loss: 1.3410, Accuracy: 27.54%\n",
            "Epoch [8/10] - Train Loss: 1.2571\n",
            "Epoch [8/10] - Validation Loss: 1.3687, Accuracy: 20.32%\n",
            "Epoch [9/10] - Train Loss: 1.2567\n",
            "Epoch [9/10] - Validation Loss: 1.3108, Accuracy: 23.53%\n",
            "Epoch [10/10] - Train Loss: 1.2425\n",
            "Epoch [10/10] - Validation Loss: 1.3117, Accuracy: 21.66%\n",
            "5\n",
            "Epoch [1/10] - Train Loss: 1.9829\n",
            "Epoch [1/10] - Validation Loss: 1.3785, Accuracy: 46.26%\n",
            "Epoch [2/10] - Train Loss: 1.4184\n",
            "Epoch [2/10] - Validation Loss: 1.4097, Accuracy: 41.44%\n",
            "Epoch [3/10] - Train Loss: 1.3351\n",
            "Epoch [3/10] - Validation Loss: 1.3389, Accuracy: 47.06%\n",
            "Epoch [4/10] - Train Loss: 1.3058\n",
            "Epoch [4/10] - Validation Loss: 1.3745, Accuracy: 42.51%\n",
            "Epoch [5/10] - Train Loss: 1.2939\n",
            "Epoch [5/10] - Validation Loss: 1.3283, Accuracy: 22.46%\n",
            "Epoch [6/10] - Train Loss: 1.2873\n",
            "Epoch [6/10] - Validation Loss: 1.3425, Accuracy: 22.99%\n",
            "Epoch [7/10] - Train Loss: 1.2654\n",
            "Epoch [7/10] - Validation Loss: 1.3501, Accuracy: 21.12%\n",
            "Epoch [8/10] - Train Loss: 1.2684\n",
            "Epoch [8/10] - Validation Loss: 1.3421, Accuracy: 21.12%\n",
            "Epoch [9/10] - Train Loss: 1.2477\n",
            "Epoch [9/10] - Validation Loss: 1.3477, Accuracy: 27.54%\n",
            "Epoch [10/10] - Train Loss: 1.2411\n",
            "Epoch [10/10] - Validation Loss: 1.3194, Accuracy: 24.33%\n",
            "6\n",
            "Epoch [1/10] - Train Loss: 1.9784\n",
            "Epoch [1/10] - Validation Loss: 1.3637, Accuracy: 17.11%\n",
            "Epoch [2/10] - Train Loss: 1.3772\n",
            "Epoch [2/10] - Validation Loss: 1.3452, Accuracy: 32.09%\n",
            "Epoch [3/10] - Train Loss: 1.3446\n",
            "Epoch [3/10] - Validation Loss: 1.3302, Accuracy: 22.73%\n",
            "Epoch [4/10] - Train Loss: 1.3164\n",
            "Epoch [4/10] - Validation Loss: 1.3149, Accuracy: 48.66%\n",
            "Epoch [5/10] - Train Loss: 1.2771\n",
            "Epoch [5/10] - Validation Loss: 1.3094, Accuracy: 42.78%\n",
            "Epoch [6/10] - Train Loss: 1.2720\n",
            "Epoch [6/10] - Validation Loss: 1.3293, Accuracy: 30.48%\n",
            "Epoch [7/10] - Train Loss: 1.2742\n",
            "Epoch [7/10] - Validation Loss: 1.2996, Accuracy: 29.95%\n",
            "Epoch [8/10] - Train Loss: 1.2590\n",
            "Epoch [8/10] - Validation Loss: 1.3007, Accuracy: 23.80%\n",
            "Epoch [9/10] - Train Loss: 1.2407\n",
            "Epoch [9/10] - Validation Loss: 1.2983, Accuracy: 33.16%\n",
            "Epoch [10/10] - Train Loss: 1.2307\n",
            "Epoch [10/10] - Validation Loss: 1.3357, Accuracy: 22.46%\n",
            "7\n",
            "Epoch [1/10] - Train Loss: 2.1983\n",
            "Epoch [1/10] - Validation Loss: 1.5403, Accuracy: 14.17%\n",
            "Epoch [2/10] - Train Loss: 1.4048\n",
            "Epoch [2/10] - Validation Loss: 1.3836, Accuracy: 45.99%\n",
            "Epoch [3/10] - Train Loss: 1.3468\n",
            "Epoch [3/10] - Validation Loss: 1.3517, Accuracy: 22.19%\n",
            "Epoch [4/10] - Train Loss: 1.3150\n",
            "Epoch [4/10] - Validation Loss: 1.3406, Accuracy: 25.67%\n",
            "Epoch [5/10] - Train Loss: 1.2969\n",
            "Epoch [5/10] - Validation Loss: 1.3266, Accuracy: 31.28%\n",
            "Epoch [6/10] - Train Loss: 1.2734\n",
            "Epoch [6/10] - Validation Loss: 1.3551, Accuracy: 20.86%\n",
            "Epoch [7/10] - Train Loss: 1.2789\n",
            "Epoch [7/10] - Validation Loss: 1.3270, Accuracy: 48.66%\n",
            "Epoch [8/10] - Train Loss: 1.2543\n",
            "Epoch [8/10] - Validation Loss: 1.3400, Accuracy: 26.74%\n",
            "Epoch [9/10] - Train Loss: 1.2454\n",
            "Epoch [9/10] - Validation Loss: 1.3042, Accuracy: 27.01%\n",
            "Epoch [10/10] - Train Loss: 1.2473\n",
            "Epoch [10/10] - Validation Loss: 1.3006, Accuracy: 26.47%\n",
            "8\n",
            "Epoch [1/10] - Train Loss: 2.0517\n",
            "Epoch [1/10] - Validation Loss: 1.4334, Accuracy: 10.96%\n",
            "Epoch [2/10] - Train Loss: 1.4005\n",
            "Epoch [2/10] - Validation Loss: 1.3505, Accuracy: 22.19%\n",
            "Epoch [3/10] - Train Loss: 1.3419\n",
            "Epoch [3/10] - Validation Loss: 1.4022, Accuracy: 24.60%\n",
            "Epoch [4/10] - Train Loss: 1.3246\n",
            "Epoch [4/10] - Validation Loss: 1.3334, Accuracy: 22.46%\n",
            "Epoch [5/10] - Train Loss: 1.2990\n",
            "Epoch [5/10] - Validation Loss: 1.3125, Accuracy: 25.94%\n",
            "Epoch [6/10] - Train Loss: 1.2758\n",
            "Epoch [6/10] - Validation Loss: 1.3126, Accuracy: 26.47%\n",
            "Epoch [7/10] - Train Loss: 1.2738\n",
            "Epoch [7/10] - Validation Loss: 1.3083, Accuracy: 28.07%\n",
            "Epoch [8/10] - Train Loss: 1.2515\n",
            "Epoch [8/10] - Validation Loss: 1.3253, Accuracy: 24.06%\n",
            "Epoch [9/10] - Train Loss: 1.2477\n",
            "Epoch [9/10] - Validation Loss: 1.3124, Accuracy: 24.33%\n",
            "Epoch [10/10] - Train Loss: 1.2421\n",
            "Epoch [10/10] - Validation Loss: 1.2945, Accuracy: 23.80%\n",
            "9\n",
            "Epoch [1/10] - Train Loss: 1.9532\n",
            "Epoch [1/10] - Validation Loss: 1.3780, Accuracy: 25.67%\n",
            "Epoch [2/10] - Train Loss: 1.3781\n",
            "Epoch [2/10] - Validation Loss: 1.3472, Accuracy: 19.79%\n",
            "Epoch [3/10] - Train Loss: 1.3361\n",
            "Epoch [3/10] - Validation Loss: 1.3204, Accuracy: 21.93%\n",
            "Epoch [4/10] - Train Loss: 1.3084\n",
            "Epoch [4/10] - Validation Loss: 1.3519, Accuracy: 21.93%\n",
            "Epoch [5/10] - Train Loss: 1.2937\n",
            "Epoch [5/10] - Validation Loss: 1.3067, Accuracy: 22.73%\n",
            "Epoch [6/10] - Train Loss: 1.2629\n",
            "Epoch [6/10] - Validation Loss: 1.3415, Accuracy: 28.07%\n",
            "Epoch [7/10] - Train Loss: 1.2743\n",
            "Epoch [7/10] - Validation Loss: 1.3176, Accuracy: 26.20%\n",
            "Epoch [8/10] - Train Loss: 1.2435\n",
            "Epoch [8/10] - Validation Loss: 1.3135, Accuracy: 26.20%\n",
            "Epoch [9/10] - Train Loss: 1.2417\n",
            "Epoch [9/10] - Validation Loss: 1.3250, Accuracy: 23.80%\n",
            "Epoch [10/10] - Train Loss: 1.2382\n",
            "Epoch [10/10] - Validation Loss: 1.2993, Accuracy: 24.33%\n",
            "10\n",
            "Epoch [1/10] - Train Loss: 2.0161\n",
            "Epoch [1/10] - Validation Loss: 1.6912, Accuracy: 12.03%\n",
            "Epoch [2/10] - Train Loss: 1.4588\n",
            "Epoch [2/10] - Validation Loss: 1.3595, Accuracy: 18.72%\n",
            "Epoch [3/10] - Train Loss: 1.3421\n",
            "Epoch [3/10] - Validation Loss: 1.3543, Accuracy: 18.45%\n",
            "Epoch [4/10] - Train Loss: 1.3333\n",
            "Epoch [4/10] - Validation Loss: 1.3283, Accuracy: 23.53%\n",
            "Epoch [5/10] - Train Loss: 1.2753\n",
            "Epoch [5/10] - Validation Loss: 1.3731, Accuracy: 22.46%\n",
            "Epoch [6/10] - Train Loss: 1.2906\n",
            "Epoch [6/10] - Validation Loss: 1.3390, Accuracy: 20.86%\n",
            "Epoch [7/10] - Train Loss: 1.2594\n",
            "Epoch [7/10] - Validation Loss: 1.3654, Accuracy: 19.79%\n",
            "Epoch [8/10] - Train Loss: 1.2588\n",
            "Epoch [8/10] - Validation Loss: 1.3334, Accuracy: 22.46%\n",
            "Epoch [9/10] - Train Loss: 1.2549\n",
            "Epoch [9/10] - Validation Loss: 1.2968, Accuracy: 34.22%\n",
            "Epoch [10/10] - Train Loss: 1.2361\n",
            "Epoch [10/10] - Validation Loss: 1.3188, Accuracy: 21.39%\n",
            "11\n",
            "Epoch [1/10] - Train Loss: 2.1658\n",
            "Epoch [1/10] - Validation Loss: 1.6722, Accuracy: 23.80%\n",
            "Epoch [2/10] - Train Loss: 1.4594\n",
            "Epoch [2/10] - Validation Loss: 1.3533, Accuracy: 19.52%\n",
            "Epoch [3/10] - Train Loss: 1.3729\n",
            "Epoch [3/10] - Validation Loss: 1.3327, Accuracy: 32.09%\n",
            "Epoch [4/10] - Train Loss: 1.3414\n",
            "Epoch [4/10] - Validation Loss: 1.3397, Accuracy: 41.71%\n",
            "Epoch [5/10] - Train Loss: 1.3082\n",
            "Epoch [5/10] - Validation Loss: 1.3597, Accuracy: 21.12%\n",
            "Epoch [6/10] - Train Loss: 1.2780\n",
            "Epoch [6/10] - Validation Loss: 1.3173, Accuracy: 28.07%\n",
            "Epoch [7/10] - Train Loss: 1.2707\n",
            "Epoch [7/10] - Validation Loss: 1.3119, Accuracy: 24.87%\n",
            "Epoch [8/10] - Train Loss: 1.2571\n",
            "Epoch [8/10] - Validation Loss: 1.3003, Accuracy: 24.33%\n",
            "Epoch [9/10] - Train Loss: 1.2510\n",
            "Epoch [9/10] - Validation Loss: 1.3198, Accuracy: 21.39%\n",
            "Epoch [10/10] - Train Loss: 1.2462\n",
            "Epoch [10/10] - Validation Loss: 1.2988, Accuracy: 25.13%\n",
            "12\n",
            "Epoch [1/10] - Train Loss: 2.0446\n",
            "Epoch [1/10] - Validation Loss: 1.4244, Accuracy: 16.84%\n",
            "Epoch [2/10] - Train Loss: 1.4116\n",
            "Epoch [2/10] - Validation Loss: 1.3889, Accuracy: 21.12%\n",
            "Epoch [3/10] - Train Loss: 1.3470\n",
            "Epoch [3/10] - Validation Loss: 1.3801, Accuracy: 25.94%\n",
            "Epoch [4/10] - Train Loss: 1.3384\n",
            "Epoch [4/10] - Validation Loss: 1.3546, Accuracy: 31.02%\n",
            "Epoch [5/10] - Train Loss: 1.3004\n",
            "Epoch [5/10] - Validation Loss: 1.3734, Accuracy: 21.12%\n",
            "Epoch [6/10] - Train Loss: 1.2929\n",
            "Epoch [6/10] - Validation Loss: 1.3248, Accuracy: 22.73%\n",
            "Epoch [7/10] - Train Loss: 1.2635\n",
            "Epoch [7/10] - Validation Loss: 1.3076, Accuracy: 26.74%\n",
            "Epoch [8/10] - Train Loss: 1.2639\n",
            "Epoch [8/10] - Validation Loss: 1.3000, Accuracy: 32.09%\n",
            "Epoch [9/10] - Train Loss: 1.2365\n",
            "Epoch [9/10] - Validation Loss: 1.3122, Accuracy: 28.88%\n",
            "Epoch [10/10] - Train Loss: 1.2398\n",
            "Epoch [10/10] - Validation Loss: 1.3122, Accuracy: 33.42%\n",
            "13\n",
            "Epoch [1/10] - Train Loss: 2.0046\n",
            "Epoch [1/10] - Validation Loss: 1.4415, Accuracy: 11.76%\n",
            "Epoch [2/10] - Train Loss: 1.4108\n",
            "Epoch [2/10] - Validation Loss: 1.4494, Accuracy: 21.66%\n",
            "Epoch [3/10] - Train Loss: 1.3491\n",
            "Epoch [3/10] - Validation Loss: 1.3930, Accuracy: 23.53%\n",
            "Epoch [4/10] - Train Loss: 1.3234\n",
            "Epoch [4/10] - Validation Loss: 1.4334, Accuracy: 17.65%\n",
            "Epoch [5/10] - Train Loss: 1.3237\n",
            "Epoch [5/10] - Validation Loss: 1.4079, Accuracy: 16.84%\n",
            "Epoch [6/10] - Train Loss: 1.2825\n",
            "Epoch [6/10] - Validation Loss: 1.3092, Accuracy: 23.80%\n",
            "Epoch [7/10] - Train Loss: 1.2722\n",
            "Epoch [7/10] - Validation Loss: 1.3205, Accuracy: 29.14%\n",
            "Epoch [8/10] - Train Loss: 1.2554\n",
            "Epoch [8/10] - Validation Loss: 1.3185, Accuracy: 29.95%\n",
            "Epoch [9/10] - Train Loss: 1.2614\n",
            "Epoch [9/10] - Validation Loss: 1.3199, Accuracy: 29.68%\n",
            "Epoch [10/10] - Train Loss: 1.2559\n",
            "Epoch [10/10] - Validation Loss: 1.3175, Accuracy: 28.88%\n",
            "14\n",
            "Epoch [1/10] - Train Loss: 2.2413\n",
            "Epoch [1/10] - Validation Loss: 1.3765, Accuracy: 25.13%\n",
            "Epoch [2/10] - Train Loss: 1.4310\n",
            "Epoch [2/10] - Validation Loss: 1.3891, Accuracy: 26.20%\n",
            "Epoch [3/10] - Train Loss: 1.3604\n",
            "Epoch [3/10] - Validation Loss: 1.3378, Accuracy: 27.27%\n",
            "Epoch [4/10] - Train Loss: 1.3347\n",
            "Epoch [4/10] - Validation Loss: 1.3265, Accuracy: 48.40%\n",
            "Epoch [5/10] - Train Loss: 1.2949\n",
            "Epoch [5/10] - Validation Loss: 1.3380, Accuracy: 22.19%\n",
            "Epoch [6/10] - Train Loss: 1.2854\n",
            "Epoch [6/10] - Validation Loss: 1.3059, Accuracy: 24.06%\n",
            "Epoch [7/10] - Train Loss: 1.2752\n",
            "Epoch [7/10] - Validation Loss: 1.2982, Accuracy: 28.34%\n",
            "Epoch [8/10] - Train Loss: 1.2656\n",
            "Epoch [8/10] - Validation Loss: 1.2904, Accuracy: 25.13%\n",
            "Epoch [9/10] - Train Loss: 1.2489\n",
            "Epoch [9/10] - Validation Loss: 1.3131, Accuracy: 26.47%\n",
            "Epoch [10/10] - Train Loss: 1.2451\n",
            "Epoch [10/10] - Validation Loss: 1.2967, Accuracy: 28.61%\n",
            "15\n",
            "Epoch [1/10] - Train Loss: 2.3058\n",
            "Epoch [1/10] - Validation Loss: 1.4573, Accuracy: 41.98%\n",
            "Epoch [2/10] - Train Loss: 1.4132\n",
            "Epoch [2/10] - Validation Loss: 1.3985, Accuracy: 24.60%\n",
            "Epoch [3/10] - Train Loss: 1.3657\n",
            "Epoch [3/10] - Validation Loss: 1.3657, Accuracy: 16.04%\n",
            "Epoch [4/10] - Train Loss: 1.3342\n",
            "Epoch [4/10] - Validation Loss: 1.3025, Accuracy: 24.60%\n",
            "Epoch [5/10] - Train Loss: 1.2904\n",
            "Epoch [5/10] - Validation Loss: 1.3901, Accuracy: 46.26%\n",
            "Epoch [6/10] - Train Loss: 1.2819\n",
            "Epoch [6/10] - Validation Loss: 1.3049, Accuracy: 28.61%\n",
            "Epoch [7/10] - Train Loss: 1.2656\n",
            "Epoch [7/10] - Validation Loss: 1.3075, Accuracy: 26.74%\n",
            "Epoch [8/10] - Train Loss: 1.2524\n",
            "Epoch [8/10] - Validation Loss: 1.2946, Accuracy: 44.92%\n",
            "Epoch [9/10] - Train Loss: 1.2495\n",
            "Epoch [9/10] - Validation Loss: 1.2888, Accuracy: 28.07%\n",
            "Epoch [10/10] - Train Loss: 1.2516\n",
            "Epoch [10/10] - Validation Loss: 1.2990, Accuracy: 21.66%\n",
            "16\n",
            "Epoch [1/10] - Train Loss: 2.1294\n",
            "Epoch [1/10] - Validation Loss: 1.4475, Accuracy: 15.24%\n",
            "Epoch [2/10] - Train Loss: 1.3847\n",
            "Epoch [2/10] - Validation Loss: 1.4151, Accuracy: 23.80%\n",
            "Epoch [3/10] - Train Loss: 1.3592\n",
            "Epoch [3/10] - Validation Loss: 1.3695, Accuracy: 30.48%\n",
            "Epoch [4/10] - Train Loss: 1.3357\n",
            "Epoch [4/10] - Validation Loss: 1.3485, Accuracy: 21.12%\n",
            "Epoch [5/10] - Train Loss: 1.3194\n",
            "Epoch [5/10] - Validation Loss: 1.3320, Accuracy: 29.14%\n",
            "Epoch [6/10] - Train Loss: 1.3006\n",
            "Epoch [6/10] - Validation Loss: 1.3194, Accuracy: 24.33%\n",
            "Epoch [7/10] - Train Loss: 1.2875\n",
            "Epoch [7/10] - Validation Loss: 1.3383, Accuracy: 29.95%\n",
            "Epoch [8/10] - Train Loss: 1.2780\n",
            "Epoch [8/10] - Validation Loss: 1.3389, Accuracy: 26.47%\n",
            "Epoch [9/10] - Train Loss: 1.2651\n",
            "Epoch [9/10] - Validation Loss: 1.3385, Accuracy: 21.66%\n",
            "Epoch [10/10] - Train Loss: 1.2520\n",
            "Epoch [10/10] - Validation Loss: 1.3310, Accuracy: 25.40%\n",
            "17\n",
            "Epoch [1/10] - Train Loss: 2.2262\n",
            "Epoch [1/10] - Validation Loss: 1.5275, Accuracy: 23.80%\n",
            "Epoch [2/10] - Train Loss: 1.4410\n",
            "Epoch [2/10] - Validation Loss: 1.3715, Accuracy: 45.19%\n",
            "Epoch [3/10] - Train Loss: 1.3736\n",
            "Epoch [3/10] - Validation Loss: 1.3509, Accuracy: 30.75%\n",
            "Epoch [4/10] - Train Loss: 1.3497\n",
            "Epoch [4/10] - Validation Loss: 1.3807, Accuracy: 17.91%\n",
            "Epoch [5/10] - Train Loss: 1.3206\n",
            "Epoch [5/10] - Validation Loss: 1.3543, Accuracy: 27.01%\n",
            "Epoch [6/10] - Train Loss: 1.3005\n",
            "Epoch [6/10] - Validation Loss: 1.3672, Accuracy: 19.25%\n",
            "Epoch [7/10] - Train Loss: 1.3005\n",
            "Epoch [7/10] - Validation Loss: 1.3359, Accuracy: 22.99%\n",
            "Epoch [8/10] - Train Loss: 1.2755\n",
            "Epoch [8/10] - Validation Loss: 1.3129, Accuracy: 24.60%\n",
            "Epoch [9/10] - Train Loss: 1.2677\n",
            "Epoch [9/10] - Validation Loss: 1.3029, Accuracy: 24.06%\n",
            "Epoch [10/10] - Train Loss: 1.2590\n",
            "Epoch [10/10] - Validation Loss: 1.2975, Accuracy: 23.53%\n",
            "18\n",
            "Epoch [1/10] - Train Loss: 1.9216\n",
            "Epoch [1/10] - Validation Loss: 1.3805, Accuracy: 14.17%\n",
            "Epoch [2/10] - Train Loss: 1.3702\n",
            "Epoch [2/10] - Validation Loss: 1.3448, Accuracy: 25.67%\n",
            "Epoch [3/10] - Train Loss: 1.3202\n",
            "Epoch [3/10] - Validation Loss: 1.3402, Accuracy: 21.39%\n",
            "Epoch [4/10] - Train Loss: 1.3020\n",
            "Epoch [4/10] - Validation Loss: 1.2988, Accuracy: 33.96%\n",
            "Epoch [5/10] - Train Loss: 1.2816\n",
            "Epoch [5/10] - Validation Loss: 1.3205, Accuracy: 39.84%\n",
            "Epoch [6/10] - Train Loss: 1.2590\n",
            "Epoch [6/10] - Validation Loss: 1.3195, Accuracy: 23.53%\n",
            "Epoch [7/10] - Train Loss: 1.2582\n",
            "Epoch [7/10] - Validation Loss: 1.2978, Accuracy: 24.33%\n",
            "Epoch [8/10] - Train Loss: 1.2443\n",
            "Epoch [8/10] - Validation Loss: 1.3332, Accuracy: 46.79%\n",
            "Epoch [9/10] - Train Loss: 1.2491\n",
            "Epoch [9/10] - Validation Loss: 1.3018, Accuracy: 42.78%\n",
            "Epoch [10/10] - Train Loss: 1.2262\n",
            "Epoch [10/10] - Validation Loss: 1.3185, Accuracy: 27.27%\n",
            "19\n",
            "Epoch [1/10] - Train Loss: 1.9562\n",
            "Epoch [1/10] - Validation Loss: 1.3666, Accuracy: 25.94%\n",
            "Epoch [2/10] - Train Loss: 1.3731\n",
            "Epoch [2/10] - Validation Loss: 1.3605, Accuracy: 18.18%\n",
            "Epoch [3/10] - Train Loss: 1.3465\n",
            "Epoch [3/10] - Validation Loss: 1.3605, Accuracy: 41.44%\n",
            "Epoch [4/10] - Train Loss: 1.3227\n",
            "Epoch [4/10] - Validation Loss: 1.3472, Accuracy: 20.59%\n",
            "Epoch [5/10] - Train Loss: 1.2889\n",
            "Epoch [5/10] - Validation Loss: 1.3176, Accuracy: 25.40%\n",
            "Epoch [6/10] - Train Loss: 1.2668\n",
            "Epoch [6/10] - Validation Loss: 1.2911, Accuracy: 28.07%\n",
            "Epoch [7/10] - Train Loss: 1.2626\n",
            "Epoch [7/10] - Validation Loss: 1.3000, Accuracy: 26.20%\n",
            "Epoch [8/10] - Train Loss: 1.2653\n",
            "Epoch [8/10] - Validation Loss: 1.3407, Accuracy: 44.12%\n",
            "Epoch [9/10] - Train Loss: 1.2533\n",
            "Epoch [9/10] - Validation Loss: 1.3798, Accuracy: 18.18%\n",
            "Epoch [10/10] - Train Loss: 1.2384\n",
            "Epoch [10/10] - Validation Loss: 1.3189, Accuracy: 26.20%\n",
            "20\n",
            "Epoch [1/10] - Train Loss: 2.3384\n",
            "Epoch [1/10] - Validation Loss: 1.4948, Accuracy: 43.32%\n",
            "Epoch [2/10] - Train Loss: 1.4299\n",
            "Epoch [2/10] - Validation Loss: 1.3521, Accuracy: 21.12%\n",
            "Epoch [3/10] - Train Loss: 1.3849\n",
            "Epoch [3/10] - Validation Loss: 1.3353, Accuracy: 23.53%\n",
            "Epoch [4/10] - Train Loss: 1.3219\n",
            "Epoch [4/10] - Validation Loss: 1.3803, Accuracy: 17.11%\n",
            "Epoch [5/10] - Train Loss: 1.3067\n",
            "Epoch [5/10] - Validation Loss: 1.3210, Accuracy: 24.60%\n",
            "Epoch [6/10] - Train Loss: 1.2831\n",
            "Epoch [6/10] - Validation Loss: 1.3389, Accuracy: 46.52%\n",
            "Epoch [7/10] - Train Loss: 1.2747\n",
            "Epoch [7/10] - Validation Loss: 1.3160, Accuracy: 30.75%\n",
            "Epoch [8/10] - Train Loss: 1.2595\n",
            "Epoch [8/10] - Validation Loss: 1.3288, Accuracy: 28.34%\n",
            "Epoch [9/10] - Train Loss: 1.2491\n",
            "Epoch [9/10] - Validation Loss: 1.3255, Accuracy: 29.14%\n",
            "Epoch [10/10] - Train Loss: 1.2426\n",
            "Epoch [10/10] - Validation Loss: 1.3017, Accuracy: 28.61%\n",
            "21\n",
            "Epoch [1/10] - Train Loss: 2.3299\n",
            "Epoch [1/10] - Validation Loss: 1.4237, Accuracy: 46.26%\n",
            "Epoch [2/10] - Train Loss: 1.4237\n",
            "Epoch [2/10] - Validation Loss: 1.4443, Accuracy: 24.87%\n",
            "Epoch [3/10] - Train Loss: 1.3882\n",
            "Epoch [3/10] - Validation Loss: 1.3408, Accuracy: 23.53%\n",
            "Epoch [4/10] - Train Loss: 1.3204\n",
            "Epoch [4/10] - Validation Loss: 1.3449, Accuracy: 19.52%\n",
            "Epoch [5/10] - Train Loss: 1.3049\n",
            "Epoch [5/10] - Validation Loss: 1.3415, Accuracy: 21.12%\n",
            "Epoch [6/10] - Train Loss: 1.2828\n",
            "Epoch [6/10] - Validation Loss: 1.3153, Accuracy: 26.47%\n",
            "Epoch [7/10] - Train Loss: 1.2605\n",
            "Epoch [7/10] - Validation Loss: 1.2901, Accuracy: 30.75%\n",
            "Epoch [8/10] - Train Loss: 1.2529\n",
            "Epoch [8/10] - Validation Loss: 1.3424, Accuracy: 31.02%\n",
            "Epoch [9/10] - Train Loss: 1.2487\n",
            "Epoch [9/10] - Validation Loss: 1.3365, Accuracy: 23.80%\n",
            "Epoch [10/10] - Train Loss: 1.2546\n",
            "Epoch [10/10] - Validation Loss: 1.3417, Accuracy: 18.18%\n",
            "22\n",
            "Epoch [1/10] - Train Loss: 2.2830\n",
            "Epoch [1/10] - Validation Loss: 1.5275, Accuracy: 42.51%\n",
            "Epoch [2/10] - Train Loss: 1.4218\n",
            "Epoch [2/10] - Validation Loss: 1.3988, Accuracy: 16.58%\n",
            "Epoch [3/10] - Train Loss: 1.3680\n",
            "Epoch [3/10] - Validation Loss: 1.3576, Accuracy: 25.40%\n",
            "Epoch [4/10] - Train Loss: 1.3211\n",
            "Epoch [4/10] - Validation Loss: 1.3542, Accuracy: 20.32%\n",
            "Epoch [5/10] - Train Loss: 1.3032\n",
            "Epoch [5/10] - Validation Loss: 1.3249, Accuracy: 23.80%\n",
            "Epoch [6/10] - Train Loss: 1.2845\n",
            "Epoch [6/10] - Validation Loss: 1.3308, Accuracy: 22.46%\n",
            "Epoch [7/10] - Train Loss: 1.2757\n",
            "Epoch [7/10] - Validation Loss: 1.3035, Accuracy: 33.16%\n",
            "Epoch [8/10] - Train Loss: 1.2664\n",
            "Epoch [8/10] - Validation Loss: 1.3074, Accuracy: 26.74%\n",
            "Epoch [9/10] - Train Loss: 1.2619\n",
            "Epoch [9/10] - Validation Loss: 1.3202, Accuracy: 22.99%\n",
            "Epoch [10/10] - Train Loss: 1.2460\n",
            "Epoch [10/10] - Validation Loss: 1.3223, Accuracy: 29.68%\n",
            "23\n",
            "Epoch [1/10] - Train Loss: 2.2429\n",
            "Epoch [1/10] - Validation Loss: 1.4619, Accuracy: 25.67%\n",
            "Epoch [2/10] - Train Loss: 1.4419\n",
            "Epoch [2/10] - Validation Loss: 1.3810, Accuracy: 14.97%\n",
            "Epoch [3/10] - Train Loss: 1.3728\n",
            "Epoch [3/10] - Validation Loss: 1.3677, Accuracy: 45.45%\n",
            "Epoch [4/10] - Train Loss: 1.3449\n",
            "Epoch [4/10] - Validation Loss: 1.3527, Accuracy: 26.47%\n",
            "Epoch [5/10] - Train Loss: 1.3302\n",
            "Epoch [5/10] - Validation Loss: 1.3390, Accuracy: 21.93%\n",
            "Epoch [6/10] - Train Loss: 1.3059\n",
            "Epoch [6/10] - Validation Loss: 1.3720, Accuracy: 22.19%\n",
            "Epoch [7/10] - Train Loss: 1.3073\n",
            "Epoch [7/10] - Validation Loss: 1.3232, Accuracy: 22.99%\n",
            "Epoch [8/10] - Train Loss: 1.2798\n",
            "Epoch [8/10] - Validation Loss: 1.3915, Accuracy: 19.25%\n",
            "Epoch [9/10] - Train Loss: 1.2579\n",
            "Epoch [9/10] - Validation Loss: 1.3132, Accuracy: 47.59%\n",
            "Epoch [10/10] - Train Loss: 1.2676\n",
            "Epoch [10/10] - Validation Loss: 1.3718, Accuracy: 18.18%\n",
            "24\n",
            "Epoch [1/10] - Train Loss: 2.2245\n",
            "Epoch [1/10] - Validation Loss: 1.4022, Accuracy: 13.90%\n",
            "Epoch [2/10] - Train Loss: 1.3942\n",
            "Epoch [2/10] - Validation Loss: 1.3874, Accuracy: 41.44%\n",
            "Epoch [3/10] - Train Loss: 1.3467\n",
            "Epoch [3/10] - Validation Loss: 1.3331, Accuracy: 22.99%\n",
            "Epoch [4/10] - Train Loss: 1.3040\n",
            "Epoch [4/10] - Validation Loss: 1.3674, Accuracy: 28.07%\n",
            "Epoch [5/10] - Train Loss: 1.2878\n",
            "Epoch [5/10] - Validation Loss: 1.3433, Accuracy: 47.33%\n",
            "Epoch [6/10] - Train Loss: 1.2818\n",
            "Epoch [6/10] - Validation Loss: 1.3592, Accuracy: 18.45%\n",
            "Epoch [7/10] - Train Loss: 1.2588\n",
            "Epoch [7/10] - Validation Loss: 1.3258, Accuracy: 27.81%\n",
            "Epoch [8/10] - Train Loss: 1.2503\n",
            "Epoch [8/10] - Validation Loss: 1.3173, Accuracy: 44.12%\n",
            "Epoch [9/10] - Train Loss: 1.2488\n",
            "Epoch [9/10] - Validation Loss: 1.3042, Accuracy: 28.07%\n",
            "Epoch [10/10] - Train Loss: 1.2369\n",
            "Epoch [10/10] - Validation Loss: 1.2975, Accuracy: 25.13%\n",
            "25\n",
            "Epoch [1/10] - Train Loss: 2.1903\n",
            "Epoch [1/10] - Validation Loss: 1.4218, Accuracy: 13.10%\n",
            "Epoch [2/10] - Train Loss: 1.4304\n",
            "Epoch [2/10] - Validation Loss: 1.3609, Accuracy: 28.88%\n",
            "Epoch [3/10] - Train Loss: 1.3587\n",
            "Epoch [3/10] - Validation Loss: 1.3724, Accuracy: 17.11%\n",
            "Epoch [4/10] - Train Loss: 1.3257\n",
            "Epoch [4/10] - Validation Loss: 1.3606, Accuracy: 18.72%\n",
            "Epoch [5/10] - Train Loss: 1.3188\n",
            "Epoch [5/10] - Validation Loss: 1.3510, Accuracy: 26.20%\n",
            "Epoch [6/10] - Train Loss: 1.3060\n",
            "Epoch [6/10] - Validation Loss: 1.3788, Accuracy: 18.72%\n",
            "Epoch [7/10] - Train Loss: 1.2809\n",
            "Epoch [7/10] - Validation Loss: 1.3338, Accuracy: 22.46%\n",
            "Epoch [8/10] - Train Loss: 1.2628\n",
            "Epoch [8/10] - Validation Loss: 1.3159, Accuracy: 23.80%\n",
            "Epoch [9/10] - Train Loss: 1.2561\n",
            "Epoch [9/10] - Validation Loss: 1.3294, Accuracy: 41.18%\n",
            "Epoch [10/10] - Train Loss: 1.2481\n",
            "Epoch [10/10] - Validation Loss: 1.3082, Accuracy: 23.53%\n",
            "26\n",
            "Epoch [1/10] - Train Loss: 2.3956\n",
            "Epoch [1/10] - Validation Loss: 1.3964, Accuracy: 13.90%\n",
            "Epoch [2/10] - Train Loss: 1.4488\n",
            "Epoch [2/10] - Validation Loss: 1.3598, Accuracy: 37.97%\n",
            "Epoch [3/10] - Train Loss: 1.3695\n",
            "Epoch [3/10] - Validation Loss: 1.3893, Accuracy: 14.97%\n",
            "Epoch [4/10] - Train Loss: 1.3469\n",
            "Epoch [4/10] - Validation Loss: 1.3450, Accuracy: 24.33%\n",
            "Epoch [5/10] - Train Loss: 1.3314\n",
            "Epoch [5/10] - Validation Loss: 1.3295, Accuracy: 26.74%\n",
            "Epoch [6/10] - Train Loss: 1.2967\n",
            "Epoch [6/10] - Validation Loss: 1.3169, Accuracy: 23.80%\n",
            "Epoch [7/10] - Train Loss: 1.2812\n",
            "Epoch [7/10] - Validation Loss: 1.3131, Accuracy: 24.06%\n",
            "Epoch [8/10] - Train Loss: 1.2773\n",
            "Epoch [8/10] - Validation Loss: 1.3262, Accuracy: 27.01%\n",
            "Epoch [9/10] - Train Loss: 1.2701\n",
            "Epoch [9/10] - Validation Loss: 1.3210, Accuracy: 22.73%\n",
            "Epoch [10/10] - Train Loss: 1.2683\n",
            "Epoch [10/10] - Validation Loss: 1.3386, Accuracy: 27.27%\n",
            "27\n",
            "Best Hyperparameters:\n",
            "Filter size: 4\n",
            "Best Accuracy: 0.3342245989304813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "#rerun with the obtained best filters to get the best learning rate, dropout rate, batch size, optimizer, embedding dim, epoch number\n",
        "learning_rates = [0.001, 0.01]\n",
        "dropout_rates = [0.3, 0.7]\n",
        "batch_sizes = [128,64]\n",
        "optimizers = [torch.optim.Adam, torch.optim.SGD]\n",
        "embedding_dims = [500,300]\n",
        "epochs = [13, 18]\n",
        "\n",
        "# Initialize variables to keep track of the best hyperparameters and metrics\n",
        "best_hyperparameters = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Perform grid search\n",
        "for learning_rate, dropout_rate, batch_size, optimizer, embedding_dim, epoch  in itertools.product(learning_rates, dropout_rates, batch_sizes, optimizers, embedding_dims, epochs):\n",
        "    batch_size = batch_size\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    # Create a new model with the current hyperparameters\n",
        "    model = SentimentCNN(\n",
        "        vocab_size=len(word_to_ix),\n",
        "        embedding_dim=embedding_dim,\n",
        "        filter_sizes=[4,4,4],\n",
        "        num_filters=[200,200,200],\n",
        "        output_dim=4,\n",
        "        dropout=dropout_rate\n",
        "    )\n",
        "\n",
        "    # Define the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor([1.0, 2.0, 2.0, 6.0]))\n",
        "    optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    num_epochs = epoch  # Adjust the number of epochs as needed\n",
        "\n",
        "    # Training loop (similar to your existing code)\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      model.train()\n",
        "      total_loss = 0.0\n",
        "\n",
        "      for batch in train_loader:\n",
        "          inputs, labels = batch\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      # Calculate and print the average loss for this epoch\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f}')\n",
        "\n",
        "      # Validation\n",
        "      model.eval() #removes dropout\n",
        "      val_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      all_predictions = []\n",
        "      with torch.no_grad():\n",
        "          for batch in val_loader:\n",
        "              inputs, labels = batch\n",
        "              outputs = model(inputs)\n",
        "              loss = criterion(outputs, labels)\n",
        "              val_loss += loss.item()\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "              all_predictions.extend(predicted.tolist())\n",
        "      val_accuracy = 100 * correct / total\n",
        "      val_loss /= len(val_loader)\n",
        "\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}] - Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "    # Calculate accuracy and F1-macro scores\n",
        "    accuracy = accuracy_score(y_val_encoded, all_predictions)\n",
        "\n",
        "    # Keep track of the best hyperparameters\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_hyperparameters = (learning_rate, dropout_rate, batch_size, optimizer, embedding_dim, epoch)\n",
        "\n",
        "# Print the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(\"Learning Rate:\", best_hyperparameters[0])\n",
        "print(\"Dropout Rate:\", best_hyperparameters[1])\n",
        "print(\"Batch Size:\", best_hyperparameters[2])\n",
        "print(\"Optimizer:\", best_hyperparameters[3])\n",
        "print(\"Embedding Dimensions:\", best_hyperparameters[4])\n",
        "print(\"Epochs:\", best_hyperparameters[5])\n",
        "print(\"Best Accuracy:\", best_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8A0hCGZePtR",
        "outputId": "285bd79c-5abb-4ea9-bb1e-96bfc67fc9d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/13] - Train Loss: 2.0485\n",
            "Epoch [1/13] - Validation Loss: 1.4083, Accuracy: 44.12%\n",
            "Epoch [2/13] - Train Loss: 1.4027\n",
            "Epoch [2/13] - Validation Loss: 1.3553, Accuracy: 25.13%\n",
            "Epoch [3/13] - Train Loss: 1.3470\n",
            "Epoch [3/13] - Validation Loss: 1.3976, Accuracy: 19.52%\n",
            "Epoch [4/13] - Train Loss: 1.3199\n",
            "Epoch [4/13] - Validation Loss: 1.3299, Accuracy: 27.81%\n",
            "Epoch [5/13] - Train Loss: 1.2977\n",
            "Epoch [5/13] - Validation Loss: 1.3392, Accuracy: 26.20%\n",
            "Epoch [6/13] - Train Loss: 1.2794\n",
            "Epoch [6/13] - Validation Loss: 1.3421, Accuracy: 18.18%\n",
            "Epoch [7/13] - Train Loss: 1.2791\n",
            "Epoch [7/13] - Validation Loss: 1.3358, Accuracy: 21.66%\n",
            "Epoch [8/13] - Train Loss: 1.2684\n",
            "Epoch [8/13] - Validation Loss: 1.3196, Accuracy: 28.61%\n",
            "Epoch [9/13] - Train Loss: 1.2750\n",
            "Epoch [9/13] - Validation Loss: 1.3212, Accuracy: 27.54%\n",
            "Epoch [10/13] - Train Loss: 1.2620\n",
            "Epoch [10/13] - Validation Loss: 1.3087, Accuracy: 25.13%\n",
            "Epoch [11/13] - Train Loss: 1.2361\n",
            "Epoch [11/13] - Validation Loss: 1.3275, Accuracy: 21.12%\n",
            "Epoch [12/13] - Train Loss: 1.2397\n",
            "Epoch [12/13] - Validation Loss: 1.3240, Accuracy: 20.59%\n",
            "Epoch [13/13] - Train Loss: 1.2358\n",
            "Epoch [13/13] - Validation Loss: 1.3279, Accuracy: 29.14%\n",
            "Epoch [1/18] - Train Loss: 1.9602\n",
            "Epoch [1/18] - Validation Loss: 1.4035, Accuracy: 27.27%\n",
            "Epoch [2/18] - Train Loss: 1.4059\n",
            "Epoch [2/18] - Validation Loss: 1.4165, Accuracy: 16.31%\n",
            "Epoch [3/18] - Train Loss: 1.3585\n",
            "Epoch [3/18] - Validation Loss: 1.3254, Accuracy: 25.13%\n",
            "Epoch [4/18] - Train Loss: 1.3184\n",
            "Epoch [4/18] - Validation Loss: 1.3351, Accuracy: 20.32%\n",
            "Epoch [5/18] - Train Loss: 1.2970\n",
            "Epoch [5/18] - Validation Loss: 1.3364, Accuracy: 28.88%\n",
            "Epoch [6/18] - Train Loss: 1.2927\n",
            "Epoch [6/18] - Validation Loss: 1.3376, Accuracy: 21.66%\n",
            "Epoch [7/18] - Train Loss: 1.2710\n",
            "Epoch [7/18] - Validation Loss: 1.3310, Accuracy: 21.66%\n",
            "Epoch [8/18] - Train Loss: 1.2657\n",
            "Epoch [8/18] - Validation Loss: 1.3031, Accuracy: 27.54%\n",
            "Epoch [9/18] - Train Loss: 1.2662\n",
            "Epoch [9/18] - Validation Loss: 1.3117, Accuracy: 23.26%\n",
            "Epoch [10/18] - Train Loss: 1.2514\n",
            "Epoch [10/18] - Validation Loss: 1.3258, Accuracy: 22.46%\n",
            "Epoch [11/18] - Train Loss: 1.2573\n",
            "Epoch [11/18] - Validation Loss: 1.3295, Accuracy: 45.19%\n",
            "Epoch [12/18] - Train Loss: 1.2574\n",
            "Epoch [12/18] - Validation Loss: 1.3391, Accuracy: 29.41%\n",
            "Epoch [13/18] - Train Loss: 1.2343\n",
            "Epoch [13/18] - Validation Loss: 1.3698, Accuracy: 19.52%\n",
            "Epoch [14/18] - Train Loss: 1.2427\n",
            "Epoch [14/18] - Validation Loss: 1.3274, Accuracy: 21.12%\n",
            "Epoch [15/18] - Train Loss: 1.2236\n",
            "Epoch [15/18] - Validation Loss: 1.3203, Accuracy: 25.67%\n",
            "Epoch [16/18] - Train Loss: 1.2303\n",
            "Epoch [16/18] - Validation Loss: 1.3067, Accuracy: 25.13%\n",
            "Epoch [17/18] - Train Loss: 1.2192\n",
            "Epoch [17/18] - Validation Loss: 1.2995, Accuracy: 24.06%\n",
            "Epoch [18/18] - Train Loss: 1.2153\n",
            "Epoch [18/18] - Validation Loss: 1.3046, Accuracy: 27.27%\n",
            "Epoch [1/13] - Train Loss: 1.8317\n",
            "Epoch [1/13] - Validation Loss: 1.3749, Accuracy: 45.19%\n",
            "Epoch [2/13] - Train Loss: 1.3913\n",
            "Epoch [2/13] - Validation Loss: 1.3859, Accuracy: 14.97%\n",
            "Epoch [3/13] - Train Loss: 1.3468\n",
            "Epoch [3/13] - Validation Loss: 1.3914, Accuracy: 28.34%\n",
            "Epoch [4/13] - Train Loss: 1.3339\n",
            "Epoch [4/13] - Validation Loss: 1.3252, Accuracy: 25.40%\n",
            "Epoch [5/13] - Train Loss: 1.2998\n",
            "Epoch [5/13] - Validation Loss: 1.3263, Accuracy: 22.19%\n",
            "Epoch [6/13] - Train Loss: 1.2872\n",
            "Epoch [6/13] - Validation Loss: 1.3257, Accuracy: 27.54%\n",
            "Epoch [7/13] - Train Loss: 1.2820\n",
            "Epoch [7/13] - Validation Loss: 1.3158, Accuracy: 22.99%\n",
            "Epoch [8/13] - Train Loss: 1.2627\n",
            "Epoch [8/13] - Validation Loss: 1.3258, Accuracy: 26.74%\n",
            "Epoch [9/13] - Train Loss: 1.2581\n",
            "Epoch [9/13] - Validation Loss: 1.3473, Accuracy: 47.59%\n",
            "Epoch [10/13] - Train Loss: 1.2470\n",
            "Epoch [10/13] - Validation Loss: 1.3205, Accuracy: 28.61%\n",
            "Epoch [11/13] - Train Loss: 1.2338\n",
            "Epoch [11/13] - Validation Loss: 1.3118, Accuracy: 23.26%\n",
            "Epoch [12/13] - Train Loss: 1.2363\n",
            "Epoch [12/13] - Validation Loss: 1.2975, Accuracy: 28.61%\n",
            "Epoch [13/13] - Train Loss: 1.2448\n",
            "Epoch [13/13] - Validation Loss: 1.3153, Accuracy: 27.81%\n",
            "Epoch [1/18] - Train Loss: 1.6734\n",
            "Epoch [1/18] - Validation Loss: 1.3667, Accuracy: 17.91%\n",
            "Epoch [2/18] - Train Loss: 1.3772\n",
            "Epoch [2/18] - Validation Loss: 1.3734, Accuracy: 16.58%\n",
            "Epoch [3/18] - Train Loss: 1.3348\n",
            "Epoch [3/18] - Validation Loss: 1.3692, Accuracy: 20.32%\n",
            "Epoch [4/18] - Train Loss: 1.3219\n",
            "Epoch [4/18] - Validation Loss: 1.3200, Accuracy: 31.55%\n",
            "Epoch [5/18] - Train Loss: 1.3113\n",
            "Epoch [5/18] - Validation Loss: 1.3153, Accuracy: 30.21%\n",
            "Epoch [6/18] - Train Loss: 1.2769\n",
            "Epoch [6/18] - Validation Loss: 1.3025, Accuracy: 24.33%\n",
            "Epoch [7/18] - Train Loss: 1.2684\n",
            "Epoch [7/18] - Validation Loss: 1.3267, Accuracy: 26.20%\n",
            "Epoch [8/18] - Train Loss: 1.2670\n",
            "Epoch [8/18] - Validation Loss: 1.3060, Accuracy: 25.94%\n",
            "Epoch [9/18] - Train Loss: 1.2617\n",
            "Epoch [9/18] - Validation Loss: 1.2980, Accuracy: 24.33%\n",
            "Epoch [10/18] - Train Loss: 1.2496\n",
            "Epoch [10/18] - Validation Loss: 1.3344, Accuracy: 30.48%\n",
            "Epoch [11/18] - Train Loss: 1.2393\n",
            "Epoch [11/18] - Validation Loss: 1.3492, Accuracy: 20.32%\n",
            "Epoch [12/18] - Train Loss: 1.2351\n",
            "Epoch [12/18] - Validation Loss: 1.3352, Accuracy: 19.25%\n",
            "Epoch [13/18] - Train Loss: 1.2313\n",
            "Epoch [13/18] - Validation Loss: 1.2765, Accuracy: 28.88%\n",
            "Epoch [14/18] - Train Loss: 1.2368\n",
            "Epoch [14/18] - Validation Loss: 1.2944, Accuracy: 23.53%\n",
            "Epoch [15/18] - Train Loss: 1.2237\n",
            "Epoch [15/18] - Validation Loss: 1.3099, Accuracy: 29.14%\n",
            "Epoch [16/18] - Train Loss: 1.2147\n",
            "Epoch [16/18] - Validation Loss: 1.3375, Accuracy: 21.66%\n",
            "Epoch [17/18] - Train Loss: 1.2162\n",
            "Epoch [17/18] - Validation Loss: 1.3087, Accuracy: 28.61%\n",
            "Epoch [18/18] - Train Loss: 1.2123\n",
            "Epoch [18/18] - Validation Loss: 1.3341, Accuracy: 22.99%\n",
            "Epoch [1/13] - Train Loss: 1.4328\n",
            "Epoch [1/13] - Validation Loss: 1.3913, Accuracy: 13.90%\n",
            "Epoch [2/13] - Train Loss: 1.4041\n",
            "Epoch [2/13] - Validation Loss: 1.3779, Accuracy: 22.99%\n",
            "Epoch [3/13] - Train Loss: 1.4051\n",
            "Epoch [3/13] - Validation Loss: 1.3865, Accuracy: 15.51%\n",
            "Epoch [4/13] - Train Loss: 1.3917\n",
            "Epoch [4/13] - Validation Loss: 1.3748, Accuracy: 15.51%\n",
            "Epoch [5/13] - Train Loss: 1.3962\n",
            "Epoch [5/13] - Validation Loss: 1.3751, Accuracy: 16.84%\n",
            "Epoch [6/13] - Train Loss: 1.3949\n",
            "Epoch [6/13] - Validation Loss: 1.3871, Accuracy: 17.11%\n",
            "Epoch [7/13] - Train Loss: 1.4017\n",
            "Epoch [7/13] - Validation Loss: 1.3684, Accuracy: 17.91%\n",
            "Epoch [8/13] - Train Loss: 1.3831\n",
            "Epoch [8/13] - Validation Loss: 1.3779, Accuracy: 17.38%\n",
            "Epoch [9/13] - Train Loss: 1.3935\n",
            "Epoch [9/13] - Validation Loss: 1.3725, Accuracy: 14.97%\n",
            "Epoch [10/13] - Train Loss: 1.3953\n",
            "Epoch [10/13] - Validation Loss: 1.3661, Accuracy: 17.91%\n",
            "Epoch [11/13] - Train Loss: 1.3960\n",
            "Epoch [11/13] - Validation Loss: 1.3696, Accuracy: 16.04%\n",
            "Epoch [12/13] - Train Loss: 1.3811\n",
            "Epoch [12/13] - Validation Loss: 1.3723, Accuracy: 15.24%\n",
            "Epoch [13/13] - Train Loss: 1.3806\n",
            "Epoch [13/13] - Validation Loss: 1.3754, Accuracy: 15.78%\n",
            "Epoch [1/18] - Train Loss: 1.4140\n",
            "Epoch [1/18] - Validation Loss: 1.3880, Accuracy: 14.97%\n",
            "Epoch [2/18] - Train Loss: 1.4002\n",
            "Epoch [2/18] - Validation Loss: 1.3839, Accuracy: 22.99%\n",
            "Epoch [3/18] - Train Loss: 1.3988\n",
            "Epoch [3/18] - Validation Loss: 1.3932, Accuracy: 23.80%\n",
            "Epoch [4/18] - Train Loss: 1.3964\n",
            "Epoch [4/18] - Validation Loss: 1.3778, Accuracy: 23.53%\n",
            "Epoch [5/18] - Train Loss: 1.3966\n",
            "Epoch [5/18] - Validation Loss: 1.3850, Accuracy: 14.71%\n",
            "Epoch [6/18] - Train Loss: 1.3868\n",
            "Epoch [6/18] - Validation Loss: 1.3879, Accuracy: 17.11%\n",
            "Epoch [7/18] - Train Loss: 1.3969\n",
            "Epoch [7/18] - Validation Loss: 1.3847, Accuracy: 22.99%\n",
            "Epoch [8/18] - Train Loss: 1.3914\n",
            "Epoch [8/18] - Validation Loss: 1.3764, Accuracy: 17.91%\n",
            "Epoch [9/18] - Train Loss: 1.3927\n",
            "Epoch [9/18] - Validation Loss: 1.3778, Accuracy: 18.18%\n",
            "Epoch [10/18] - Train Loss: 1.3841\n",
            "Epoch [10/18] - Validation Loss: 1.3701, Accuracy: 19.52%\n",
            "Epoch [11/18] - Train Loss: 1.3785\n",
            "Epoch [11/18] - Validation Loss: 1.3687, Accuracy: 18.72%\n",
            "Epoch [12/18] - Train Loss: 1.3930\n",
            "Epoch [12/18] - Validation Loss: 1.3721, Accuracy: 18.72%\n",
            "Epoch [13/18] - Train Loss: 1.3668\n",
            "Epoch [13/18] - Validation Loss: 1.3854, Accuracy: 16.84%\n",
            "Epoch [14/18] - Train Loss: 1.3856\n",
            "Epoch [14/18] - Validation Loss: 1.3725, Accuracy: 17.38%\n",
            "Epoch [15/18] - Train Loss: 1.3837\n",
            "Epoch [15/18] - Validation Loss: 1.3690, Accuracy: 17.38%\n",
            "Epoch [16/18] - Train Loss: 1.3717\n",
            "Epoch [16/18] - Validation Loss: 1.3733, Accuracy: 17.38%\n",
            "Epoch [17/18] - Train Loss: 1.3779\n",
            "Epoch [17/18] - Validation Loss: 1.3764, Accuracy: 15.78%\n",
            "Epoch [18/18] - Train Loss: 1.3734\n",
            "Epoch [18/18] - Validation Loss: 1.3752, Accuracy: 16.31%\n",
            "Epoch [1/13] - Train Loss: 1.4086\n",
            "Epoch [1/13] - Validation Loss: 1.4049, Accuracy: 9.36%\n",
            "Epoch [2/13] - Train Loss: 1.4051\n",
            "Epoch [2/13] - Validation Loss: 1.4126, Accuracy: 8.56%\n",
            "Epoch [3/13] - Train Loss: 1.4133\n",
            "Epoch [3/13] - Validation Loss: 1.4155, Accuracy: 8.02%\n",
            "Epoch [4/13] - Train Loss: 1.4113\n",
            "Epoch [4/13] - Validation Loss: 1.3895, Accuracy: 21.66%\n",
            "Epoch [5/13] - Train Loss: 1.4021\n",
            "Epoch [5/13] - Validation Loss: 1.3894, Accuracy: 15.24%\n",
            "Epoch [6/13] - Train Loss: 1.4090\n",
            "Epoch [6/13] - Validation Loss: 1.3882, Accuracy: 16.58%\n",
            "Epoch [7/13] - Train Loss: 1.3952\n",
            "Epoch [7/13] - Validation Loss: 1.3857, Accuracy: 13.37%\n",
            "Epoch [8/13] - Train Loss: 1.4003\n",
            "Epoch [8/13] - Validation Loss: 1.3843, Accuracy: 24.33%\n",
            "Epoch [9/13] - Train Loss: 1.4000\n",
            "Epoch [9/13] - Validation Loss: 1.3805, Accuracy: 16.58%\n",
            "Epoch [10/13] - Train Loss: 1.3916\n",
            "Epoch [10/13] - Validation Loss: 1.3870, Accuracy: 14.71%\n",
            "Epoch [11/13] - Train Loss: 1.4009\n",
            "Epoch [11/13] - Validation Loss: 1.3826, Accuracy: 16.58%\n",
            "Epoch [12/13] - Train Loss: 1.3950\n",
            "Epoch [12/13] - Validation Loss: 1.3852, Accuracy: 15.51%\n",
            "Epoch [13/13] - Train Loss: 1.3907\n",
            "Epoch [13/13] - Validation Loss: 1.3783, Accuracy: 16.84%\n",
            "Epoch [1/18] - Train Loss: 1.4456\n",
            "Epoch [1/18] - Validation Loss: 1.3880, Accuracy: 18.72%\n",
            "Epoch [2/18] - Train Loss: 1.4050\n",
            "Epoch [2/18] - Validation Loss: 1.3904, Accuracy: 21.93%\n",
            "Epoch [3/18] - Train Loss: 1.4018\n",
            "Epoch [3/18] - Validation Loss: 1.3867, Accuracy: 23.53%\n",
            "Epoch [4/18] - Train Loss: 1.3965\n",
            "Epoch [4/18] - Validation Loss: 1.3838, Accuracy: 12.57%\n",
            "Epoch [5/18] - Train Loss: 1.3898\n",
            "Epoch [5/18] - Validation Loss: 1.3806, Accuracy: 16.31%\n",
            "Epoch [6/18] - Train Loss: 1.3949\n",
            "Epoch [6/18] - Validation Loss: 1.3868, Accuracy: 12.30%\n",
            "Epoch [7/18] - Train Loss: 1.3853\n",
            "Epoch [7/18] - Validation Loss: 1.3750, Accuracy: 16.31%\n",
            "Epoch [8/18] - Train Loss: 1.3928\n",
            "Epoch [8/18] - Validation Loss: 1.3740, Accuracy: 22.73%\n",
            "Epoch [9/18] - Train Loss: 1.3925\n",
            "Epoch [9/18] - Validation Loss: 1.3732, Accuracy: 16.58%\n",
            "Epoch [10/18] - Train Loss: 1.3832\n",
            "Epoch [10/18] - Validation Loss: 1.3794, Accuracy: 17.38%\n",
            "Epoch [11/18] - Train Loss: 1.3869\n",
            "Epoch [11/18] - Validation Loss: 1.3711, Accuracy: 17.65%\n",
            "Epoch [12/18] - Train Loss: 1.3897\n",
            "Epoch [12/18] - Validation Loss: 1.3719, Accuracy: 17.38%\n",
            "Epoch [13/18] - Train Loss: 1.3839\n",
            "Epoch [13/18] - Validation Loss: 1.3797, Accuracy: 16.31%\n",
            "Epoch [14/18] - Train Loss: 1.3836\n",
            "Epoch [14/18] - Validation Loss: 1.3713, Accuracy: 17.11%\n",
            "Epoch [15/18] - Train Loss: 1.3777\n",
            "Epoch [15/18] - Validation Loss: 1.3764, Accuracy: 14.17%\n",
            "Epoch [16/18] - Train Loss: 1.3851\n",
            "Epoch [16/18] - Validation Loss: 1.3669, Accuracy: 17.91%\n",
            "Epoch [17/18] - Train Loss: 1.3783\n",
            "Epoch [17/18] - Validation Loss: 1.3703, Accuracy: 17.38%\n",
            "Epoch [18/18] - Train Loss: 1.3735\n",
            "Epoch [18/18] - Validation Loss: 1.3658, Accuracy: 18.18%\n",
            "Epoch [1/13] - Train Loss: 1.9273\n",
            "Epoch [1/13] - Validation Loss: 1.4076, Accuracy: 24.33%\n",
            "Epoch [2/13] - Train Loss: 1.3997\n",
            "Epoch [2/13] - Validation Loss: 1.3445, Accuracy: 22.19%\n",
            "Epoch [3/13] - Train Loss: 1.3386\n",
            "Epoch [3/13] - Validation Loss: 1.3296, Accuracy: 24.60%\n",
            "Epoch [4/13] - Train Loss: 1.3110\n",
            "Epoch [4/13] - Validation Loss: 1.3224, Accuracy: 31.28%\n",
            "Epoch [5/13] - Train Loss: 1.3038\n",
            "Epoch [5/13] - Validation Loss: 1.3431, Accuracy: 20.86%\n",
            "Epoch [6/13] - Train Loss: 1.2887\n",
            "Epoch [6/13] - Validation Loss: 1.3374, Accuracy: 19.52%\n",
            "Epoch [7/13] - Train Loss: 1.2779\n",
            "Epoch [7/13] - Validation Loss: 1.3063, Accuracy: 25.40%\n",
            "Epoch [8/13] - Train Loss: 1.2608\n",
            "Epoch [8/13] - Validation Loss: 1.3329, Accuracy: 27.54%\n",
            "Epoch [9/13] - Train Loss: 1.2558\n",
            "Epoch [9/13] - Validation Loss: 1.3133, Accuracy: 21.39%\n",
            "Epoch [10/13] - Train Loss: 1.2651\n",
            "Epoch [10/13] - Validation Loss: 1.3042, Accuracy: 27.27%\n",
            "Epoch [11/13] - Train Loss: 1.2476\n",
            "Epoch [11/13] - Validation Loss: 1.3299, Accuracy: 20.32%\n",
            "Epoch [12/13] - Train Loss: 1.2406\n",
            "Epoch [12/13] - Validation Loss: 1.3198, Accuracy: 26.74%\n",
            "Epoch [13/13] - Train Loss: 1.2374\n",
            "Epoch [13/13] - Validation Loss: 1.3057, Accuracy: 21.39%\n",
            "Epoch [1/18] - Train Loss: 1.7077\n",
            "Epoch [1/18] - Validation Loss: 1.4074, Accuracy: 43.32%\n",
            "Epoch [2/18] - Train Loss: 1.3570\n",
            "Epoch [2/18] - Validation Loss: 1.4075, Accuracy: 24.06%\n",
            "Epoch [3/18] - Train Loss: 1.3335\n",
            "Epoch [3/18] - Validation Loss: 1.3613, Accuracy: 29.95%\n",
            "Epoch [4/18] - Train Loss: 1.3203\n",
            "Epoch [4/18] - Validation Loss: 1.3412, Accuracy: 20.86%\n",
            "Epoch [5/18] - Train Loss: 1.3007\n",
            "Epoch [5/18] - Validation Loss: 1.3338, Accuracy: 20.32%\n",
            "Epoch [6/18] - Train Loss: 1.2762\n",
            "Epoch [6/18] - Validation Loss: 1.3268, Accuracy: 20.59%\n",
            "Epoch [7/18] - Train Loss: 1.2745\n",
            "Epoch [7/18] - Validation Loss: 1.3115, Accuracy: 26.47%\n",
            "Epoch [8/18] - Train Loss: 1.2665\n",
            "Epoch [8/18] - Validation Loss: 1.3118, Accuracy: 43.85%\n",
            "Epoch [9/18] - Train Loss: 1.2592\n",
            "Epoch [9/18] - Validation Loss: 1.3093, Accuracy: 42.78%\n",
            "Epoch [10/18] - Train Loss: 1.2494\n",
            "Epoch [10/18] - Validation Loss: 1.3092, Accuracy: 22.46%\n",
            "Epoch [11/18] - Train Loss: 1.2431\n",
            "Epoch [11/18] - Validation Loss: 1.3069, Accuracy: 22.46%\n",
            "Epoch [12/18] - Train Loss: 1.2454\n",
            "Epoch [12/18] - Validation Loss: 1.3222, Accuracy: 19.25%\n",
            "Epoch [13/18] - Train Loss: 1.2364\n",
            "Epoch [13/18] - Validation Loss: 1.3072, Accuracy: 20.59%\n",
            "Epoch [14/18] - Train Loss: 1.2445\n",
            "Epoch [14/18] - Validation Loss: 1.3208, Accuracy: 20.59%\n",
            "Epoch [15/18] - Train Loss: 1.2372\n",
            "Epoch [15/18] - Validation Loss: 1.2904, Accuracy: 27.81%\n",
            "Epoch [16/18] - Train Loss: 1.2220\n",
            "Epoch [16/18] - Validation Loss: 1.3017, Accuracy: 21.93%\n",
            "Epoch [17/18] - Train Loss: 1.2244\n",
            "Epoch [17/18] - Validation Loss: 1.3225, Accuracy: 21.39%\n",
            "Epoch [18/18] - Train Loss: 1.2088\n",
            "Epoch [18/18] - Validation Loss: 1.3158, Accuracy: 23.26%\n",
            "Epoch [1/13] - Train Loss: 1.5639\n",
            "Epoch [1/13] - Validation Loss: 1.3775, Accuracy: 47.33%\n",
            "Epoch [2/13] - Train Loss: 1.3766\n",
            "Epoch [2/13] - Validation Loss: 1.3452, Accuracy: 22.19%\n",
            "Epoch [3/13] - Train Loss: 1.3625\n",
            "Epoch [3/13] - Validation Loss: 1.3961, Accuracy: 14.44%\n",
            "Epoch [4/13] - Train Loss: 1.3094\n",
            "Epoch [4/13] - Validation Loss: 1.3832, Accuracy: 19.79%\n",
            "Epoch [5/13] - Train Loss: 1.2887\n",
            "Epoch [5/13] - Validation Loss: 1.3135, Accuracy: 27.54%\n",
            "Epoch [6/13] - Train Loss: 1.2689\n",
            "Epoch [6/13] - Validation Loss: 1.3579, Accuracy: 21.12%\n",
            "Epoch [7/13] - Train Loss: 1.2632\n",
            "Epoch [7/13] - Validation Loss: 1.3327, Accuracy: 21.39%\n",
            "Epoch [8/13] - Train Loss: 1.2399\n",
            "Epoch [8/13] - Validation Loss: 1.3525, Accuracy: 26.20%\n",
            "Epoch [9/13] - Train Loss: 1.2499\n",
            "Epoch [9/13] - Validation Loss: 1.3113, Accuracy: 27.01%\n",
            "Epoch [10/13] - Train Loss: 1.2334\n",
            "Epoch [10/13] - Validation Loss: 1.3101, Accuracy: 21.39%\n",
            "Epoch [11/13] - Train Loss: 1.2314\n",
            "Epoch [11/13] - Validation Loss: 1.3122, Accuracy: 21.12%\n",
            "Epoch [12/13] - Train Loss: 1.2256\n",
            "Epoch [12/13] - Validation Loss: 1.3447, Accuracy: 19.79%\n",
            "Epoch [13/13] - Train Loss: 1.2225\n",
            "Epoch [13/13] - Validation Loss: 1.3142, Accuracy: 21.39%\n",
            "Epoch [1/18] - Train Loss: 1.6427\n",
            "Epoch [1/18] - Validation Loss: 1.4604, Accuracy: 30.48%\n",
            "Epoch [2/18] - Train Loss: 1.3792\n",
            "Epoch [2/18] - Validation Loss: 1.3924, Accuracy: 44.65%\n",
            "Epoch [3/18] - Train Loss: 1.3519\n",
            "Epoch [3/18] - Validation Loss: 1.3392, Accuracy: 23.26%\n",
            "Epoch [4/18] - Train Loss: 1.3113\n",
            "Epoch [4/18] - Validation Loss: 1.3537, Accuracy: 26.20%\n",
            "Epoch [5/18] - Train Loss: 1.2930\n",
            "Epoch [5/18] - Validation Loss: 1.3971, Accuracy: 16.31%\n",
            "Epoch [6/18] - Train Loss: 1.2729\n",
            "Epoch [6/18] - Validation Loss: 1.3129, Accuracy: 29.95%\n",
            "Epoch [7/18] - Train Loss: 1.2646\n",
            "Epoch [7/18] - Validation Loss: 1.3056, Accuracy: 25.94%\n",
            "Epoch [8/18] - Train Loss: 1.2529\n",
            "Epoch [8/18] - Validation Loss: 1.3178, Accuracy: 33.96%\n",
            "Epoch [9/18] - Train Loss: 1.2505\n",
            "Epoch [9/18] - Validation Loss: 1.3389, Accuracy: 23.26%\n",
            "Epoch [10/18] - Train Loss: 1.2400\n",
            "Epoch [10/18] - Validation Loss: 1.2978, Accuracy: 25.94%\n",
            "Epoch [11/18] - Train Loss: 1.2421\n",
            "Epoch [11/18] - Validation Loss: 1.3105, Accuracy: 23.53%\n",
            "Epoch [12/18] - Train Loss: 1.2393\n",
            "Epoch [12/18] - Validation Loss: 1.4405, Accuracy: 20.86%\n",
            "Epoch [13/18] - Train Loss: 1.2300\n",
            "Epoch [13/18] - Validation Loss: 1.3082, Accuracy: 29.68%\n",
            "Epoch [14/18] - Train Loss: 1.2239\n",
            "Epoch [14/18] - Validation Loss: 1.3062, Accuracy: 23.53%\n",
            "Epoch [15/18] - Train Loss: 1.2168\n",
            "Epoch [15/18] - Validation Loss: 1.3143, Accuracy: 25.94%\n",
            "Epoch [16/18] - Train Loss: 1.2150\n",
            "Epoch [16/18] - Validation Loss: 1.3400, Accuracy: 22.99%\n",
            "Epoch [17/18] - Train Loss: 1.2112\n",
            "Epoch [17/18] - Validation Loss: 1.3654, Accuracy: 29.95%\n",
            "Epoch [18/18] - Train Loss: 1.2116\n",
            "Epoch [18/18] - Validation Loss: 1.3171, Accuracy: 32.89%\n",
            "Epoch [1/13] - Train Loss: 1.4114\n",
            "Epoch [1/13] - Validation Loss: 1.3932, Accuracy: 41.71%\n",
            "Epoch [2/13] - Train Loss: 1.4145\n",
            "Epoch [2/13] - Validation Loss: 1.3815, Accuracy: 15.51%\n",
            "Epoch [3/13] - Train Loss: 1.3932\n",
            "Epoch [3/13] - Validation Loss: 1.3817, Accuracy: 15.24%\n",
            "Epoch [4/13] - Train Loss: 1.3945\n",
            "Epoch [4/13] - Validation Loss: 1.3812, Accuracy: 17.65%\n",
            "Epoch [5/13] - Train Loss: 1.3867\n",
            "Epoch [5/13] - Validation Loss: 1.3743, Accuracy: 24.06%\n",
            "Epoch [6/13] - Train Loss: 1.3800\n",
            "Epoch [6/13] - Validation Loss: 1.3663, Accuracy: 16.58%\n",
            "Epoch [7/13] - Train Loss: 1.3813\n",
            "Epoch [7/13] - Validation Loss: 1.3669, Accuracy: 17.38%\n",
            "Epoch [8/13] - Train Loss: 1.3796\n",
            "Epoch [8/13] - Validation Loss: 1.3670, Accuracy: 17.65%\n",
            "Epoch [9/13] - Train Loss: 1.3706\n",
            "Epoch [9/13] - Validation Loss: 1.3608, Accuracy: 25.13%\n",
            "Epoch [10/13] - Train Loss: 1.3789\n",
            "Epoch [10/13] - Validation Loss: 1.3727, Accuracy: 17.65%\n",
            "Epoch [11/13] - Train Loss: 1.3733\n",
            "Epoch [11/13] - Validation Loss: 1.3651, Accuracy: 17.11%\n",
            "Epoch [12/13] - Train Loss: 1.3717\n",
            "Epoch [12/13] - Validation Loss: 1.3574, Accuracy: 17.91%\n",
            "Epoch [13/13] - Train Loss: 1.3694\n",
            "Epoch [13/13] - Validation Loss: 1.3570, Accuracy: 25.40%\n",
            "Epoch [1/18] - Train Loss: 1.4197\n",
            "Epoch [1/18] - Validation Loss: 1.3921, Accuracy: 14.97%\n",
            "Epoch [2/18] - Train Loss: 1.4048\n",
            "Epoch [2/18] - Validation Loss: 1.3906, Accuracy: 14.71%\n",
            "Epoch [3/18] - Train Loss: 1.3996\n",
            "Epoch [3/18] - Validation Loss: 1.3735, Accuracy: 16.58%\n",
            "Epoch [4/18] - Train Loss: 1.3921\n",
            "Epoch [4/18] - Validation Loss: 1.3722, Accuracy: 16.84%\n",
            "Epoch [5/18] - Train Loss: 1.3963\n",
            "Epoch [5/18] - Validation Loss: 1.3705, Accuracy: 23.26%\n",
            "Epoch [6/18] - Train Loss: 1.3831\n",
            "Epoch [6/18] - Validation Loss: 1.3888, Accuracy: 12.83%\n",
            "Epoch [7/18] - Train Loss: 1.3883\n",
            "Epoch [7/18] - Validation Loss: 1.3733, Accuracy: 17.11%\n",
            "Epoch [8/18] - Train Loss: 1.3882\n",
            "Epoch [8/18] - Validation Loss: 1.3647, Accuracy: 17.65%\n",
            "Epoch [9/18] - Train Loss: 1.3733\n",
            "Epoch [9/18] - Validation Loss: 1.3671, Accuracy: 17.38%\n",
            "Epoch [10/18] - Train Loss: 1.3816\n",
            "Epoch [10/18] - Validation Loss: 1.3643, Accuracy: 16.58%\n",
            "Epoch [11/18] - Train Loss: 1.3814\n",
            "Epoch [11/18] - Validation Loss: 1.3563, Accuracy: 18.45%\n",
            "Epoch [12/18] - Train Loss: 1.3763\n",
            "Epoch [12/18] - Validation Loss: 1.3664, Accuracy: 17.65%\n",
            "Epoch [13/18] - Train Loss: 1.3727\n",
            "Epoch [13/18] - Validation Loss: 1.3588, Accuracy: 18.18%\n",
            "Epoch [14/18] - Train Loss: 1.3704\n",
            "Epoch [14/18] - Validation Loss: 1.3572, Accuracy: 24.33%\n",
            "Epoch [15/18] - Train Loss: 1.3671\n",
            "Epoch [15/18] - Validation Loss: 1.3688, Accuracy: 16.84%\n",
            "Epoch [16/18] - Train Loss: 1.3601\n",
            "Epoch [16/18] - Validation Loss: 1.3580, Accuracy: 18.45%\n",
            "Epoch [17/18] - Train Loss: 1.3589\n",
            "Epoch [17/18] - Validation Loss: 1.3610, Accuracy: 18.18%\n",
            "Epoch [18/18] - Train Loss: 1.3564\n",
            "Epoch [18/18] - Validation Loss: 1.3626, Accuracy: 16.84%\n",
            "Epoch [1/13] - Train Loss: 1.4102\n",
            "Epoch [1/13] - Validation Loss: 1.3912, Accuracy: 20.59%\n",
            "Epoch [2/13] - Train Loss: 1.3933\n",
            "Epoch [2/13] - Validation Loss: 1.3849, Accuracy: 13.64%\n",
            "Epoch [3/13] - Train Loss: 1.3979\n",
            "Epoch [3/13] - Validation Loss: 1.3914, Accuracy: 22.46%\n",
            "Epoch [4/13] - Train Loss: 1.3882\n",
            "Epoch [4/13] - Validation Loss: 1.3768, Accuracy: 14.97%\n",
            "Epoch [5/13] - Train Loss: 1.3929\n",
            "Epoch [5/13] - Validation Loss: 1.3855, Accuracy: 17.11%\n",
            "Epoch [6/13] - Train Loss: 1.4001\n",
            "Epoch [6/13] - Validation Loss: 1.3747, Accuracy: 17.38%\n",
            "Epoch [7/13] - Train Loss: 1.3886\n",
            "Epoch [7/13] - Validation Loss: 1.3751, Accuracy: 17.38%\n",
            "Epoch [8/13] - Train Loss: 1.3892\n",
            "Epoch [8/13] - Validation Loss: 1.3709, Accuracy: 22.73%\n",
            "Epoch [9/13] - Train Loss: 1.3803\n",
            "Epoch [9/13] - Validation Loss: 1.3663, Accuracy: 17.65%\n",
            "Epoch [10/13] - Train Loss: 1.3824\n",
            "Epoch [10/13] - Validation Loss: 1.3697, Accuracy: 17.11%\n",
            "Epoch [11/13] - Train Loss: 1.3794\n",
            "Epoch [11/13] - Validation Loss: 1.3870, Accuracy: 14.97%\n",
            "Epoch [12/13] - Train Loss: 1.3815\n",
            "Epoch [12/13] - Validation Loss: 1.3622, Accuracy: 18.18%\n",
            "Epoch [13/13] - Train Loss: 1.3736\n",
            "Epoch [13/13] - Validation Loss: 1.3711, Accuracy: 17.11%\n",
            "Epoch [1/18] - Train Loss: 1.4069\n",
            "Epoch [1/18] - Validation Loss: 1.3795, Accuracy: 25.94%\n",
            "Epoch [2/18] - Train Loss: 1.4026\n",
            "Epoch [2/18] - Validation Loss: 1.3808, Accuracy: 16.58%\n",
            "Epoch [3/18] - Train Loss: 1.3989\n",
            "Epoch [3/18] - Validation Loss: 1.3923, Accuracy: 10.16%\n",
            "Epoch [4/18] - Train Loss: 1.3947\n",
            "Epoch [4/18] - Validation Loss: 1.3756, Accuracy: 17.65%\n",
            "Epoch [5/18] - Train Loss: 1.3916\n",
            "Epoch [5/18] - Validation Loss: 1.3792, Accuracy: 14.71%\n",
            "Epoch [6/18] - Train Loss: 1.3926\n",
            "Epoch [6/18] - Validation Loss: 1.3732, Accuracy: 18.45%\n",
            "Epoch [7/18] - Train Loss: 1.3886\n",
            "Epoch [7/18] - Validation Loss: 1.3686, Accuracy: 20.59%\n",
            "Epoch [8/18] - Train Loss: 1.3904\n",
            "Epoch [8/18] - Validation Loss: 1.3681, Accuracy: 18.72%\n",
            "Epoch [9/18] - Train Loss: 1.3814\n",
            "Epoch [9/18] - Validation Loss: 1.3757, Accuracy: 23.26%\n",
            "Epoch [10/18] - Train Loss: 1.3820\n",
            "Epoch [10/18] - Validation Loss: 1.3645, Accuracy: 17.91%\n",
            "Epoch [11/18] - Train Loss: 1.3790\n",
            "Epoch [11/18] - Validation Loss: 1.3644, Accuracy: 18.72%\n",
            "Epoch [12/18] - Train Loss: 1.3900\n",
            "Epoch [12/18] - Validation Loss: 1.3632, Accuracy: 17.65%\n",
            "Epoch [13/18] - Train Loss: 1.3813\n",
            "Epoch [13/18] - Validation Loss: 1.3599, Accuracy: 18.72%\n",
            "Epoch [14/18] - Train Loss: 1.3749\n",
            "Epoch [14/18] - Validation Loss: 1.3729, Accuracy: 18.72%\n",
            "Epoch [15/18] - Train Loss: 1.3708\n",
            "Epoch [15/18] - Validation Loss: 1.3613, Accuracy: 16.31%\n",
            "Epoch [16/18] - Train Loss: 1.3753\n",
            "Epoch [16/18] - Validation Loss: 1.3644, Accuracy: 18.98%\n",
            "Epoch [17/18] - Train Loss: 1.3729\n",
            "Epoch [17/18] - Validation Loss: 1.3645, Accuracy: 17.91%\n",
            "Epoch [18/18] - Train Loss: 1.3636\n",
            "Epoch [18/18] - Validation Loss: 1.3655, Accuracy: 23.26%\n",
            "Epoch [1/13] - Train Loss: 1.8947\n",
            "Epoch [1/13] - Validation Loss: 1.3665, Accuracy: 29.41%\n",
            "Epoch [2/13] - Train Loss: 1.3984\n",
            "Epoch [2/13] - Validation Loss: 1.3550, Accuracy: 22.46%\n",
            "Epoch [3/13] - Train Loss: 1.3639\n",
            "Epoch [3/13] - Validation Loss: 1.3482, Accuracy: 20.86%\n",
            "Epoch [4/13] - Train Loss: 1.3422\n",
            "Epoch [4/13] - Validation Loss: 1.3504, Accuracy: 16.84%\n",
            "Epoch [5/13] - Train Loss: 1.3394\n",
            "Epoch [5/13] - Validation Loss: 1.3456, Accuracy: 28.61%\n",
            "Epoch [6/13] - Train Loss: 1.3263\n",
            "Epoch [6/13] - Validation Loss: 1.3341, Accuracy: 17.91%\n",
            "Epoch [7/13] - Train Loss: 1.3247\n",
            "Epoch [7/13] - Validation Loss: 1.3204, Accuracy: 22.46%\n",
            "Epoch [8/13] - Train Loss: 1.3101\n",
            "Epoch [8/13] - Validation Loss: 1.3186, Accuracy: 22.46%\n",
            "Epoch [9/13] - Train Loss: 1.3105\n",
            "Epoch [9/13] - Validation Loss: 1.3222, Accuracy: 21.93%\n",
            "Epoch [10/13] - Train Loss: 1.2959\n",
            "Epoch [10/13] - Validation Loss: 1.3392, Accuracy: 18.18%\n",
            "Epoch [11/13] - Train Loss: 1.2971\n",
            "Epoch [11/13] - Validation Loss: 1.3209, Accuracy: 24.60%\n",
            "Epoch [12/13] - Train Loss: 1.2893\n",
            "Epoch [12/13] - Validation Loss: 1.3089, Accuracy: 22.46%\n",
            "Epoch [13/13] - Train Loss: 1.2697\n",
            "Epoch [13/13] - Validation Loss: 1.3111, Accuracy: 21.66%\n",
            "Epoch [1/18] - Train Loss: 2.0018\n",
            "Epoch [1/18] - Validation Loss: 1.3927, Accuracy: 16.04%\n",
            "Epoch [2/18] - Train Loss: 1.3932\n",
            "Epoch [2/18] - Validation Loss: 1.3712, Accuracy: 22.46%\n",
            "Epoch [3/18] - Train Loss: 1.3768\n",
            "Epoch [3/18] - Validation Loss: 1.3558, Accuracy: 17.65%\n",
            "Epoch [4/18] - Train Loss: 1.3575\n",
            "Epoch [4/18] - Validation Loss: 1.3402, Accuracy: 21.39%\n",
            "Epoch [5/18] - Train Loss: 1.3470\n",
            "Epoch [5/18] - Validation Loss: 1.3400, Accuracy: 27.54%\n",
            "Epoch [6/18] - Train Loss: 1.3356\n",
            "Epoch [6/18] - Validation Loss: 1.3315, Accuracy: 21.39%\n",
            "Epoch [7/18] - Train Loss: 1.3139\n",
            "Epoch [7/18] - Validation Loss: 1.3199, Accuracy: 23.53%\n",
            "Epoch [8/18] - Train Loss: 1.3120\n",
            "Epoch [8/18] - Validation Loss: 1.3134, Accuracy: 23.26%\n",
            "Epoch [9/18] - Train Loss: 1.2993\n",
            "Epoch [9/18] - Validation Loss: 1.3107, Accuracy: 21.93%\n",
            "Epoch [10/18] - Train Loss: 1.2899\n",
            "Epoch [10/18] - Validation Loss: 1.3083, Accuracy: 24.87%\n",
            "Epoch [11/18] - Train Loss: 1.2931\n",
            "Epoch [11/18] - Validation Loss: 1.3120, Accuracy: 29.68%\n",
            "Epoch [12/18] - Train Loss: 1.2916\n",
            "Epoch [12/18] - Validation Loss: 1.3021, Accuracy: 28.88%\n",
            "Epoch [13/18] - Train Loss: 1.2832\n",
            "Epoch [13/18] - Validation Loss: 1.2992, Accuracy: 29.41%\n",
            "Epoch [14/18] - Train Loss: 1.2824\n",
            "Epoch [14/18] - Validation Loss: 1.3069, Accuracy: 20.86%\n",
            "Epoch [15/18] - Train Loss: 1.2734\n",
            "Epoch [15/18] - Validation Loss: 1.3070, Accuracy: 21.12%\n",
            "Epoch [16/18] - Train Loss: 1.2652\n",
            "Epoch [16/18] - Validation Loss: 1.3032, Accuracy: 21.39%\n",
            "Epoch [17/18] - Train Loss: 1.2728\n",
            "Epoch [17/18] - Validation Loss: 1.3037, Accuracy: 22.19%\n",
            "Epoch [18/18] - Train Loss: 1.2739\n",
            "Epoch [18/18] - Validation Loss: 1.3145, Accuracy: 19.79%\n",
            "Epoch [1/13] - Train Loss: 1.6543\n",
            "Epoch [1/13] - Validation Loss: 1.3911, Accuracy: 40.64%\n",
            "Epoch [2/13] - Train Loss: 1.4002\n",
            "Epoch [2/13] - Validation Loss: 1.3505, Accuracy: 21.12%\n",
            "Epoch [3/13] - Train Loss: 1.3541\n",
            "Epoch [3/13] - Validation Loss: 1.3451, Accuracy: 19.52%\n",
            "Epoch [4/13] - Train Loss: 1.3302\n",
            "Epoch [4/13] - Validation Loss: 1.3381, Accuracy: 27.01%\n",
            "Epoch [5/13] - Train Loss: 1.3300\n",
            "Epoch [5/13] - Validation Loss: 1.3551, Accuracy: 16.31%\n",
            "Epoch [6/13] - Train Loss: 1.3324\n",
            "Epoch [6/13] - Validation Loss: 1.3337, Accuracy: 18.72%\n",
            "Epoch [7/13] - Train Loss: 1.3131\n",
            "Epoch [7/13] - Validation Loss: 1.3284, Accuracy: 17.91%\n",
            "Epoch [8/13] - Train Loss: 1.3069\n",
            "Epoch [8/13] - Validation Loss: 1.3327, Accuracy: 26.20%\n",
            "Epoch [9/13] - Train Loss: 1.2941\n",
            "Epoch [9/13] - Validation Loss: 1.3261, Accuracy: 18.98%\n",
            "Epoch [10/13] - Train Loss: 1.2948\n",
            "Epoch [10/13] - Validation Loss: 1.3377, Accuracy: 18.72%\n",
            "Epoch [11/13] - Train Loss: 1.2768\n",
            "Epoch [11/13] - Validation Loss: 1.3145, Accuracy: 27.27%\n",
            "Epoch [12/13] - Train Loss: 1.2888\n",
            "Epoch [12/13] - Validation Loss: 1.3113, Accuracy: 21.39%\n",
            "Epoch [13/13] - Train Loss: 1.2802\n",
            "Epoch [13/13] - Validation Loss: 1.3291, Accuracy: 21.12%\n",
            "Epoch [1/18] - Train Loss: 1.7019\n",
            "Epoch [1/18] - Validation Loss: 1.4593, Accuracy: 42.78%\n",
            "Epoch [2/18] - Train Loss: 1.4393\n",
            "Epoch [2/18] - Validation Loss: 1.3620, Accuracy: 28.88%\n",
            "Epoch [3/18] - Train Loss: 1.3736\n",
            "Epoch [3/18] - Validation Loss: 1.3514, Accuracy: 20.59%\n",
            "Epoch [4/18] - Train Loss: 1.3568\n",
            "Epoch [4/18] - Validation Loss: 1.3517, Accuracy: 17.11%\n",
            "Epoch [5/18] - Train Loss: 1.3356\n",
            "Epoch [5/18] - Validation Loss: 1.3341, Accuracy: 27.81%\n",
            "Epoch [6/18] - Train Loss: 1.3276\n",
            "Epoch [6/18] - Validation Loss: 1.3359, Accuracy: 27.54%\n",
            "Epoch [7/18] - Train Loss: 1.3383\n",
            "Epoch [7/18] - Validation Loss: 1.3543, Accuracy: 16.58%\n",
            "Epoch [8/18] - Train Loss: 1.3134\n",
            "Epoch [8/18] - Validation Loss: 1.3293, Accuracy: 22.73%\n",
            "Epoch [9/18] - Train Loss: 1.2972\n",
            "Epoch [9/18] - Validation Loss: 1.3183, Accuracy: 18.72%\n",
            "Epoch [10/18] - Train Loss: 1.3045\n",
            "Epoch [10/18] - Validation Loss: 1.3173, Accuracy: 29.41%\n",
            "Epoch [11/18] - Train Loss: 1.2973\n",
            "Epoch [11/18] - Validation Loss: 1.3210, Accuracy: 18.98%\n",
            "Epoch [12/18] - Train Loss: 1.2900\n",
            "Epoch [12/18] - Validation Loss: 1.3120, Accuracy: 24.87%\n",
            "Epoch [13/18] - Train Loss: 1.2891\n",
            "Epoch [13/18] - Validation Loss: 1.3150, Accuracy: 27.54%\n",
            "Epoch [14/18] - Train Loss: 1.2823\n",
            "Epoch [14/18] - Validation Loss: 1.3049, Accuracy: 21.39%\n",
            "Epoch [15/18] - Train Loss: 1.2797\n",
            "Epoch [15/18] - Validation Loss: 1.3180, Accuracy: 20.32%\n",
            "Epoch [16/18] - Train Loss: 1.2830\n",
            "Epoch [16/18] - Validation Loss: 1.3059, Accuracy: 22.46%\n",
            "Epoch [17/18] - Train Loss: 1.2739\n",
            "Epoch [17/18] - Validation Loss: 1.3181, Accuracy: 43.58%\n",
            "Epoch [18/18] - Train Loss: 1.2773\n",
            "Epoch [18/18] - Validation Loss: 1.2994, Accuracy: 21.93%\n",
            "Epoch [1/13] - Train Loss: 1.4979\n",
            "Epoch [1/13] - Validation Loss: 1.3962, Accuracy: 22.19%\n",
            "Epoch [2/13] - Train Loss: 1.4776\n",
            "Epoch [2/13] - Validation Loss: 1.3973, Accuracy: 22.73%\n",
            "Epoch [3/13] - Train Loss: 1.4619\n",
            "Epoch [3/13] - Validation Loss: 1.3905, Accuracy: 13.90%\n",
            "Epoch [4/13] - Train Loss: 1.4685\n",
            "Epoch [4/13] - Validation Loss: 1.3885, Accuracy: 17.65%\n",
            "Epoch [5/13] - Train Loss: 1.4430\n",
            "Epoch [5/13] - Validation Loss: 1.3807, Accuracy: 13.90%\n",
            "Epoch [6/13] - Train Loss: 1.4353\n",
            "Epoch [6/13] - Validation Loss: 1.3808, Accuracy: 14.44%\n",
            "Epoch [7/13] - Train Loss: 1.4349\n",
            "Epoch [7/13] - Validation Loss: 1.3797, Accuracy: 16.58%\n",
            "Epoch [8/13] - Train Loss: 1.4279\n",
            "Epoch [8/13] - Validation Loss: 1.3755, Accuracy: 16.84%\n",
            "Epoch [9/13] - Train Loss: 1.4325\n",
            "Epoch [9/13] - Validation Loss: 1.3719, Accuracy: 16.84%\n",
            "Epoch [10/13] - Train Loss: 1.4204\n",
            "Epoch [10/13] - Validation Loss: 1.3707, Accuracy: 18.45%\n",
            "Epoch [11/13] - Train Loss: 1.4039\n",
            "Epoch [11/13] - Validation Loss: 1.3697, Accuracy: 19.79%\n",
            "Epoch [12/13] - Train Loss: 1.4033\n",
            "Epoch [12/13] - Validation Loss: 1.3729, Accuracy: 16.31%\n",
            "Epoch [13/13] - Train Loss: 1.4117\n",
            "Epoch [13/13] - Validation Loss: 1.3717, Accuracy: 15.24%\n",
            "Epoch [1/18] - Train Loss: 1.4826\n",
            "Epoch [1/18] - Validation Loss: 1.4005, Accuracy: 8.82%\n",
            "Epoch [2/18] - Train Loss: 1.4841\n",
            "Epoch [2/18] - Validation Loss: 1.3916, Accuracy: 16.84%\n",
            "Epoch [3/18] - Train Loss: 1.4583\n",
            "Epoch [3/18] - Validation Loss: 1.3858, Accuracy: 23.26%\n",
            "Epoch [4/18] - Train Loss: 1.4639\n",
            "Epoch [4/18] - Validation Loss: 1.3947, Accuracy: 23.53%\n",
            "Epoch [5/18] - Train Loss: 1.4559\n",
            "Epoch [5/18] - Validation Loss: 1.3881, Accuracy: 17.91%\n",
            "Epoch [6/18] - Train Loss: 1.4402\n",
            "Epoch [6/18] - Validation Loss: 1.3815, Accuracy: 18.18%\n",
            "Epoch [7/18] - Train Loss: 1.4056\n",
            "Epoch [7/18] - Validation Loss: 1.3782, Accuracy: 17.38%\n",
            "Epoch [8/18] - Train Loss: 1.4249\n",
            "Epoch [8/18] - Validation Loss: 1.3721, Accuracy: 39.04%\n",
            "Epoch [9/18] - Train Loss: 1.4240\n",
            "Epoch [9/18] - Validation Loss: 1.3802, Accuracy: 16.58%\n",
            "Epoch [10/18] - Train Loss: 1.4271\n",
            "Epoch [10/18] - Validation Loss: 1.3777, Accuracy: 23.53%\n",
            "Epoch [11/18] - Train Loss: 1.4122\n",
            "Epoch [11/18] - Validation Loss: 1.3736, Accuracy: 23.53%\n",
            "Epoch [12/18] - Train Loss: 1.4027\n",
            "Epoch [12/18] - Validation Loss: 1.3786, Accuracy: 23.53%\n",
            "Epoch [13/18] - Train Loss: 1.4083\n",
            "Epoch [13/18] - Validation Loss: 1.3673, Accuracy: 39.30%\n",
            "Epoch [14/18] - Train Loss: 1.3989\n",
            "Epoch [14/18] - Validation Loss: 1.3673, Accuracy: 17.65%\n",
            "Epoch [15/18] - Train Loss: 1.4032\n",
            "Epoch [15/18] - Validation Loss: 1.3760, Accuracy: 15.78%\n",
            "Epoch [16/18] - Train Loss: 1.3922\n",
            "Epoch [16/18] - Validation Loss: 1.3721, Accuracy: 17.65%\n",
            "Epoch [17/18] - Train Loss: 1.3939\n",
            "Epoch [17/18] - Validation Loss: 1.3668, Accuracy: 18.45%\n",
            "Epoch [18/18] - Train Loss: 1.3857\n",
            "Epoch [18/18] - Validation Loss: 1.3663, Accuracy: 18.45%\n",
            "Epoch [1/13] - Train Loss: 1.4972\n",
            "Epoch [1/13] - Validation Loss: 1.4025, Accuracy: 14.71%\n",
            "Epoch [2/13] - Train Loss: 1.4786\n",
            "Epoch [2/13] - Validation Loss: 1.3987, Accuracy: 16.04%\n",
            "Epoch [3/13] - Train Loss: 1.4631\n",
            "Epoch [3/13] - Validation Loss: 1.4010, Accuracy: 13.37%\n",
            "Epoch [4/13] - Train Loss: 1.4932\n",
            "Epoch [4/13] - Validation Loss: 1.3982, Accuracy: 15.24%\n",
            "Epoch [5/13] - Train Loss: 1.4608\n",
            "Epoch [5/13] - Validation Loss: 1.3900, Accuracy: 16.31%\n",
            "Epoch [6/13] - Train Loss: 1.4395\n",
            "Epoch [6/13] - Validation Loss: 1.3953, Accuracy: 22.46%\n",
            "Epoch [7/13] - Train Loss: 1.4585\n",
            "Epoch [7/13] - Validation Loss: 1.3853, Accuracy: 15.51%\n",
            "Epoch [8/13] - Train Loss: 1.4525\n",
            "Epoch [8/13] - Validation Loss: 1.3923, Accuracy: 22.73%\n",
            "Epoch [9/13] - Train Loss: 1.4361\n",
            "Epoch [9/13] - Validation Loss: 1.3840, Accuracy: 15.51%\n",
            "Epoch [10/13] - Train Loss: 1.4427\n",
            "Epoch [10/13] - Validation Loss: 1.3844, Accuracy: 17.91%\n",
            "Epoch [11/13] - Train Loss: 1.4326\n",
            "Epoch [11/13] - Validation Loss: 1.3847, Accuracy: 22.99%\n",
            "Epoch [12/13] - Train Loss: 1.4304\n",
            "Epoch [12/13] - Validation Loss: 1.3917, Accuracy: 15.51%\n",
            "Epoch [13/13] - Train Loss: 1.4156\n",
            "Epoch [13/13] - Validation Loss: 1.3831, Accuracy: 17.91%\n",
            "Epoch [1/18] - Train Loss: 1.5137\n",
            "Epoch [1/18] - Validation Loss: 1.3949, Accuracy: 12.57%\n",
            "Epoch [2/18] - Train Loss: 1.5034\n",
            "Epoch [2/18] - Validation Loss: 1.3905, Accuracy: 17.11%\n",
            "Epoch [3/18] - Train Loss: 1.4876\n",
            "Epoch [3/18] - Validation Loss: 1.3843, Accuracy: 25.13%\n",
            "Epoch [4/18] - Train Loss: 1.4969\n",
            "Epoch [4/18] - Validation Loss: 1.3972, Accuracy: 15.78%\n",
            "Epoch [5/18] - Train Loss: 1.4737\n",
            "Epoch [5/18] - Validation Loss: 1.3906, Accuracy: 15.51%\n",
            "Epoch [6/18] - Train Loss: 1.4587\n",
            "Epoch [6/18] - Validation Loss: 1.4006, Accuracy: 10.16%\n",
            "Epoch [7/18] - Train Loss: 1.4611\n",
            "Epoch [7/18] - Validation Loss: 1.3831, Accuracy: 18.18%\n",
            "Epoch [8/18] - Train Loss: 1.4317\n",
            "Epoch [8/18] - Validation Loss: 1.3834, Accuracy: 18.45%\n",
            "Epoch [9/18] - Train Loss: 1.4459\n",
            "Epoch [9/18] - Validation Loss: 1.3777, Accuracy: 18.72%\n",
            "Epoch [10/18] - Train Loss: 1.4232\n",
            "Epoch [10/18] - Validation Loss: 1.3830, Accuracy: 18.45%\n",
            "Epoch [11/18] - Train Loss: 1.4156\n",
            "Epoch [11/18] - Validation Loss: 1.3832, Accuracy: 18.45%\n",
            "Epoch [12/18] - Train Loss: 1.4340\n",
            "Epoch [12/18] - Validation Loss: 1.3743, Accuracy: 18.45%\n",
            "Epoch [13/18] - Train Loss: 1.4120\n",
            "Epoch [13/18] - Validation Loss: 1.3817, Accuracy: 16.04%\n",
            "Epoch [14/18] - Train Loss: 1.4162\n",
            "Epoch [14/18] - Validation Loss: 1.3739, Accuracy: 18.98%\n",
            "Epoch [15/18] - Train Loss: 1.4245\n",
            "Epoch [15/18] - Validation Loss: 1.3721, Accuracy: 18.98%\n",
            "Epoch [16/18] - Train Loss: 1.4104\n",
            "Epoch [16/18] - Validation Loss: 1.3704, Accuracy: 18.72%\n",
            "Epoch [17/18] - Train Loss: 1.4187\n",
            "Epoch [17/18] - Validation Loss: 1.3721, Accuracy: 18.18%\n",
            "Epoch [18/18] - Train Loss: 1.4062\n",
            "Epoch [18/18] - Validation Loss: 1.3731, Accuracy: 18.45%\n",
            "Epoch [1/13] - Train Loss: 1.8020\n",
            "Epoch [1/13] - Validation Loss: 1.3813, Accuracy: 24.06%\n",
            "Epoch [2/13] - Train Loss: 1.3781\n",
            "Epoch [2/13] - Validation Loss: 1.3597, Accuracy: 25.40%\n",
            "Epoch [3/13] - Train Loss: 1.3738\n",
            "Epoch [3/13] - Validation Loss: 1.3561, Accuracy: 23.53%\n",
            "Epoch [4/13] - Train Loss: 1.3568\n",
            "Epoch [4/13] - Validation Loss: 1.3629, Accuracy: 16.58%\n",
            "Epoch [5/13] - Train Loss: 1.3376\n",
            "Epoch [5/13] - Validation Loss: 1.3515, Accuracy: 17.65%\n",
            "Epoch [6/13] - Train Loss: 1.3391\n",
            "Epoch [6/13] - Validation Loss: 1.3467, Accuracy: 20.59%\n",
            "Epoch [7/13] - Train Loss: 1.3248\n",
            "Epoch [7/13] - Validation Loss: 1.3424, Accuracy: 18.45%\n",
            "Epoch [8/13] - Train Loss: 1.3232\n",
            "Epoch [8/13] - Validation Loss: 1.3384, Accuracy: 17.38%\n",
            "Epoch [9/13] - Train Loss: 1.3117\n",
            "Epoch [9/13] - Validation Loss: 1.3336, Accuracy: 18.98%\n",
            "Epoch [10/13] - Train Loss: 1.3122\n",
            "Epoch [10/13] - Validation Loss: 1.3420, Accuracy: 17.91%\n",
            "Epoch [11/13] - Train Loss: 1.3033\n",
            "Epoch [11/13] - Validation Loss: 1.3381, Accuracy: 19.25%\n",
            "Epoch [12/13] - Train Loss: 1.2976\n",
            "Epoch [12/13] - Validation Loss: 1.3107, Accuracy: 22.19%\n",
            "Epoch [13/13] - Train Loss: 1.2986\n",
            "Epoch [13/13] - Validation Loss: 1.3103, Accuracy: 22.46%\n",
            "Epoch [1/18] - Train Loss: 1.8251\n",
            "Epoch [1/18] - Validation Loss: 1.3769, Accuracy: 24.33%\n",
            "Epoch [2/18] - Train Loss: 1.3892\n",
            "Epoch [2/18] - Validation Loss: 1.3678, Accuracy: 17.11%\n",
            "Epoch [3/18] - Train Loss: 1.3630\n",
            "Epoch [3/18] - Validation Loss: 1.3559, Accuracy: 17.38%\n",
            "Epoch [4/18] - Train Loss: 1.3700\n",
            "Epoch [4/18] - Validation Loss: 1.3410, Accuracy: 19.25%\n",
            "Epoch [5/18] - Train Loss: 1.3569\n",
            "Epoch [5/18] - Validation Loss: 1.3371, Accuracy: 26.74%\n",
            "Epoch [6/18] - Train Loss: 1.3352\n",
            "Epoch [6/18] - Validation Loss: 1.3403, Accuracy: 41.44%\n",
            "Epoch [7/18] - Train Loss: 1.3257\n",
            "Epoch [7/18] - Validation Loss: 1.3301, Accuracy: 25.40%\n",
            "Epoch [8/18] - Train Loss: 1.3243\n",
            "Epoch [8/18] - Validation Loss: 1.3160, Accuracy: 24.33%\n",
            "Epoch [9/18] - Train Loss: 1.3096\n",
            "Epoch [9/18] - Validation Loss: 1.3156, Accuracy: 31.55%\n",
            "Epoch [10/18] - Train Loss: 1.3054\n",
            "Epoch [10/18] - Validation Loss: 1.3155, Accuracy: 21.12%\n",
            "Epoch [11/18] - Train Loss: 1.3019\n",
            "Epoch [11/18] - Validation Loss: 1.3078, Accuracy: 27.27%\n",
            "Epoch [12/18] - Train Loss: 1.2996\n",
            "Epoch [12/18] - Validation Loss: 1.3127, Accuracy: 27.54%\n",
            "Epoch [13/18] - Train Loss: 1.2844\n",
            "Epoch [13/18] - Validation Loss: 1.3135, Accuracy: 20.86%\n",
            "Epoch [14/18] - Train Loss: 1.2950\n",
            "Epoch [14/18] - Validation Loss: 1.3070, Accuracy: 20.86%\n",
            "Epoch [15/18] - Train Loss: 1.2925\n",
            "Epoch [15/18] - Validation Loss: 1.3235, Accuracy: 17.91%\n",
            "Epoch [16/18] - Train Loss: 1.2714\n",
            "Epoch [16/18] - Validation Loss: 1.3165, Accuracy: 20.59%\n",
            "Epoch [17/18] - Train Loss: 1.2754\n",
            "Epoch [17/18] - Validation Loss: 1.3138, Accuracy: 20.32%\n",
            "Epoch [18/18] - Train Loss: 1.2681\n",
            "Epoch [18/18] - Validation Loss: 1.3102, Accuracy: 20.05%\n",
            "Epoch [1/13] - Train Loss: 1.7314\n",
            "Epoch [1/13] - Validation Loss: 1.3982, Accuracy: 11.23%\n",
            "Epoch [2/13] - Train Loss: 1.3984\n",
            "Epoch [2/13] - Validation Loss: 1.3718, Accuracy: 23.80%\n",
            "Epoch [3/13] - Train Loss: 1.3743\n",
            "Epoch [3/13] - Validation Loss: 1.3493, Accuracy: 21.39%\n",
            "Epoch [4/13] - Train Loss: 1.3505\n",
            "Epoch [4/13] - Validation Loss: 1.3515, Accuracy: 21.66%\n",
            "Epoch [5/13] - Train Loss: 1.3399\n",
            "Epoch [5/13] - Validation Loss: 1.3454, Accuracy: 41.71%\n",
            "Epoch [6/13] - Train Loss: 1.3294\n",
            "Epoch [6/13] - Validation Loss: 1.3319, Accuracy: 43.32%\n",
            "Epoch [7/13] - Train Loss: 1.3109\n",
            "Epoch [7/13] - Validation Loss: 1.3321, Accuracy: 20.59%\n",
            "Epoch [8/13] - Train Loss: 1.3154\n",
            "Epoch [8/13] - Validation Loss: 1.3208, Accuracy: 21.66%\n",
            "Epoch [9/13] - Train Loss: 1.3010\n",
            "Epoch [9/13] - Validation Loss: 1.3157, Accuracy: 28.61%\n",
            "Epoch [10/13] - Train Loss: 1.2926\n",
            "Epoch [10/13] - Validation Loss: 1.3299, Accuracy: 24.60%\n",
            "Epoch [11/13] - Train Loss: 1.2972\n",
            "Epoch [11/13] - Validation Loss: 1.3241, Accuracy: 20.32%\n",
            "Epoch [12/13] - Train Loss: 1.2923\n",
            "Epoch [12/13] - Validation Loss: 1.3077, Accuracy: 21.12%\n",
            "Epoch [13/13] - Train Loss: 1.2834\n",
            "Epoch [13/13] - Validation Loss: 1.3174, Accuracy: 19.25%\n",
            "Epoch [1/18] - Train Loss: 1.6489\n",
            "Epoch [1/18] - Validation Loss: 1.3664, Accuracy: 23.53%\n",
            "Epoch [2/18] - Train Loss: 1.3874\n",
            "Epoch [2/18] - Validation Loss: 1.3528, Accuracy: 16.58%\n",
            "Epoch [3/18] - Train Loss: 1.3607\n",
            "Epoch [3/18] - Validation Loss: 1.3423, Accuracy: 18.45%\n",
            "Epoch [4/18] - Train Loss: 1.3405\n",
            "Epoch [4/18] - Validation Loss: 1.3379, Accuracy: 21.12%\n",
            "Epoch [5/18] - Train Loss: 1.3329\n",
            "Epoch [5/18] - Validation Loss: 1.3309, Accuracy: 25.94%\n",
            "Epoch [6/18] - Train Loss: 1.3086\n",
            "Epoch [6/18] - Validation Loss: 1.3507, Accuracy: 16.31%\n",
            "Epoch [7/18] - Train Loss: 1.3223\n",
            "Epoch [7/18] - Validation Loss: 1.3263, Accuracy: 18.98%\n",
            "Epoch [8/18] - Train Loss: 1.3068\n",
            "Epoch [8/18] - Validation Loss: 1.3084, Accuracy: 28.88%\n",
            "Epoch [9/18] - Train Loss: 1.2964\n",
            "Epoch [9/18] - Validation Loss: 1.3031, Accuracy: 20.59%\n",
            "Epoch [10/18] - Train Loss: 1.3000\n",
            "Epoch [10/18] - Validation Loss: 1.3070, Accuracy: 21.12%\n",
            "Epoch [11/18] - Train Loss: 1.2875\n",
            "Epoch [11/18] - Validation Loss: 1.3157, Accuracy: 18.98%\n",
            "Epoch [12/18] - Train Loss: 1.2816\n",
            "Epoch [12/18] - Validation Loss: 1.2997, Accuracy: 21.12%\n",
            "Epoch [13/18] - Train Loss: 1.2750\n",
            "Epoch [13/18] - Validation Loss: 1.3007, Accuracy: 21.39%\n",
            "Epoch [14/18] - Train Loss: 1.2834\n",
            "Epoch [14/18] - Validation Loss: 1.3035, Accuracy: 21.12%\n",
            "Epoch [15/18] - Train Loss: 1.2679\n",
            "Epoch [15/18] - Validation Loss: 1.2977, Accuracy: 21.39%\n",
            "Epoch [16/18] - Train Loss: 1.2704\n",
            "Epoch [16/18] - Validation Loss: 1.3164, Accuracy: 20.32%\n",
            "Epoch [17/18] - Train Loss: 1.2696\n",
            "Epoch [17/18] - Validation Loss: 1.2950, Accuracy: 21.39%\n",
            "Epoch [18/18] - Train Loss: 1.2576\n",
            "Epoch [18/18] - Validation Loss: 1.2978, Accuracy: 21.93%\n",
            "Epoch [1/13] - Train Loss: 1.5272\n",
            "Epoch [1/13] - Validation Loss: 1.3984, Accuracy: 12.03%\n",
            "Epoch [2/13] - Train Loss: 1.4916\n",
            "Epoch [2/13] - Validation Loss: 1.3834, Accuracy: 21.12%\n",
            "Epoch [3/13] - Train Loss: 1.4540\n",
            "Epoch [3/13] - Validation Loss: 1.3832, Accuracy: 13.90%\n",
            "Epoch [4/13] - Train Loss: 1.4509\n",
            "Epoch [4/13] - Validation Loss: 1.3798, Accuracy: 13.10%\n",
            "Epoch [5/13] - Train Loss: 1.4439\n",
            "Epoch [5/13] - Validation Loss: 1.3759, Accuracy: 15.78%\n",
            "Epoch [6/13] - Train Loss: 1.4134\n",
            "Epoch [6/13] - Validation Loss: 1.3760, Accuracy: 23.53%\n",
            "Epoch [7/13] - Train Loss: 1.4196\n",
            "Epoch [7/13] - Validation Loss: 1.3799, Accuracy: 22.99%\n",
            "Epoch [8/13] - Train Loss: 1.4054\n",
            "Epoch [8/13] - Validation Loss: 1.3679, Accuracy: 17.38%\n",
            "Epoch [9/13] - Train Loss: 1.4125\n",
            "Epoch [9/13] - Validation Loss: 1.3665, Accuracy: 17.38%\n",
            "Epoch [10/13] - Train Loss: 1.3888\n",
            "Epoch [10/13] - Validation Loss: 1.3747, Accuracy: 23.53%\n",
            "Epoch [11/13] - Train Loss: 1.3919\n",
            "Epoch [11/13] - Validation Loss: 1.3622, Accuracy: 20.05%\n",
            "Epoch [12/13] - Train Loss: 1.3907\n",
            "Epoch [12/13] - Validation Loss: 1.3603, Accuracy: 19.25%\n",
            "Epoch [13/13] - Train Loss: 1.3851\n",
            "Epoch [13/13] - Validation Loss: 1.3594, Accuracy: 18.98%\n",
            "Epoch [1/18] - Train Loss: 1.4918\n",
            "Epoch [1/18] - Validation Loss: 1.3859, Accuracy: 15.24%\n",
            "Epoch [2/18] - Train Loss: 1.4576\n",
            "Epoch [2/18] - Validation Loss: 1.3937, Accuracy: 14.71%\n",
            "Epoch [3/18] - Train Loss: 1.4449\n",
            "Epoch [3/18] - Validation Loss: 1.3740, Accuracy: 18.45%\n",
            "Epoch [4/18] - Train Loss: 1.4291\n",
            "Epoch [4/18] - Validation Loss: 1.3848, Accuracy: 13.90%\n",
            "Epoch [5/18] - Train Loss: 1.4292\n",
            "Epoch [5/18] - Validation Loss: 1.3717, Accuracy: 17.11%\n",
            "Epoch [6/18] - Train Loss: 1.4206\n",
            "Epoch [6/18] - Validation Loss: 1.3687, Accuracy: 16.31%\n",
            "Epoch [7/18] - Train Loss: 1.4049\n",
            "Epoch [7/18] - Validation Loss: 1.3693, Accuracy: 24.33%\n",
            "Epoch [8/18] - Train Loss: 1.4025\n",
            "Epoch [8/18] - Validation Loss: 1.3673, Accuracy: 18.72%\n",
            "Epoch [9/18] - Train Loss: 1.3935\n",
            "Epoch [9/18] - Validation Loss: 1.3630, Accuracy: 19.25%\n",
            "Epoch [10/18] - Train Loss: 1.3881\n",
            "Epoch [10/18] - Validation Loss: 1.3601, Accuracy: 18.98%\n",
            "Epoch [11/18] - Train Loss: 1.3885\n",
            "Epoch [11/18] - Validation Loss: 1.3611, Accuracy: 18.72%\n",
            "Epoch [12/18] - Train Loss: 1.3745\n",
            "Epoch [12/18] - Validation Loss: 1.3622, Accuracy: 18.72%\n",
            "Epoch [13/18] - Train Loss: 1.3857\n",
            "Epoch [13/18] - Validation Loss: 1.3620, Accuracy: 18.45%\n",
            "Epoch [14/18] - Train Loss: 1.3752\n",
            "Epoch [14/18] - Validation Loss: 1.3603, Accuracy: 18.72%\n",
            "Epoch [15/18] - Train Loss: 1.3699\n",
            "Epoch [15/18] - Validation Loss: 1.3570, Accuracy: 18.72%\n",
            "Epoch [16/18] - Train Loss: 1.3682\n",
            "Epoch [16/18] - Validation Loss: 1.3593, Accuracy: 18.45%\n",
            "Epoch [17/18] - Train Loss: 1.3650\n",
            "Epoch [17/18] - Validation Loss: 1.3534, Accuracy: 19.79%\n",
            "Epoch [18/18] - Train Loss: 1.3741\n",
            "Epoch [18/18] - Validation Loss: 1.3543, Accuracy: 19.25%\n",
            "Epoch [1/13] - Train Loss: 1.5250\n",
            "Epoch [1/13] - Validation Loss: 1.3992, Accuracy: 17.65%\n",
            "Epoch [2/13] - Train Loss: 1.4789\n",
            "Epoch [2/13] - Validation Loss: 1.3937, Accuracy: 18.98%\n",
            "Epoch [3/13] - Train Loss: 1.4624\n",
            "Epoch [3/13] - Validation Loss: 1.3896, Accuracy: 19.79%\n",
            "Epoch [4/13] - Train Loss: 1.4436\n",
            "Epoch [4/13] - Validation Loss: 1.3876, Accuracy: 12.83%\n",
            "Epoch [5/13] - Train Loss: 1.4415\n",
            "Epoch [5/13] - Validation Loss: 1.3895, Accuracy: 14.71%\n",
            "Epoch [6/13] - Train Loss: 1.4356\n",
            "Epoch [6/13] - Validation Loss: 1.3909, Accuracy: 14.17%\n",
            "Epoch [7/13] - Train Loss: 1.4109\n",
            "Epoch [7/13] - Validation Loss: 1.3844, Accuracy: 14.17%\n",
            "Epoch [8/13] - Train Loss: 1.4311\n",
            "Epoch [8/13] - Validation Loss: 1.3778, Accuracy: 15.51%\n",
            "Epoch [9/13] - Train Loss: 1.4040\n",
            "Epoch [9/13] - Validation Loss: 1.3745, Accuracy: 17.11%\n",
            "Epoch [10/13] - Train Loss: 1.4010\n",
            "Epoch [10/13] - Validation Loss: 1.3766, Accuracy: 16.31%\n",
            "Epoch [11/13] - Train Loss: 1.3918\n",
            "Epoch [11/13] - Validation Loss: 1.3723, Accuracy: 18.18%\n",
            "Epoch [12/13] - Train Loss: 1.4001\n",
            "Epoch [12/13] - Validation Loss: 1.3761, Accuracy: 16.84%\n",
            "Epoch [13/13] - Train Loss: 1.3977\n",
            "Epoch [13/13] - Validation Loss: 1.3748, Accuracy: 15.78%\n",
            "Epoch [1/18] - Train Loss: 1.4908\n",
            "Epoch [1/18] - Validation Loss: 1.4066, Accuracy: 8.82%\n",
            "Epoch [2/18] - Train Loss: 1.4776\n",
            "Epoch [2/18] - Validation Loss: 1.3988, Accuracy: 10.96%\n",
            "Epoch [3/18] - Train Loss: 1.4572\n",
            "Epoch [3/18] - Validation Loss: 1.3944, Accuracy: 23.80%\n",
            "Epoch [4/18] - Train Loss: 1.4597\n",
            "Epoch [4/18] - Validation Loss: 1.3884, Accuracy: 17.65%\n",
            "Epoch [5/18] - Train Loss: 1.4392\n",
            "Epoch [5/18] - Validation Loss: 1.3842, Accuracy: 18.18%\n",
            "Epoch [6/18] - Train Loss: 1.4421\n",
            "Epoch [6/18] - Validation Loss: 1.3822, Accuracy: 16.04%\n",
            "Epoch [7/18] - Train Loss: 1.4262\n",
            "Epoch [7/18] - Validation Loss: 1.3791, Accuracy: 18.45%\n",
            "Epoch [8/18] - Train Loss: 1.4265\n",
            "Epoch [8/18] - Validation Loss: 1.3749, Accuracy: 20.05%\n",
            "Epoch [9/18] - Train Loss: 1.4107\n",
            "Epoch [9/18] - Validation Loss: 1.3749, Accuracy: 18.72%\n",
            "Epoch [10/18] - Train Loss: 1.4089\n",
            "Epoch [10/18] - Validation Loss: 1.3760, Accuracy: 18.45%\n",
            "Epoch [11/18] - Train Loss: 1.3979\n",
            "Epoch [11/18] - Validation Loss: 1.3673, Accuracy: 20.86%\n",
            "Epoch [12/18] - Train Loss: 1.4069\n",
            "Epoch [12/18] - Validation Loss: 1.3722, Accuracy: 18.18%\n",
            "Epoch [13/18] - Train Loss: 1.3972\n",
            "Epoch [13/18] - Validation Loss: 1.3698, Accuracy: 19.25%\n",
            "Epoch [14/18] - Train Loss: 1.4037\n",
            "Epoch [14/18] - Validation Loss: 1.3690, Accuracy: 19.52%\n",
            "Epoch [15/18] - Train Loss: 1.3850\n",
            "Epoch [15/18] - Validation Loss: 1.3644, Accuracy: 19.79%\n",
            "Epoch [16/18] - Train Loss: 1.3792\n",
            "Epoch [16/18] - Validation Loss: 1.3665, Accuracy: 18.72%\n",
            "Epoch [17/18] - Train Loss: 1.3816\n",
            "Epoch [17/18] - Validation Loss: 1.3623, Accuracy: 18.98%\n",
            "Epoch [18/18] - Train Loss: 1.3875\n",
            "Epoch [18/18] - Validation Loss: 1.3649, Accuracy: 18.98%\n",
            "Epoch [1/13] - Train Loss: 9.1252\n",
            "Epoch [1/13] - Validation Loss: 1.4075, Accuracy: 10.96%\n",
            "Epoch [2/13] - Train Loss: 1.3828\n",
            "Epoch [2/13] - Validation Loss: 1.3610, Accuracy: 13.10%\n",
            "Epoch [3/13] - Train Loss: 1.3650\n",
            "Epoch [3/13] - Validation Loss: 1.3623, Accuracy: 18.98%\n",
            "Epoch [4/13] - Train Loss: 1.3376\n",
            "Epoch [4/13] - Validation Loss: 1.3614, Accuracy: 19.25%\n",
            "Epoch [5/13] - Train Loss: 1.3336\n",
            "Epoch [5/13] - Validation Loss: 1.3590, Accuracy: 17.38%\n",
            "Epoch [6/13] - Train Loss: 1.3107\n",
            "Epoch [6/13] - Validation Loss: 1.3514, Accuracy: 20.59%\n",
            "Epoch [7/13] - Train Loss: 1.3139\n",
            "Epoch [7/13] - Validation Loss: 1.3700, Accuracy: 20.32%\n",
            "Epoch [8/13] - Train Loss: 1.3198\n",
            "Epoch [8/13] - Validation Loss: 1.3362, Accuracy: 17.91%\n",
            "Epoch [9/13] - Train Loss: 1.2953\n",
            "Epoch [9/13] - Validation Loss: 1.3471, Accuracy: 17.65%\n",
            "Epoch [10/13] - Train Loss: 1.2838\n",
            "Epoch [10/13] - Validation Loss: 1.3291, Accuracy: 17.65%\n",
            "Epoch [11/13] - Train Loss: 1.2812\n",
            "Epoch [11/13] - Validation Loss: 1.3603, Accuracy: 17.11%\n",
            "Epoch [12/13] - Train Loss: 1.2759\n",
            "Epoch [12/13] - Validation Loss: 1.3235, Accuracy: 17.91%\n",
            "Epoch [13/13] - Train Loss: 1.2734\n",
            "Epoch [13/13] - Validation Loss: 1.3165, Accuracy: 18.18%\n",
            "Epoch [1/18] - Train Loss: 13.2359\n",
            "Epoch [1/18] - Validation Loss: 1.4337, Accuracy: 17.11%\n",
            "Epoch [2/18] - Train Loss: 1.4575\n",
            "Epoch [2/18] - Validation Loss: 1.3952, Accuracy: 15.78%\n",
            "Epoch [3/18] - Train Loss: 1.3843\n",
            "Epoch [3/18] - Validation Loss: 1.3602, Accuracy: 12.83%\n",
            "Epoch [4/18] - Train Loss: 1.3655\n",
            "Epoch [4/18] - Validation Loss: 1.3569, Accuracy: 13.64%\n",
            "Epoch [5/18] - Train Loss: 1.3379\n",
            "Epoch [5/18] - Validation Loss: 1.3448, Accuracy: 14.17%\n",
            "Epoch [6/18] - Train Loss: 1.3470\n",
            "Epoch [6/18] - Validation Loss: 1.3723, Accuracy: 22.73%\n",
            "Epoch [7/18] - Train Loss: 1.3294\n",
            "Epoch [7/18] - Validation Loss: 1.3620, Accuracy: 14.71%\n",
            "Epoch [8/18] - Train Loss: 1.3185\n",
            "Epoch [8/18] - Validation Loss: 1.4688, Accuracy: 36.63%\n",
            "Epoch [9/18] - Train Loss: 1.3215\n",
            "Epoch [9/18] - Validation Loss: 1.3490, Accuracy: 16.04%\n",
            "Epoch [10/18] - Train Loss: 1.3270\n",
            "Epoch [10/18] - Validation Loss: 1.3746, Accuracy: 14.97%\n",
            "Epoch [11/18] - Train Loss: 1.2951\n",
            "Epoch [11/18] - Validation Loss: 1.3471, Accuracy: 14.71%\n",
            "Epoch [12/18] - Train Loss: 1.3078\n",
            "Epoch [12/18] - Validation Loss: 1.3383, Accuracy: 16.58%\n",
            "Epoch [13/18] - Train Loss: 1.2972\n",
            "Epoch [13/18] - Validation Loss: 1.3418, Accuracy: 17.38%\n",
            "Epoch [14/18] - Train Loss: 1.2812\n",
            "Epoch [14/18] - Validation Loss: 1.3398, Accuracy: 20.32%\n",
            "Epoch [15/18] - Train Loss: 1.2861\n",
            "Epoch [15/18] - Validation Loss: 1.3475, Accuracy: 16.84%\n",
            "Epoch [16/18] - Train Loss: 1.2914\n",
            "Epoch [16/18] - Validation Loss: 1.3385, Accuracy: 16.84%\n",
            "Epoch [17/18] - Train Loss: 1.2777\n",
            "Epoch [17/18] - Validation Loss: 1.3347, Accuracy: 16.58%\n",
            "Epoch [18/18] - Train Loss: 1.2792\n",
            "Epoch [18/18] - Validation Loss: 1.3346, Accuracy: 19.25%\n",
            "Epoch [1/13] - Train Loss: 8.9050\n",
            "Epoch [1/13] - Validation Loss: 1.3922, Accuracy: 25.67%\n",
            "Epoch [2/13] - Train Loss: 1.3966\n",
            "Epoch [2/13] - Validation Loss: 1.3715, Accuracy: 12.30%\n",
            "Epoch [3/13] - Train Loss: 1.3661\n",
            "Epoch [3/13] - Validation Loss: 1.3709, Accuracy: 22.19%\n",
            "Epoch [4/13] - Train Loss: 1.3429\n",
            "Epoch [4/13] - Validation Loss: 1.3423, Accuracy: 16.84%\n",
            "Epoch [5/13] - Train Loss: 1.3434\n",
            "Epoch [5/13] - Validation Loss: 1.3727, Accuracy: 14.44%\n",
            "Epoch [6/13] - Train Loss: 1.3189\n",
            "Epoch [6/13] - Validation Loss: 1.3513, Accuracy: 16.31%\n",
            "Epoch [7/13] - Train Loss: 1.3101\n",
            "Epoch [7/13] - Validation Loss: 1.3279, Accuracy: 20.05%\n",
            "Epoch [8/13] - Train Loss: 1.2786\n",
            "Epoch [8/13] - Validation Loss: 1.3373, Accuracy: 18.45%\n",
            "Epoch [9/13] - Train Loss: 1.2873\n",
            "Epoch [9/13] - Validation Loss: 1.3348, Accuracy: 17.91%\n",
            "Epoch [10/13] - Train Loss: 1.2875\n",
            "Epoch [10/13] - Validation Loss: 1.3171, Accuracy: 19.79%\n",
            "Epoch [11/13] - Train Loss: 1.2807\n",
            "Epoch [11/13] - Validation Loss: 1.3328, Accuracy: 19.52%\n",
            "Epoch [12/13] - Train Loss: 1.2648\n",
            "Epoch [12/13] - Validation Loss: 1.3134, Accuracy: 19.25%\n",
            "Epoch [13/13] - Train Loss: 1.2738\n",
            "Epoch [13/13] - Validation Loss: 1.3024, Accuracy: 18.72%\n",
            "Epoch [1/18] - Train Loss: 7.0150\n",
            "Epoch [1/18] - Validation Loss: 1.4133, Accuracy: 13.64%\n",
            "Epoch [2/18] - Train Loss: 1.3717\n",
            "Epoch [2/18] - Validation Loss: 1.3537, Accuracy: 15.51%\n",
            "Epoch [3/18] - Train Loss: 1.3388\n",
            "Epoch [3/18] - Validation Loss: 1.3691, Accuracy: 14.97%\n",
            "Epoch [4/18] - Train Loss: 1.3303\n",
            "Epoch [4/18] - Validation Loss: 1.3581, Accuracy: 16.04%\n",
            "Epoch [5/18] - Train Loss: 1.3131\n",
            "Epoch [5/18] - Validation Loss: 1.3327, Accuracy: 17.11%\n",
            "Epoch [6/18] - Train Loss: 1.3178\n",
            "Epoch [6/18] - Validation Loss: 1.3796, Accuracy: 25.13%\n",
            "Epoch [7/18] - Train Loss: 1.3296\n",
            "Epoch [7/18] - Validation Loss: 1.3235, Accuracy: 31.28%\n",
            "Epoch [8/18] - Train Loss: 1.2923\n",
            "Epoch [8/18] - Validation Loss: 1.3481, Accuracy: 17.38%\n",
            "Epoch [9/18] - Train Loss: 1.2852\n",
            "Epoch [9/18] - Validation Loss: 1.3788, Accuracy: 15.24%\n",
            "Epoch [10/18] - Train Loss: 1.2861\n",
            "Epoch [10/18] - Validation Loss: 1.3358, Accuracy: 19.25%\n",
            "Epoch [11/18] - Train Loss: 1.2744\n",
            "Epoch [11/18] - Validation Loss: 1.3310, Accuracy: 19.52%\n",
            "Epoch [12/18] - Train Loss: 1.2707\n",
            "Epoch [12/18] - Validation Loss: 1.3351, Accuracy: 19.25%\n",
            "Epoch [13/18] - Train Loss: 1.2606\n",
            "Epoch [13/18] - Validation Loss: 1.3158, Accuracy: 18.98%\n",
            "Epoch [14/18] - Train Loss: 1.2514\n",
            "Epoch [14/18] - Validation Loss: 1.3465, Accuracy: 19.79%\n",
            "Epoch [15/18] - Train Loss: 1.2654\n",
            "Epoch [15/18] - Validation Loss: 1.3516, Accuracy: 17.38%\n",
            "Epoch [16/18] - Train Loss: 1.2457\n",
            "Epoch [16/18] - Validation Loss: 1.3032, Accuracy: 22.19%\n",
            "Epoch [17/18] - Train Loss: 1.2514\n",
            "Epoch [17/18] - Validation Loss: 1.3147, Accuracy: 19.79%\n",
            "Epoch [18/18] - Train Loss: 1.2489\n",
            "Epoch [18/18] - Validation Loss: 1.3181, Accuracy: 20.32%\n",
            "Epoch [1/13] - Train Loss: 1.4436\n",
            "Epoch [1/13] - Validation Loss: 1.4198, Accuracy: 26.47%\n",
            "Epoch [2/13] - Train Loss: 1.4062\n",
            "Epoch [2/13] - Validation Loss: 1.4447, Accuracy: 10.96%\n",
            "Epoch [3/13] - Train Loss: 1.3820\n",
            "Epoch [3/13] - Validation Loss: 1.4276, Accuracy: 28.88%\n",
            "Epoch [4/13] - Train Loss: 1.3853\n",
            "Epoch [4/13] - Validation Loss: 1.3543, Accuracy: 28.07%\n",
            "Epoch [5/13] - Train Loss: 1.3707\n",
            "Epoch [5/13] - Validation Loss: 1.3735, Accuracy: 23.53%\n",
            "Epoch [6/13] - Train Loss: 1.3563\n",
            "Epoch [6/13] - Validation Loss: 1.4544, Accuracy: 10.70%\n",
            "Epoch [7/13] - Train Loss: 1.3461\n",
            "Epoch [7/13] - Validation Loss: 1.3600, Accuracy: 27.54%\n",
            "Epoch [8/13] - Train Loss: 1.3419\n",
            "Epoch [8/13] - Validation Loss: 1.3391, Accuracy: 27.54%\n",
            "Epoch [9/13] - Train Loss: 1.3234\n",
            "Epoch [9/13] - Validation Loss: 1.3949, Accuracy: 14.71%\n",
            "Epoch [10/13] - Train Loss: 1.3254\n",
            "Epoch [10/13] - Validation Loss: 1.4380, Accuracy: 24.60%\n",
            "Epoch [11/13] - Train Loss: 1.3229\n",
            "Epoch [11/13] - Validation Loss: 1.3535, Accuracy: 46.79%\n",
            "Epoch [12/13] - Train Loss: 1.3091\n",
            "Epoch [12/13] - Validation Loss: 1.3406, Accuracy: 19.79%\n",
            "Epoch [13/13] - Train Loss: 1.3052\n",
            "Epoch [13/13] - Validation Loss: 1.3317, Accuracy: 25.40%\n",
            "Epoch [1/18] - Train Loss: 1.4658\n",
            "Epoch [1/18] - Validation Loss: 1.5315, Accuracy: 23.80%\n",
            "Epoch [2/18] - Train Loss: 1.4163\n",
            "Epoch [2/18] - Validation Loss: 1.4582, Accuracy: 39.84%\n",
            "Epoch [3/18] - Train Loss: 1.3767\n",
            "Epoch [3/18] - Validation Loss: 1.4115, Accuracy: 40.64%\n",
            "Epoch [4/18] - Train Loss: 1.3673\n",
            "Epoch [4/18] - Validation Loss: 1.4429, Accuracy: 28.34%\n",
            "Epoch [5/18] - Train Loss: 1.3639\n",
            "Epoch [5/18] - Validation Loss: 1.3433, Accuracy: 43.58%\n",
            "Epoch [6/18] - Train Loss: 1.3517\n",
            "Epoch [6/18] - Validation Loss: 1.3641, Accuracy: 19.25%\n",
            "Epoch [7/18] - Train Loss: 1.3380\n",
            "Epoch [7/18] - Validation Loss: 1.3981, Accuracy: 25.13%\n",
            "Epoch [8/18] - Train Loss: 1.3385\n",
            "Epoch [8/18] - Validation Loss: 1.3580, Accuracy: 27.81%\n",
            "Epoch [9/18] - Train Loss: 1.3369\n",
            "Epoch [9/18] - Validation Loss: 1.3803, Accuracy: 25.67%\n",
            "Epoch [10/18] - Train Loss: 1.3271\n",
            "Epoch [10/18] - Validation Loss: 1.3794, Accuracy: 18.18%\n",
            "Epoch [11/18] - Train Loss: 1.3222\n",
            "Epoch [11/18] - Validation Loss: 1.3434, Accuracy: 20.05%\n",
            "Epoch [12/18] - Train Loss: 1.3119\n",
            "Epoch [12/18] - Validation Loss: 1.3270, Accuracy: 29.95%\n",
            "Epoch [13/18] - Train Loss: 1.3069\n",
            "Epoch [13/18] - Validation Loss: 1.3493, Accuracy: 18.72%\n",
            "Epoch [14/18] - Train Loss: 1.3065\n",
            "Epoch [14/18] - Validation Loss: 1.3416, Accuracy: 20.05%\n",
            "Epoch [15/18] - Train Loss: 1.2998\n",
            "Epoch [15/18] - Validation Loss: 1.3407, Accuracy: 25.40%\n",
            "Epoch [16/18] - Train Loss: 1.2989\n",
            "Epoch [16/18] - Validation Loss: 1.3207, Accuracy: 25.94%\n",
            "Epoch [17/18] - Train Loss: 1.2876\n",
            "Epoch [17/18] - Validation Loss: 1.3672, Accuracy: 18.98%\n",
            "Epoch [18/18] - Train Loss: 1.2833\n",
            "Epoch [18/18] - Validation Loss: 1.3276, Accuracy: 21.12%\n",
            "Epoch [1/13] - Train Loss: 1.4306\n",
            "Epoch [1/13] - Validation Loss: 1.5110, Accuracy: 7.49%\n",
            "Epoch [2/13] - Train Loss: 1.4297\n",
            "Epoch [2/13] - Validation Loss: 1.3830, Accuracy: 24.06%\n",
            "Epoch [3/13] - Train Loss: 1.3939\n",
            "Epoch [3/13] - Validation Loss: 1.6870, Accuracy: 7.49%\n",
            "Epoch [4/13] - Train Loss: 1.3976\n",
            "Epoch [4/13] - Validation Loss: 1.4057, Accuracy: 23.80%\n",
            "Epoch [5/13] - Train Loss: 1.3773\n",
            "Epoch [5/13] - Validation Loss: 1.4676, Accuracy: 26.47%\n",
            "Epoch [6/13] - Train Loss: 1.3797\n",
            "Epoch [6/13] - Validation Loss: 1.3708, Accuracy: 23.80%\n",
            "Epoch [7/13] - Train Loss: 1.3564\n",
            "Epoch [7/13] - Validation Loss: 1.3966, Accuracy: 13.10%\n",
            "Epoch [8/13] - Train Loss: 1.3541\n",
            "Epoch [8/13] - Validation Loss: 1.3602, Accuracy: 27.81%\n",
            "Epoch [9/13] - Train Loss: 1.3507\n",
            "Epoch [9/13] - Validation Loss: 1.3492, Accuracy: 25.40%\n",
            "Epoch [10/13] - Train Loss: 1.3324\n",
            "Epoch [10/13] - Validation Loss: 1.3745, Accuracy: 40.91%\n",
            "Epoch [11/13] - Train Loss: 1.3357\n",
            "Epoch [11/13] - Validation Loss: 1.3381, Accuracy: 28.88%\n",
            "Epoch [12/13] - Train Loss: 1.3332\n",
            "Epoch [12/13] - Validation Loss: 1.3681, Accuracy: 25.13%\n",
            "Epoch [13/13] - Train Loss: 1.3262\n",
            "Epoch [13/13] - Validation Loss: 1.3511, Accuracy: 18.72%\n",
            "Epoch [1/18] - Train Loss: 1.4393\n",
            "Epoch [1/18] - Validation Loss: 1.4389, Accuracy: 28.34%\n",
            "Epoch [2/18] - Train Loss: 1.4264\n",
            "Epoch [2/18] - Validation Loss: 1.4111, Accuracy: 13.64%\n",
            "Epoch [3/18] - Train Loss: 1.3959\n",
            "Epoch [3/18] - Validation Loss: 1.3792, Accuracy: 16.84%\n",
            "Epoch [4/18] - Train Loss: 1.3846\n",
            "Epoch [4/18] - Validation Loss: 1.5422, Accuracy: 23.80%\n",
            "Epoch [5/18] - Train Loss: 1.3717\n",
            "Epoch [5/18] - Validation Loss: 1.4149, Accuracy: 19.52%\n",
            "Epoch [6/18] - Train Loss: 1.3664\n",
            "Epoch [6/18] - Validation Loss: 1.4287, Accuracy: 14.44%\n",
            "Epoch [7/18] - Train Loss: 1.3626\n",
            "Epoch [7/18] - Validation Loss: 1.3827, Accuracy: 23.80%\n",
            "Epoch [8/18] - Train Loss: 1.3597\n",
            "Epoch [8/18] - Validation Loss: 1.3703, Accuracy: 28.61%\n",
            "Epoch [9/18] - Train Loss: 1.3519\n",
            "Epoch [9/18] - Validation Loss: 1.3961, Accuracy: 14.17%\n",
            "Epoch [10/18] - Train Loss: 1.3615\n",
            "Epoch [10/18] - Validation Loss: 1.3995, Accuracy: 24.87%\n",
            "Epoch [11/18] - Train Loss: 1.3490\n",
            "Epoch [11/18] - Validation Loss: 1.3577, Accuracy: 21.39%\n",
            "Epoch [12/18] - Train Loss: 1.3385\n",
            "Epoch [12/18] - Validation Loss: 1.3395, Accuracy: 25.13%\n",
            "Epoch [13/18] - Train Loss: 1.3344\n",
            "Epoch [13/18] - Validation Loss: 1.3525, Accuracy: 19.25%\n",
            "Epoch [14/18] - Train Loss: 1.3237\n",
            "Epoch [14/18] - Validation Loss: 1.3688, Accuracy: 18.98%\n",
            "Epoch [15/18] - Train Loss: 1.3198\n",
            "Epoch [15/18] - Validation Loss: 1.3615, Accuracy: 26.47%\n",
            "Epoch [16/18] - Train Loss: 1.3194\n",
            "Epoch [16/18] - Validation Loss: 1.3703, Accuracy: 18.72%\n",
            "Epoch [17/18] - Train Loss: 1.3153\n",
            "Epoch [17/18] - Validation Loss: 1.3423, Accuracy: 23.53%\n",
            "Epoch [18/18] - Train Loss: 1.3068\n",
            "Epoch [18/18] - Validation Loss: 1.3248, Accuracy: 25.67%\n",
            "Epoch [1/13] - Train Loss: 6.2861\n",
            "Epoch [1/13] - Validation Loss: 1.3786, Accuracy: 22.73%\n",
            "Epoch [2/13] - Train Loss: 1.3893\n",
            "Epoch [2/13] - Validation Loss: 1.3578, Accuracy: 12.83%\n",
            "Epoch [3/13] - Train Loss: 1.3613\n",
            "Epoch [3/13] - Validation Loss: 1.3538, Accuracy: 13.64%\n",
            "Epoch [4/13] - Train Loss: 1.3468\n",
            "Epoch [4/13] - Validation Loss: 1.3866, Accuracy: 12.57%\n",
            "Epoch [5/13] - Train Loss: 1.3390\n",
            "Epoch [5/13] - Validation Loss: 1.3652, Accuracy: 12.30%\n",
            "Epoch [6/13] - Train Loss: 1.3287\n",
            "Epoch [6/13] - Validation Loss: 1.3662, Accuracy: 14.71%\n",
            "Epoch [7/13] - Train Loss: 1.3640\n",
            "Epoch [7/13] - Validation Loss: 1.3473, Accuracy: 15.51%\n",
            "Epoch [8/13] - Train Loss: 1.3213\n",
            "Epoch [8/13] - Validation Loss: 1.3412, Accuracy: 15.51%\n",
            "Epoch [9/13] - Train Loss: 1.3189\n",
            "Epoch [9/13] - Validation Loss: 1.3671, Accuracy: 14.97%\n",
            "Epoch [10/13] - Train Loss: 1.3285\n",
            "Epoch [10/13] - Validation Loss: 1.3437, Accuracy: 14.44%\n",
            "Epoch [11/13] - Train Loss: 1.3137\n",
            "Epoch [11/13] - Validation Loss: 1.3298, Accuracy: 17.11%\n",
            "Epoch [12/13] - Train Loss: 1.2997\n",
            "Epoch [12/13] - Validation Loss: 1.3401, Accuracy: 15.51%\n",
            "Epoch [13/13] - Train Loss: 1.3052\n",
            "Epoch [13/13] - Validation Loss: 1.3545, Accuracy: 16.04%\n",
            "Epoch [1/18] - Train Loss: 7.0667\n",
            "Epoch [1/18] - Validation Loss: 1.3793, Accuracy: 10.96%\n",
            "Epoch [2/18] - Train Loss: 1.3796\n",
            "Epoch [2/18] - Validation Loss: 1.3759, Accuracy: 13.10%\n",
            "Epoch [3/18] - Train Loss: 1.3769\n",
            "Epoch [3/18] - Validation Loss: 1.3651, Accuracy: 12.83%\n",
            "Epoch [4/18] - Train Loss: 1.3481\n",
            "Epoch [4/18] - Validation Loss: 1.3606, Accuracy: 13.10%\n",
            "Epoch [5/18] - Train Loss: 1.3268\n",
            "Epoch [5/18] - Validation Loss: 1.3479, Accuracy: 13.90%\n",
            "Epoch [6/18] - Train Loss: 1.3296\n",
            "Epoch [6/18] - Validation Loss: 1.3589, Accuracy: 13.64%\n",
            "Epoch [7/18] - Train Loss: 1.3183\n",
            "Epoch [7/18] - Validation Loss: 1.3542, Accuracy: 13.37%\n",
            "Epoch [8/18] - Train Loss: 1.3136\n",
            "Epoch [8/18] - Validation Loss: 1.3648, Accuracy: 14.71%\n",
            "Epoch [9/18] - Train Loss: 1.3108\n",
            "Epoch [9/18] - Validation Loss: 1.3179, Accuracy: 15.78%\n",
            "Epoch [10/18] - Train Loss: 1.3173\n",
            "Epoch [10/18] - Validation Loss: 1.3310, Accuracy: 16.58%\n",
            "Epoch [11/18] - Train Loss: 1.3003\n",
            "Epoch [11/18] - Validation Loss: 1.3800, Accuracy: 15.51%\n",
            "Epoch [12/18] - Train Loss: 1.3153\n",
            "Epoch [12/18] - Validation Loss: 1.3361, Accuracy: 16.84%\n",
            "Epoch [13/18] - Train Loss: 1.2952\n",
            "Epoch [13/18] - Validation Loss: 1.3464, Accuracy: 17.91%\n",
            "Epoch [14/18] - Train Loss: 1.3017\n",
            "Epoch [14/18] - Validation Loss: 1.3336, Accuracy: 15.78%\n",
            "Epoch [15/18] - Train Loss: 1.2926\n",
            "Epoch [15/18] - Validation Loss: 1.3426, Accuracy: 17.38%\n",
            "Epoch [16/18] - Train Loss: 1.2940\n",
            "Epoch [16/18] - Validation Loss: 1.3401, Accuracy: 17.38%\n",
            "Epoch [17/18] - Train Loss: 1.2979\n",
            "Epoch [17/18] - Validation Loss: 1.3302, Accuracy: 16.84%\n",
            "Epoch [18/18] - Train Loss: 1.3457\n",
            "Epoch [18/18] - Validation Loss: 1.3244, Accuracy: 17.11%\n",
            "Epoch [1/13] - Train Loss: 4.6021\n",
            "Epoch [1/13] - Validation Loss: 1.3700, Accuracy: 10.43%\n",
            "Epoch [2/13] - Train Loss: 1.3720\n",
            "Epoch [2/13] - Validation Loss: 1.3502, Accuracy: 17.38%\n",
            "Epoch [3/13] - Train Loss: 1.3644\n",
            "Epoch [3/13] - Validation Loss: 1.3466, Accuracy: 13.90%\n",
            "Epoch [4/13] - Train Loss: 1.3364\n",
            "Epoch [4/13] - Validation Loss: 1.3542, Accuracy: 16.04%\n",
            "Epoch [5/13] - Train Loss: 1.3292\n",
            "Epoch [5/13] - Validation Loss: 1.3597, Accuracy: 15.51%\n",
            "Epoch [6/13] - Train Loss: 1.3281\n",
            "Epoch [6/13] - Validation Loss: 1.3501, Accuracy: 15.51%\n",
            "Epoch [7/13] - Train Loss: 1.3135\n",
            "Epoch [7/13] - Validation Loss: 1.3703, Accuracy: 16.04%\n",
            "Epoch [8/13] - Train Loss: 1.3012\n",
            "Epoch [8/13] - Validation Loss: 1.3348, Accuracy: 28.34%\n",
            "Epoch [9/13] - Train Loss: 1.2962\n",
            "Epoch [9/13] - Validation Loss: 1.3547, Accuracy: 17.11%\n",
            "Epoch [10/13] - Train Loss: 1.3090\n",
            "Epoch [10/13] - Validation Loss: 1.3236, Accuracy: 17.38%\n",
            "Epoch [11/13] - Train Loss: 1.2897\n",
            "Epoch [11/13] - Validation Loss: 1.3309, Accuracy: 17.11%\n",
            "Epoch [12/13] - Train Loss: 1.2958\n",
            "Epoch [12/13] - Validation Loss: 1.3414, Accuracy: 15.51%\n",
            "Epoch [13/13] - Train Loss: 1.2760\n",
            "Epoch [13/13] - Validation Loss: 1.3121, Accuracy: 19.79%\n",
            "Epoch [1/18] - Train Loss: 4.3022\n",
            "Epoch [1/18] - Validation Loss: 1.3980, Accuracy: 24.87%\n",
            "Epoch [2/18] - Train Loss: 1.3867\n",
            "Epoch [2/18] - Validation Loss: 1.3631, Accuracy: 12.57%\n",
            "Epoch [3/18] - Train Loss: 1.3647\n",
            "Epoch [3/18] - Validation Loss: 1.3627, Accuracy: 11.76%\n",
            "Epoch [4/18] - Train Loss: 1.3487\n",
            "Epoch [4/18] - Validation Loss: 1.3702, Accuracy: 12.57%\n",
            "Epoch [5/18] - Train Loss: 1.3389\n",
            "Epoch [5/18] - Validation Loss: 1.3470, Accuracy: 15.78%\n",
            "Epoch [6/18] - Train Loss: 1.3249\n",
            "Epoch [6/18] - Validation Loss: 1.3370, Accuracy: 16.04%\n",
            "Epoch [7/18] - Train Loss: 1.3273\n",
            "Epoch [7/18] - Validation Loss: 1.3451, Accuracy: 32.35%\n",
            "Epoch [8/18] - Train Loss: 1.3054\n",
            "Epoch [8/18] - Validation Loss: 1.3510, Accuracy: 17.38%\n",
            "Epoch [9/18] - Train Loss: 1.2969\n",
            "Epoch [9/18] - Validation Loss: 1.3186, Accuracy: 19.25%\n",
            "Epoch [10/18] - Train Loss: 1.3013\n",
            "Epoch [10/18] - Validation Loss: 1.3237, Accuracy: 17.91%\n",
            "Epoch [11/18] - Train Loss: 1.2879\n",
            "Epoch [11/18] - Validation Loss: 1.3312, Accuracy: 18.18%\n",
            "Epoch [12/18] - Train Loss: 1.2884\n",
            "Epoch [12/18] - Validation Loss: 1.3163, Accuracy: 19.25%\n",
            "Epoch [13/18] - Train Loss: 1.2885\n",
            "Epoch [13/18] - Validation Loss: 1.3169, Accuracy: 18.72%\n",
            "Epoch [14/18] - Train Loss: 1.2758\n",
            "Epoch [14/18] - Validation Loss: 1.3182, Accuracy: 18.72%\n",
            "Epoch [15/18] - Train Loss: 1.2856\n",
            "Epoch [15/18] - Validation Loss: 1.3355, Accuracy: 17.11%\n",
            "Epoch [16/18] - Train Loss: 1.2883\n",
            "Epoch [16/18] - Validation Loss: 1.3171, Accuracy: 18.45%\n",
            "Epoch [17/18] - Train Loss: 1.2833\n",
            "Epoch [17/18] - Validation Loss: 1.3308, Accuracy: 16.84%\n",
            "Epoch [18/18] - Train Loss: 1.4093\n",
            "Epoch [18/18] - Validation Loss: 1.3311, Accuracy: 17.65%\n",
            "Epoch [1/13] - Train Loss: 1.4611\n",
            "Epoch [1/13] - Validation Loss: 1.4046, Accuracy: 23.26%\n",
            "Epoch [2/13] - Train Loss: 1.3987\n",
            "Epoch [2/13] - Validation Loss: 1.3808, Accuracy: 14.97%\n",
            "Epoch [3/13] - Train Loss: 1.3579\n",
            "Epoch [3/13] - Validation Loss: 1.3593, Accuracy: 19.79%\n",
            "Epoch [4/13] - Train Loss: 1.3416\n",
            "Epoch [4/13] - Validation Loss: 1.3606, Accuracy: 18.72%\n",
            "Epoch [5/13] - Train Loss: 1.3334\n",
            "Epoch [5/13] - Validation Loss: 1.3363, Accuracy: 25.67%\n",
            "Epoch [6/13] - Train Loss: 1.3197\n",
            "Epoch [6/13] - Validation Loss: 1.3535, Accuracy: 19.25%\n",
            "Epoch [7/13] - Train Loss: 1.3038\n",
            "Epoch [7/13] - Validation Loss: 1.3228, Accuracy: 27.54%\n",
            "Epoch [8/13] - Train Loss: 1.3055\n",
            "Epoch [8/13] - Validation Loss: 1.3076, Accuracy: 26.20%\n",
            "Epoch [9/13] - Train Loss: 1.2980\n",
            "Epoch [9/13] - Validation Loss: 1.3160, Accuracy: 23.80%\n",
            "Epoch [10/13] - Train Loss: 1.2893\n",
            "Epoch [10/13] - Validation Loss: 1.3186, Accuracy: 27.27%\n",
            "Epoch [11/13] - Train Loss: 1.2749\n",
            "Epoch [11/13] - Validation Loss: 1.3311, Accuracy: 28.61%\n",
            "Epoch [12/13] - Train Loss: 1.2711\n",
            "Epoch [12/13] - Validation Loss: 1.3050, Accuracy: 32.62%\n",
            "Epoch [13/13] - Train Loss: 1.2688\n",
            "Epoch [13/13] - Validation Loss: 1.3065, Accuracy: 24.06%\n",
            "Epoch [1/18] - Train Loss: 1.4509\n",
            "Epoch [1/18] - Validation Loss: 1.5043, Accuracy: 11.23%\n",
            "Epoch [2/18] - Train Loss: 1.3975\n",
            "Epoch [2/18] - Validation Loss: 1.3937, Accuracy: 14.97%\n",
            "Epoch [3/18] - Train Loss: 1.3634\n",
            "Epoch [3/18] - Validation Loss: 1.3774, Accuracy: 20.05%\n",
            "Epoch [4/18] - Train Loss: 1.3452\n",
            "Epoch [4/18] - Validation Loss: 1.3561, Accuracy: 20.05%\n",
            "Epoch [5/18] - Train Loss: 1.3359\n",
            "Epoch [5/18] - Validation Loss: 1.3628, Accuracy: 29.14%\n",
            "Epoch [6/18] - Train Loss: 1.3238\n",
            "Epoch [6/18] - Validation Loss: 1.3379, Accuracy: 21.12%\n",
            "Epoch [7/18] - Train Loss: 1.3141\n",
            "Epoch [7/18] - Validation Loss: 1.3249, Accuracy: 29.14%\n",
            "Epoch [8/18] - Train Loss: 1.3041\n",
            "Epoch [8/18] - Validation Loss: 1.3190, Accuracy: 24.60%\n",
            "Epoch [9/18] - Train Loss: 1.2897\n",
            "Epoch [9/18] - Validation Loss: 1.3596, Accuracy: 18.45%\n",
            "Epoch [10/18] - Train Loss: 1.2890\n",
            "Epoch [10/18] - Validation Loss: 1.3211, Accuracy: 25.13%\n",
            "Epoch [11/18] - Train Loss: 1.2843\n",
            "Epoch [11/18] - Validation Loss: 1.3166, Accuracy: 23.53%\n",
            "Epoch [12/18] - Train Loss: 1.2767\n",
            "Epoch [12/18] - Validation Loss: 1.3202, Accuracy: 43.32%\n",
            "Epoch [13/18] - Train Loss: 1.2740\n",
            "Epoch [13/18] - Validation Loss: 1.3511, Accuracy: 21.66%\n",
            "Epoch [14/18] - Train Loss: 1.2657\n",
            "Epoch [14/18] - Validation Loss: 1.3375, Accuracy: 28.61%\n",
            "Epoch [15/18] - Train Loss: 1.2626\n",
            "Epoch [15/18] - Validation Loss: 1.3238, Accuracy: 24.60%\n",
            "Epoch [16/18] - Train Loss: 1.2574\n",
            "Epoch [16/18] - Validation Loss: 1.3133, Accuracy: 28.88%\n",
            "Epoch [17/18] - Train Loss: 1.2613\n",
            "Epoch [17/18] - Validation Loss: 1.3347, Accuracy: 32.89%\n",
            "Epoch [18/18] - Train Loss: 1.2615\n",
            "Epoch [18/18] - Validation Loss: 1.3104, Accuracy: 24.33%\n",
            "Epoch [1/13] - Train Loss: 1.4507\n",
            "Epoch [1/13] - Validation Loss: 1.5259, Accuracy: 23.80%\n",
            "Epoch [2/13] - Train Loss: 1.4054\n",
            "Epoch [2/13] - Validation Loss: 1.3493, Accuracy: 43.58%\n",
            "Epoch [3/13] - Train Loss: 1.3823\n",
            "Epoch [3/13] - Validation Loss: 1.3850, Accuracy: 44.12%\n",
            "Epoch [4/13] - Train Loss: 1.3642\n",
            "Epoch [4/13] - Validation Loss: 1.3498, Accuracy: 26.20%\n",
            "Epoch [5/13] - Train Loss: 1.3476\n",
            "Epoch [5/13] - Validation Loss: 1.3743, Accuracy: 16.84%\n",
            "Epoch [6/13] - Train Loss: 1.3446\n",
            "Epoch [6/13] - Validation Loss: 1.3395, Accuracy: 25.40%\n",
            "Epoch [7/13] - Train Loss: 1.3312\n",
            "Epoch [7/13] - Validation Loss: 1.3558, Accuracy: 43.58%\n",
            "Epoch [8/13] - Train Loss: 1.3242\n",
            "Epoch [8/13] - Validation Loss: 1.3386, Accuracy: 25.94%\n",
            "Epoch [9/13] - Train Loss: 1.3108\n",
            "Epoch [9/13] - Validation Loss: 1.4111, Accuracy: 24.87%\n",
            "Epoch [10/13] - Train Loss: 1.3045\n",
            "Epoch [10/13] - Validation Loss: 1.3248, Accuracy: 27.54%\n",
            "Epoch [11/13] - Train Loss: 1.2997\n",
            "Epoch [11/13] - Validation Loss: 1.3201, Accuracy: 26.74%\n",
            "Epoch [12/13] - Train Loss: 1.2911\n",
            "Epoch [12/13] - Validation Loss: 1.3147, Accuracy: 23.26%\n",
            "Epoch [13/13] - Train Loss: 1.2895\n",
            "Epoch [13/13] - Validation Loss: 1.3196, Accuracy: 23.26%\n",
            "Epoch [1/18] - Train Loss: 1.4418\n",
            "Epoch [1/18] - Validation Loss: 1.3887, Accuracy: 24.06%\n",
            "Epoch [2/18] - Train Loss: 1.4240\n",
            "Epoch [2/18] - Validation Loss: 1.3899, Accuracy: 17.11%\n",
            "Epoch [3/18] - Train Loss: 1.3740\n",
            "Epoch [3/18] - Validation Loss: 1.4685, Accuracy: 23.80%\n",
            "Epoch [4/18] - Train Loss: 1.3686\n",
            "Epoch [4/18] - Validation Loss: 1.3628, Accuracy: 20.86%\n",
            "Epoch [5/18] - Train Loss: 1.3592\n",
            "Epoch [5/18] - Validation Loss: 1.3611, Accuracy: 45.45%\n",
            "Epoch [6/18] - Train Loss: 1.3408\n",
            "Epoch [6/18] - Validation Loss: 1.3783, Accuracy: 23.80%\n",
            "Epoch [7/18] - Train Loss: 1.3289\n",
            "Epoch [7/18] - Validation Loss: 1.3453, Accuracy: 28.88%\n",
            "Epoch [8/18] - Train Loss: 1.3316\n",
            "Epoch [8/18] - Validation Loss: 1.3455, Accuracy: 19.25%\n",
            "Epoch [9/18] - Train Loss: 1.3229\n",
            "Epoch [9/18] - Validation Loss: 1.3223, Accuracy: 29.68%\n",
            "Epoch [10/18] - Train Loss: 1.3044\n",
            "Epoch [10/18] - Validation Loss: 1.3263, Accuracy: 23.80%\n",
            "Epoch [11/18] - Train Loss: 1.3049\n",
            "Epoch [11/18] - Validation Loss: 1.3212, Accuracy: 26.20%\n",
            "Epoch [12/18] - Train Loss: 1.3054\n",
            "Epoch [12/18] - Validation Loss: 1.3318, Accuracy: 21.39%\n",
            "Epoch [13/18] - Train Loss: 1.2926\n",
            "Epoch [13/18] - Validation Loss: 1.3148, Accuracy: 22.99%\n",
            "Epoch [14/18] - Train Loss: 1.2896\n",
            "Epoch [14/18] - Validation Loss: 1.3146, Accuracy: 31.55%\n",
            "Epoch [15/18] - Train Loss: 1.2855\n",
            "Epoch [15/18] - Validation Loss: 1.3101, Accuracy: 23.80%\n",
            "Epoch [16/18] - Train Loss: 1.2803\n",
            "Epoch [16/18] - Validation Loss: 1.3094, Accuracy: 23.53%\n",
            "Epoch [17/18] - Train Loss: 1.2743\n",
            "Epoch [17/18] - Validation Loss: 1.3114, Accuracy: 24.33%\n",
            "Epoch [18/18] - Train Loss: 1.2707\n",
            "Epoch [18/18] - Validation Loss: 1.3151, Accuracy: 23.26%\n",
            "Epoch [1/13] - Train Loss: 11.9341\n",
            "Epoch [1/13] - Validation Loss: 1.3958, Accuracy: 9.89%\n",
            "Epoch [2/13] - Train Loss: 1.3951\n",
            "Epoch [2/13] - Validation Loss: 1.3944, Accuracy: 8.02%\n",
            "Epoch [3/13] - Train Loss: 1.3823\n",
            "Epoch [3/13] - Validation Loss: 1.3951, Accuracy: 8.29%\n",
            "Epoch [4/13] - Train Loss: 1.3786\n",
            "Epoch [4/13] - Validation Loss: 1.3911, Accuracy: 8.02%\n",
            "Epoch [5/13] - Train Loss: 1.3927\n",
            "Epoch [5/13] - Validation Loss: 1.4022, Accuracy: 7.49%\n",
            "Epoch [6/13] - Train Loss: 1.5572\n",
            "Epoch [6/13] - Validation Loss: 1.4239, Accuracy: 25.67%\n",
            "Epoch [7/13] - Train Loss: 1.3890\n",
            "Epoch [7/13] - Validation Loss: 1.3961, Accuracy: 8.02%\n",
            "Epoch [8/13] - Train Loss: 1.3782\n",
            "Epoch [8/13] - Validation Loss: 1.3987, Accuracy: 7.75%\n",
            "Epoch [9/13] - Train Loss: 1.3784\n",
            "Epoch [9/13] - Validation Loss: 1.3963, Accuracy: 22.99%\n",
            "Epoch [10/13] - Train Loss: 1.3798\n",
            "Epoch [10/13] - Validation Loss: 1.3965, Accuracy: 23.26%\n",
            "Epoch [11/13] - Train Loss: 1.3798\n",
            "Epoch [11/13] - Validation Loss: 1.3980, Accuracy: 7.75%\n",
            "Epoch [12/13] - Train Loss: 1.3729\n",
            "Epoch [12/13] - Validation Loss: 1.3979, Accuracy: 7.49%\n",
            "Epoch [13/13] - Train Loss: 1.3765\n",
            "Epoch [13/13] - Validation Loss: 1.3981, Accuracy: 7.49%\n",
            "Epoch [1/18] - Train Loss: 10.3353\n",
            "Epoch [1/18] - Validation Loss: 1.3825, Accuracy: 12.03%\n",
            "Epoch [2/18] - Train Loss: 1.4033\n",
            "Epoch [2/18] - Validation Loss: 1.3686, Accuracy: 13.10%\n",
            "Epoch [3/18] - Train Loss: 1.3670\n",
            "Epoch [3/18] - Validation Loss: 1.3616, Accuracy: 14.17%\n",
            "Epoch [4/18] - Train Loss: 1.3714\n",
            "Epoch [4/18] - Validation Loss: 1.3678, Accuracy: 12.57%\n",
            "Epoch [5/18] - Train Loss: 1.3614\n",
            "Epoch [5/18] - Validation Loss: 1.3618, Accuracy: 14.17%\n",
            "Epoch [6/18] - Train Loss: 1.3597\n",
            "Epoch [6/18] - Validation Loss: 1.3593, Accuracy: 12.57%\n",
            "Epoch [7/18] - Train Loss: 1.3469\n",
            "Epoch [7/18] - Validation Loss: 1.3605, Accuracy: 11.23%\n",
            "Epoch [8/18] - Train Loss: 1.3482\n",
            "Epoch [8/18] - Validation Loss: 1.3506, Accuracy: 13.37%\n",
            "Epoch [9/18] - Train Loss: 1.3574\n",
            "Epoch [9/18] - Validation Loss: 1.3663, Accuracy: 11.76%\n",
            "Epoch [10/18] - Train Loss: 1.3531\n",
            "Epoch [10/18] - Validation Loss: 1.3549, Accuracy: 12.30%\n",
            "Epoch [11/18] - Train Loss: 1.3648\n",
            "Epoch [11/18] - Validation Loss: 1.3546, Accuracy: 13.37%\n",
            "Epoch [12/18] - Train Loss: 1.3494\n",
            "Epoch [12/18] - Validation Loss: 1.3538, Accuracy: 13.37%\n",
            "Epoch [13/18] - Train Loss: 1.3521\n",
            "Epoch [13/18] - Validation Loss: 1.3557, Accuracy: 12.83%\n",
            "Epoch [14/18] - Train Loss: 1.3831\n",
            "Epoch [14/18] - Validation Loss: 1.3493, Accuracy: 13.64%\n",
            "Epoch [15/18] - Train Loss: 1.3349\n",
            "Epoch [15/18] - Validation Loss: 1.3541, Accuracy: 11.23%\n",
            "Epoch [16/18] - Train Loss: 1.3371\n",
            "Epoch [16/18] - Validation Loss: 1.3746, Accuracy: 11.76%\n",
            "Epoch [17/18] - Train Loss: 1.3397\n",
            "Epoch [17/18] - Validation Loss: 1.3571, Accuracy: 10.70%\n",
            "Epoch [18/18] - Train Loss: 1.3438\n",
            "Epoch [18/18] - Validation Loss: 1.3579, Accuracy: 11.76%\n",
            "Epoch [1/13] - Train Loss: 6.6774\n",
            "Epoch [1/13] - Validation Loss: 1.3899, Accuracy: 39.57%\n",
            "Epoch [2/13] - Train Loss: 1.4048\n",
            "Epoch [2/13] - Validation Loss: 1.3752, Accuracy: 22.19%\n",
            "Epoch [3/13] - Train Loss: 1.3838\n",
            "Epoch [3/13] - Validation Loss: 1.3772, Accuracy: 10.96%\n",
            "Epoch [4/13] - Train Loss: 1.3725\n",
            "Epoch [4/13] - Validation Loss: 1.3558, Accuracy: 12.83%\n",
            "Epoch [5/13] - Train Loss: 1.3683\n",
            "Epoch [5/13] - Validation Loss: 1.3759, Accuracy: 10.96%\n",
            "Epoch [6/13] - Train Loss: 1.3731\n",
            "Epoch [6/13] - Validation Loss: 1.3672, Accuracy: 10.96%\n",
            "Epoch [7/13] - Train Loss: 1.3617\n",
            "Epoch [7/13] - Validation Loss: 1.3576, Accuracy: 13.10%\n",
            "Epoch [8/13] - Train Loss: 1.3608\n",
            "Epoch [8/13] - Validation Loss: 1.3618, Accuracy: 12.03%\n",
            "Epoch [9/13] - Train Loss: 1.3617\n",
            "Epoch [9/13] - Validation Loss: 1.3515, Accuracy: 13.37%\n",
            "Epoch [10/13] - Train Loss: 1.3551\n",
            "Epoch [10/13] - Validation Loss: 1.3620, Accuracy: 12.83%\n",
            "Epoch [11/13] - Train Loss: 1.3592\n",
            "Epoch [11/13] - Validation Loss: 1.3539, Accuracy: 13.37%\n",
            "Epoch [12/13] - Train Loss: 1.3723\n",
            "Epoch [12/13] - Validation Loss: 1.3559, Accuracy: 12.57%\n",
            "Epoch [13/13] - Train Loss: 1.3458\n",
            "Epoch [13/13] - Validation Loss: 1.3536, Accuracy: 12.30%\n",
            "Epoch [1/18] - Train Loss: 7.1488\n",
            "Epoch [1/18] - Validation Loss: 1.4020, Accuracy: 39.04%\n",
            "Epoch [2/18] - Train Loss: 1.4055\n",
            "Epoch [2/18] - Validation Loss: 1.3827, Accuracy: 20.86%\n",
            "Epoch [3/18] - Train Loss: 1.3791\n",
            "Epoch [3/18] - Validation Loss: 1.3830, Accuracy: 12.83%\n",
            "Epoch [4/18] - Train Loss: 1.3783\n",
            "Epoch [4/18] - Validation Loss: 1.3795, Accuracy: 21.12%\n",
            "Epoch [5/18] - Train Loss: 1.3580\n",
            "Epoch [5/18] - Validation Loss: 1.3637, Accuracy: 13.10%\n",
            "Epoch [6/18] - Train Loss: 1.3442\n",
            "Epoch [6/18] - Validation Loss: 1.3587, Accuracy: 14.17%\n",
            "Epoch [7/18] - Train Loss: 1.3484\n",
            "Epoch [7/18] - Validation Loss: 1.3573, Accuracy: 11.50%\n",
            "Epoch [8/18] - Train Loss: 1.3475\n",
            "Epoch [8/18] - Validation Loss: 1.3611, Accuracy: 12.57%\n",
            "Epoch [9/18] - Train Loss: 1.3377\n",
            "Epoch [9/18] - Validation Loss: 1.3488, Accuracy: 13.37%\n",
            "Epoch [10/18] - Train Loss: 1.3322\n",
            "Epoch [10/18] - Validation Loss: 1.3437, Accuracy: 14.44%\n",
            "Epoch [11/18] - Train Loss: 1.3421\n",
            "Epoch [11/18] - Validation Loss: 1.3477, Accuracy: 13.10%\n",
            "Epoch [12/18] - Train Loss: 1.3542\n",
            "Epoch [12/18] - Validation Loss: 1.3527, Accuracy: 14.44%\n",
            "Epoch [13/18] - Train Loss: 1.3513\n",
            "Epoch [13/18] - Validation Loss: 1.8931, Accuracy: 22.99%\n",
            "Epoch [14/18] - Train Loss: 1.3899\n",
            "Epoch [14/18] - Validation Loss: 1.3571, Accuracy: 13.10%\n",
            "Epoch [15/18] - Train Loss: 1.3290\n",
            "Epoch [15/18] - Validation Loss: 1.3405, Accuracy: 14.44%\n",
            "Epoch [16/18] - Train Loss: 1.3377\n",
            "Epoch [16/18] - Validation Loss: 1.3521, Accuracy: 13.37%\n",
            "Epoch [17/18] - Train Loss: 1.3333\n",
            "Epoch [17/18] - Validation Loss: 1.3626, Accuracy: 13.64%\n",
            "Epoch [18/18] - Train Loss: 1.3450\n",
            "Epoch [18/18] - Validation Loss: 1.3549, Accuracy: 12.03%\n",
            "Epoch [1/13] - Train Loss: 1.5005\n",
            "Epoch [1/13] - Validation Loss: 1.3977, Accuracy: 24.06%\n",
            "Epoch [2/13] - Train Loss: 1.4233\n",
            "Epoch [2/13] - Validation Loss: 1.3776, Accuracy: 14.44%\n",
            "Epoch [3/13] - Train Loss: 1.3994\n",
            "Epoch [3/13] - Validation Loss: 1.3952, Accuracy: 43.85%\n",
            "Epoch [4/13] - Train Loss: 1.3858\n",
            "Epoch [4/13] - Validation Loss: 1.3870, Accuracy: 16.58%\n",
            "Epoch [5/13] - Train Loss: 1.3612\n",
            "Epoch [5/13] - Validation Loss: 1.3697, Accuracy: 16.58%\n",
            "Epoch [6/13] - Train Loss: 1.3591\n",
            "Epoch [6/13] - Validation Loss: 1.3582, Accuracy: 25.67%\n",
            "Epoch [7/13] - Train Loss: 1.3442\n",
            "Epoch [7/13] - Validation Loss: 1.3561, Accuracy: 19.79%\n",
            "Epoch [8/13] - Train Loss: 1.3400\n",
            "Epoch [8/13] - Validation Loss: 1.3361, Accuracy: 21.12%\n",
            "Epoch [9/13] - Train Loss: 1.3371\n",
            "Epoch [9/13] - Validation Loss: 1.3514, Accuracy: 20.32%\n",
            "Epoch [10/13] - Train Loss: 1.3312\n",
            "Epoch [10/13] - Validation Loss: 1.3418, Accuracy: 21.39%\n",
            "Epoch [11/13] - Train Loss: 1.3230\n",
            "Epoch [11/13] - Validation Loss: 1.3580, Accuracy: 16.31%\n",
            "Epoch [12/13] - Train Loss: 1.3223\n",
            "Epoch [12/13] - Validation Loss: 1.3345, Accuracy: 21.66%\n",
            "Epoch [13/13] - Train Loss: 1.3179\n",
            "Epoch [13/13] - Validation Loss: 1.3332, Accuracy: 27.54%\n",
            "Epoch [1/18] - Train Loss: 1.5096\n",
            "Epoch [1/18] - Validation Loss: 1.5939, Accuracy: 43.05%\n",
            "Epoch [2/18] - Train Loss: 1.4233\n",
            "Epoch [2/18] - Validation Loss: 1.4888, Accuracy: 7.49%\n",
            "Epoch [3/18] - Train Loss: 1.3921\n",
            "Epoch [3/18] - Validation Loss: 1.3619, Accuracy: 18.18%\n",
            "Epoch [4/18] - Train Loss: 1.3758\n",
            "Epoch [4/18] - Validation Loss: 1.3827, Accuracy: 48.13%\n",
            "Epoch [5/18] - Train Loss: 1.3744\n",
            "Epoch [5/18] - Validation Loss: 1.3551, Accuracy: 25.40%\n",
            "Epoch [6/18] - Train Loss: 1.3512\n",
            "Epoch [6/18] - Validation Loss: 1.3601, Accuracy: 18.98%\n",
            "Epoch [7/18] - Train Loss: 1.3448\n",
            "Epoch [7/18] - Validation Loss: 1.4012, Accuracy: 12.57%\n",
            "Epoch [8/18] - Train Loss: 1.3424\n",
            "Epoch [8/18] - Validation Loss: 1.3718, Accuracy: 19.79%\n",
            "Epoch [9/18] - Train Loss: 1.3380\n",
            "Epoch [9/18] - Validation Loss: 1.3557, Accuracy: 18.72%\n",
            "Epoch [10/18] - Train Loss: 1.3294\n",
            "Epoch [10/18] - Validation Loss: 1.3470, Accuracy: 20.32%\n",
            "Epoch [11/18] - Train Loss: 1.3273\n",
            "Epoch [11/18] - Validation Loss: 1.3548, Accuracy: 19.25%\n",
            "Epoch [12/18] - Train Loss: 1.3201\n",
            "Epoch [12/18] - Validation Loss: 1.3510, Accuracy: 18.18%\n",
            "Epoch [13/18] - Train Loss: 1.3169\n",
            "Epoch [13/18] - Validation Loss: 1.3298, Accuracy: 27.27%\n",
            "Epoch [14/18] - Train Loss: 1.3140\n",
            "Epoch [14/18] - Validation Loss: 1.3507, Accuracy: 19.25%\n",
            "Epoch [15/18] - Train Loss: 1.3177\n",
            "Epoch [15/18] - Validation Loss: 1.3437, Accuracy: 21.66%\n",
            "Epoch [16/18] - Train Loss: 1.3052\n",
            "Epoch [16/18] - Validation Loss: 1.3380, Accuracy: 25.94%\n",
            "Epoch [17/18] - Train Loss: 1.3049\n",
            "Epoch [17/18] - Validation Loss: 1.3337, Accuracy: 21.12%\n",
            "Epoch [18/18] - Train Loss: 1.2985\n",
            "Epoch [18/18] - Validation Loss: 1.3423, Accuracy: 20.86%\n",
            "Epoch [1/13] - Train Loss: 1.5010\n",
            "Epoch [1/13] - Validation Loss: 1.5546, Accuracy: 7.75%\n",
            "Epoch [2/13] - Train Loss: 1.4369\n",
            "Epoch [2/13] - Validation Loss: 1.4396, Accuracy: 13.37%\n",
            "Epoch [3/13] - Train Loss: 1.4060\n",
            "Epoch [3/13] - Validation Loss: 1.3999, Accuracy: 12.57%\n",
            "Epoch [4/13] - Train Loss: 1.3880\n",
            "Epoch [4/13] - Validation Loss: 1.3636, Accuracy: 27.54%\n",
            "Epoch [5/13] - Train Loss: 1.3798\n",
            "Epoch [5/13] - Validation Loss: 1.3596, Accuracy: 21.93%\n",
            "Epoch [6/13] - Train Loss: 1.3746\n",
            "Epoch [6/13] - Validation Loss: 1.3844, Accuracy: 16.04%\n",
            "Epoch [7/13] - Train Loss: 1.3627\n",
            "Epoch [7/13] - Validation Loss: 1.3596, Accuracy: 25.40%\n",
            "Epoch [8/13] - Train Loss: 1.3661\n",
            "Epoch [8/13] - Validation Loss: 1.3524, Accuracy: 18.45%\n",
            "Epoch [9/13] - Train Loss: 1.3546\n",
            "Epoch [9/13] - Validation Loss: 1.3410, Accuracy: 24.60%\n",
            "Epoch [10/13] - Train Loss: 1.3510\n",
            "Epoch [10/13] - Validation Loss: 1.3441, Accuracy: 20.32%\n",
            "Epoch [11/13] - Train Loss: 1.3473\n",
            "Epoch [11/13] - Validation Loss: 1.3420, Accuracy: 21.12%\n",
            "Epoch [12/13] - Train Loss: 1.3414\n",
            "Epoch [12/13] - Validation Loss: 1.3531, Accuracy: 18.72%\n",
            "Epoch [13/13] - Train Loss: 1.3332\n",
            "Epoch [13/13] - Validation Loss: 1.3508, Accuracy: 18.72%\n",
            "Epoch [1/18] - Train Loss: 1.5076\n",
            "Epoch [1/18] - Validation Loss: 1.4205, Accuracy: 23.80%\n",
            "Epoch [2/18] - Train Loss: 1.4419\n",
            "Epoch [2/18] - Validation Loss: 1.4195, Accuracy: 8.56%\n",
            "Epoch [3/18] - Train Loss: 1.4069\n",
            "Epoch [3/18] - Validation Loss: 1.3736, Accuracy: 27.81%\n",
            "Epoch [4/18] - Train Loss: 1.3869\n",
            "Epoch [4/18] - Validation Loss: 1.3706, Accuracy: 17.11%\n",
            "Epoch [5/18] - Train Loss: 1.3770\n",
            "Epoch [5/18] - Validation Loss: 1.3731, Accuracy: 24.60%\n",
            "Epoch [6/18] - Train Loss: 1.3690\n",
            "Epoch [6/18] - Validation Loss: 1.3718, Accuracy: 24.33%\n",
            "Epoch [7/18] - Train Loss: 1.3659\n",
            "Epoch [7/18] - Validation Loss: 1.3560, Accuracy: 25.13%\n",
            "Epoch [8/18] - Train Loss: 1.3563\n",
            "Epoch [8/18] - Validation Loss: 1.3525, Accuracy: 19.79%\n",
            "Epoch [9/18] - Train Loss: 1.3468\n",
            "Epoch [9/18] - Validation Loss: 1.3487, Accuracy: 19.25%\n",
            "Epoch [10/18] - Train Loss: 1.3463\n",
            "Epoch [10/18] - Validation Loss: 1.3445, Accuracy: 26.47%\n",
            "Epoch [11/18] - Train Loss: 1.3394\n",
            "Epoch [11/18] - Validation Loss: 1.3426, Accuracy: 25.13%\n",
            "Epoch [12/18] - Train Loss: 1.3320\n",
            "Epoch [12/18] - Validation Loss: 1.3551, Accuracy: 18.45%\n",
            "Epoch [13/18] - Train Loss: 1.3343\n",
            "Epoch [13/18] - Validation Loss: 1.3473, Accuracy: 27.54%\n",
            "Epoch [14/18] - Train Loss: 1.3326\n",
            "Epoch [14/18] - Validation Loss: 1.3498, Accuracy: 25.94%\n",
            "Epoch [15/18] - Train Loss: 1.3179\n",
            "Epoch [15/18] - Validation Loss: 1.3456, Accuracy: 19.25%\n",
            "Epoch [16/18] - Train Loss: 1.3213\n",
            "Epoch [16/18] - Validation Loss: 1.3409, Accuracy: 20.86%\n",
            "Epoch [17/18] - Train Loss: 1.3202\n",
            "Epoch [17/18] - Validation Loss: 1.3398, Accuracy: 21.39%\n",
            "Epoch [18/18] - Train Loss: 1.3215\n",
            "Epoch [18/18] - Validation Loss: 1.3503, Accuracy: 25.94%\n",
            "Epoch [1/13] - Train Loss: 6.3392\n",
            "Epoch [1/13] - Validation Loss: 1.3883, Accuracy: 12.83%\n",
            "Epoch [2/13] - Train Loss: 1.3870\n",
            "Epoch [2/13] - Validation Loss: 1.3857, Accuracy: 12.57%\n",
            "Epoch [3/13] - Train Loss: 1.3809\n",
            "Epoch [3/13] - Validation Loss: 1.3808, Accuracy: 12.03%\n",
            "Epoch [4/13] - Train Loss: 1.3680\n",
            "Epoch [4/13] - Validation Loss: 1.3726, Accuracy: 11.23%\n",
            "Epoch [5/13] - Train Loss: 1.3837\n",
            "Epoch [5/13] - Validation Loss: 1.3577, Accuracy: 11.50%\n",
            "Epoch [6/13] - Train Loss: 1.3650\n",
            "Epoch [6/13] - Validation Loss: 1.3586, Accuracy: 10.70%\n",
            "Epoch [7/13] - Train Loss: 1.3482\n",
            "Epoch [7/13] - Validation Loss: 1.3577, Accuracy: 11.76%\n",
            "Epoch [8/13] - Train Loss: 1.3615\n",
            "Epoch [8/13] - Validation Loss: 1.3546, Accuracy: 11.23%\n",
            "Epoch [9/13] - Train Loss: 1.3547\n",
            "Epoch [9/13] - Validation Loss: 1.3603, Accuracy: 11.50%\n",
            "Epoch [10/13] - Train Loss: 1.3776\n",
            "Epoch [10/13] - Validation Loss: 1.3636, Accuracy: 10.16%\n",
            "Epoch [11/13] - Train Loss: 1.3551\n",
            "Epoch [11/13] - Validation Loss: 1.3547, Accuracy: 11.23%\n",
            "Epoch [12/13] - Train Loss: 1.3417\n",
            "Epoch [12/13] - Validation Loss: 2.1823, Accuracy: 23.53%\n",
            "Epoch [13/13] - Train Loss: 1.4283\n",
            "Epoch [13/13] - Validation Loss: 1.3519, Accuracy: 11.50%\n",
            "Epoch [1/18] - Train Loss: 7.9322\n",
            "Epoch [1/18] - Validation Loss: 1.3772, Accuracy: 26.20%\n",
            "Epoch [2/18] - Train Loss: 1.3831\n",
            "Epoch [2/18] - Validation Loss: 1.3747, Accuracy: 10.96%\n",
            "Epoch [3/18] - Train Loss: 1.3751\n",
            "Epoch [3/18] - Validation Loss: 1.3590, Accuracy: 13.64%\n",
            "Epoch [4/18] - Train Loss: 1.3640\n",
            "Epoch [4/18] - Validation Loss: 1.3680, Accuracy: 11.76%\n",
            "Epoch [5/18] - Train Loss: 1.3557\n",
            "Epoch [5/18] - Validation Loss: 1.3527, Accuracy: 13.64%\n",
            "Epoch [6/18] - Train Loss: 1.3719\n",
            "Epoch [6/18] - Validation Loss: 1.3688, Accuracy: 13.37%\n",
            "Epoch [7/18] - Train Loss: 1.3639\n",
            "Epoch [7/18] - Validation Loss: 1.3526, Accuracy: 12.03%\n",
            "Epoch [8/18] - Train Loss: 1.3602\n",
            "Epoch [8/18] - Validation Loss: 1.3627, Accuracy: 11.76%\n",
            "Epoch [9/18] - Train Loss: 1.3454\n",
            "Epoch [9/18] - Validation Loss: 1.3529, Accuracy: 10.96%\n",
            "Epoch [10/18] - Train Loss: 1.3724\n",
            "Epoch [10/18] - Validation Loss: 1.3442, Accuracy: 12.83%\n",
            "Epoch [11/18] - Train Loss: 1.3429\n",
            "Epoch [11/18] - Validation Loss: 1.3588, Accuracy: 12.30%\n",
            "Epoch [12/18] - Train Loss: 1.3412\n",
            "Epoch [12/18] - Validation Loss: 1.3566, Accuracy: 11.50%\n",
            "Epoch [13/18] - Train Loss: 1.3424\n",
            "Epoch [13/18] - Validation Loss: 1.3559, Accuracy: 11.23%\n",
            "Epoch [14/18] - Train Loss: 1.3330\n",
            "Epoch [14/18] - Validation Loss: 1.3526, Accuracy: 11.76%\n",
            "Epoch [15/18] - Train Loss: 1.3374\n",
            "Epoch [15/18] - Validation Loss: 1.3430, Accuracy: 13.10%\n",
            "Epoch [16/18] - Train Loss: 1.3396\n",
            "Epoch [16/18] - Validation Loss: 1.3533, Accuracy: 11.76%\n",
            "Epoch [17/18] - Train Loss: 1.3366\n",
            "Epoch [17/18] - Validation Loss: 1.3525, Accuracy: 11.76%\n",
            "Epoch [18/18] - Train Loss: 1.3434\n",
            "Epoch [18/18] - Validation Loss: 1.3485, Accuracy: 11.76%\n",
            "Epoch [1/13] - Train Loss: 6.5817\n",
            "Epoch [1/13] - Validation Loss: 1.3958, Accuracy: 24.60%\n",
            "Epoch [2/13] - Train Loss: 1.3859\n",
            "Epoch [2/13] - Validation Loss: 1.4622, Accuracy: 18.98%\n",
            "Epoch [3/13] - Train Loss: 1.3961\n",
            "Epoch [3/13] - Validation Loss: 1.3708, Accuracy: 23.80%\n",
            "Epoch [4/13] - Train Loss: 1.3808\n",
            "Epoch [4/13] - Validation Loss: 1.3641, Accuracy: 13.64%\n",
            "Epoch [5/13] - Train Loss: 1.3718\n",
            "Epoch [5/13] - Validation Loss: 1.3668, Accuracy: 13.64%\n",
            "Epoch [6/13] - Train Loss: 1.3602\n",
            "Epoch [6/13] - Validation Loss: 1.3579, Accuracy: 12.30%\n",
            "Epoch [7/13] - Train Loss: 1.3633\n",
            "Epoch [7/13] - Validation Loss: 1.3636, Accuracy: 13.64%\n",
            "Epoch [8/13] - Train Loss: 1.3593\n",
            "Epoch [8/13] - Validation Loss: 1.3581, Accuracy: 14.44%\n",
            "Epoch [9/13] - Train Loss: 1.3477\n",
            "Epoch [9/13] - Validation Loss: 1.3631, Accuracy: 13.90%\n",
            "Epoch [10/13] - Train Loss: 1.3633\n",
            "Epoch [10/13] - Validation Loss: 1.3482, Accuracy: 15.24%\n",
            "Epoch [11/13] - Train Loss: 1.3542\n",
            "Epoch [11/13] - Validation Loss: 1.3477, Accuracy: 14.17%\n",
            "Epoch [12/13] - Train Loss: 1.3525\n",
            "Epoch [12/13] - Validation Loss: 1.3382, Accuracy: 14.97%\n",
            "Epoch [13/13] - Train Loss: 1.3467\n",
            "Epoch [13/13] - Validation Loss: 1.3490, Accuracy: 39.04%\n",
            "Epoch [1/18] - Train Loss: 4.1509\n",
            "Epoch [1/18] - Validation Loss: 1.3628, Accuracy: 15.51%\n",
            "Epoch [2/18] - Train Loss: 1.4002\n",
            "Epoch [2/18] - Validation Loss: 1.3688, Accuracy: 22.46%\n",
            "Epoch [3/18] - Train Loss: 1.3805\n",
            "Epoch [3/18] - Validation Loss: 1.3711, Accuracy: 13.64%\n",
            "Epoch [4/18] - Train Loss: 1.3863\n",
            "Epoch [4/18] - Validation Loss: 1.3828, Accuracy: 13.90%\n",
            "Epoch [5/18] - Train Loss: 1.3748\n",
            "Epoch [5/18] - Validation Loss: 1.3610, Accuracy: 12.30%\n",
            "Epoch [6/18] - Train Loss: 1.3704\n",
            "Epoch [6/18] - Validation Loss: 1.3690, Accuracy: 10.70%\n",
            "Epoch [7/18] - Train Loss: 1.3623\n",
            "Epoch [7/18] - Validation Loss: 1.3555, Accuracy: 13.37%\n",
            "Epoch [8/18] - Train Loss: 1.3760\n",
            "Epoch [8/18] - Validation Loss: 1.3828, Accuracy: 11.76%\n",
            "Epoch [9/18] - Train Loss: 1.3605\n",
            "Epoch [9/18] - Validation Loss: 1.3836, Accuracy: 13.90%\n",
            "Epoch [10/18] - Train Loss: 1.3592\n",
            "Epoch [10/18] - Validation Loss: 1.3561, Accuracy: 11.50%\n",
            "Epoch [11/18] - Train Loss: 1.3545\n",
            "Epoch [11/18] - Validation Loss: 1.3529, Accuracy: 12.30%\n",
            "Epoch [12/18] - Train Loss: 1.3627\n",
            "Epoch [12/18] - Validation Loss: 1.3641, Accuracy: 12.83%\n",
            "Epoch [13/18] - Train Loss: 1.3692\n",
            "Epoch [13/18] - Validation Loss: 1.3708, Accuracy: 10.43%\n",
            "Epoch [14/18] - Train Loss: 1.3608\n",
            "Epoch [14/18] - Validation Loss: 1.3599, Accuracy: 10.70%\n",
            "Epoch [15/18] - Train Loss: 1.3627\n",
            "Epoch [15/18] - Validation Loss: 1.3589, Accuracy: 11.50%\n",
            "Epoch [16/18] - Train Loss: 1.3593\n",
            "Epoch [16/18] - Validation Loss: 1.3581, Accuracy: 11.50%\n",
            "Epoch [17/18] - Train Loss: 1.3622\n",
            "Epoch [17/18] - Validation Loss: 1.3640, Accuracy: 10.96%\n",
            "Epoch [18/18] - Train Loss: 1.3503\n",
            "Epoch [18/18] - Validation Loss: 1.3599, Accuracy: 12.03%\n",
            "Epoch [1/13] - Train Loss: 1.4994\n",
            "Epoch [1/13] - Validation Loss: 1.3885, Accuracy: 18.98%\n",
            "Epoch [2/13] - Train Loss: 1.4001\n",
            "Epoch [2/13] - Validation Loss: 1.3806, Accuracy: 15.51%\n",
            "Epoch [3/13] - Train Loss: 1.3739\n",
            "Epoch [3/13] - Validation Loss: 1.3684, Accuracy: 14.44%\n",
            "Epoch [4/13] - Train Loss: 1.3571\n",
            "Epoch [4/13] - Validation Loss: 1.3599, Accuracy: 16.84%\n",
            "Epoch [5/13] - Train Loss: 1.3489\n",
            "Epoch [5/13] - Validation Loss: 1.3683, Accuracy: 17.65%\n",
            "Epoch [6/13] - Train Loss: 1.3337\n",
            "Epoch [6/13] - Validation Loss: 1.3418, Accuracy: 20.05%\n",
            "Epoch [7/13] - Train Loss: 1.3271\n",
            "Epoch [7/13] - Validation Loss: 1.3376, Accuracy: 25.13%\n",
            "Epoch [8/13] - Train Loss: 1.3229\n",
            "Epoch [8/13] - Validation Loss: 1.3573, Accuracy: 15.24%\n",
            "Epoch [9/13] - Train Loss: 1.3091\n",
            "Epoch [9/13] - Validation Loss: 1.3627, Accuracy: 15.78%\n",
            "Epoch [10/13] - Train Loss: 1.3045\n",
            "Epoch [10/13] - Validation Loss: 1.3311, Accuracy: 18.98%\n",
            "Epoch [11/13] - Train Loss: 1.3037\n",
            "Epoch [11/13] - Validation Loss: 1.3384, Accuracy: 21.39%\n",
            "Epoch [12/13] - Train Loss: 1.2969\n",
            "Epoch [12/13] - Validation Loss: 1.3197, Accuracy: 21.93%\n",
            "Epoch [13/13] - Train Loss: 1.2960\n",
            "Epoch [13/13] - Validation Loss: 1.3270, Accuracy: 21.93%\n",
            "Epoch [1/18] - Train Loss: 1.4927\n",
            "Epoch [1/18] - Validation Loss: 1.3872, Accuracy: 13.90%\n",
            "Epoch [2/18] - Train Loss: 1.4029\n",
            "Epoch [2/18] - Validation Loss: 1.4029, Accuracy: 9.36%\n",
            "Epoch [3/18] - Train Loss: 1.3741\n",
            "Epoch [3/18] - Validation Loss: 1.3805, Accuracy: 17.38%\n",
            "Epoch [4/18] - Train Loss: 1.3603\n",
            "Epoch [4/18] - Validation Loss: 1.3624, Accuracy: 47.86%\n",
            "Epoch [5/18] - Train Loss: 1.3559\n",
            "Epoch [5/18] - Validation Loss: 1.3485, Accuracy: 26.47%\n",
            "Epoch [6/18] - Train Loss: 1.3410\n",
            "Epoch [6/18] - Validation Loss: 1.3517, Accuracy: 24.60%\n",
            "Epoch [7/18] - Train Loss: 1.3272\n",
            "Epoch [7/18] - Validation Loss: 1.3358, Accuracy: 19.79%\n",
            "Epoch [8/18] - Train Loss: 1.3265\n",
            "Epoch [8/18] - Validation Loss: 1.3457, Accuracy: 19.52%\n",
            "Epoch [9/18] - Train Loss: 1.3178\n",
            "Epoch [9/18] - Validation Loss: 1.3286, Accuracy: 24.60%\n",
            "Epoch [10/18] - Train Loss: 1.3159\n",
            "Epoch [10/18] - Validation Loss: 1.3361, Accuracy: 26.74%\n",
            "Epoch [11/18] - Train Loss: 1.3084\n",
            "Epoch [11/18] - Validation Loss: 1.3384, Accuracy: 26.74%\n",
            "Epoch [12/18] - Train Loss: 1.2972\n",
            "Epoch [12/18] - Validation Loss: 1.3225, Accuracy: 21.66%\n",
            "Epoch [13/18] - Train Loss: 1.2972\n",
            "Epoch [13/18] - Validation Loss: 1.3273, Accuracy: 19.52%\n",
            "Epoch [14/18] - Train Loss: 1.2924\n",
            "Epoch [14/18] - Validation Loss: 1.3456, Accuracy: 19.79%\n",
            "Epoch [15/18] - Train Loss: 1.2889\n",
            "Epoch [15/18] - Validation Loss: 1.3298, Accuracy: 18.98%\n",
            "Epoch [16/18] - Train Loss: 1.2875\n",
            "Epoch [16/18] - Validation Loss: 1.3294, Accuracy: 18.45%\n",
            "Epoch [17/18] - Train Loss: 1.2857\n",
            "Epoch [17/18] - Validation Loss: 1.3179, Accuracy: 29.68%\n",
            "Epoch [18/18] - Train Loss: 1.2786\n",
            "Epoch [18/18] - Validation Loss: 1.3079, Accuracy: 21.39%\n",
            "Epoch [1/13] - Train Loss: 1.4659\n",
            "Epoch [1/13] - Validation Loss: 1.3685, Accuracy: 21.66%\n",
            "Epoch [2/13] - Train Loss: 1.4316\n",
            "Epoch [2/13] - Validation Loss: 1.3704, Accuracy: 23.26%\n",
            "Epoch [3/13] - Train Loss: 1.3930\n",
            "Epoch [3/13] - Validation Loss: 1.4004, Accuracy: 10.16%\n",
            "Epoch [4/13] - Train Loss: 1.3660\n",
            "Epoch [4/13] - Validation Loss: 1.3827, Accuracy: 45.99%\n",
            "Epoch [5/13] - Train Loss: 1.3641\n",
            "Epoch [5/13] - Validation Loss: 1.3557, Accuracy: 20.05%\n",
            "Epoch [6/13] - Train Loss: 1.3513\n",
            "Epoch [6/13] - Validation Loss: 1.3612, Accuracy: 24.60%\n",
            "Epoch [7/13] - Train Loss: 1.3444\n",
            "Epoch [7/13] - Validation Loss: 1.3526, Accuracy: 17.11%\n",
            "Epoch [8/13] - Train Loss: 1.3339\n",
            "Epoch [8/13] - Validation Loss: 1.3498, Accuracy: 19.79%\n",
            "Epoch [9/13] - Train Loss: 1.3249\n",
            "Epoch [9/13] - Validation Loss: 1.3522, Accuracy: 20.32%\n",
            "Epoch [10/13] - Train Loss: 1.3245\n",
            "Epoch [10/13] - Validation Loss: 1.3407, Accuracy: 19.52%\n",
            "Epoch [11/13] - Train Loss: 1.3166\n",
            "Epoch [11/13] - Validation Loss: 1.3393, Accuracy: 18.72%\n",
            "Epoch [12/13] - Train Loss: 1.3156\n",
            "Epoch [12/13] - Validation Loss: 1.3312, Accuracy: 20.59%\n",
            "Epoch [13/13] - Train Loss: 1.3104\n",
            "Epoch [13/13] - Validation Loss: 1.3271, Accuracy: 22.73%\n",
            "Epoch [1/18] - Train Loss: 1.4963\n",
            "Epoch [1/18] - Validation Loss: 1.4131, Accuracy: 9.09%\n",
            "Epoch [2/18] - Train Loss: 1.4265\n",
            "Epoch [2/18] - Validation Loss: 1.3577, Accuracy: 22.73%\n",
            "Epoch [3/18] - Train Loss: 1.3835\n",
            "Epoch [3/18] - Validation Loss: 1.3558, Accuracy: 19.25%\n",
            "Epoch [4/18] - Train Loss: 1.3734\n",
            "Epoch [4/18] - Validation Loss: 1.3688, Accuracy: 24.33%\n",
            "Epoch [5/18] - Train Loss: 1.3571\n",
            "Epoch [5/18] - Validation Loss: 1.3489, Accuracy: 18.72%\n",
            "Epoch [6/18] - Train Loss: 1.3581\n",
            "Epoch [6/18] - Validation Loss: 1.3613, Accuracy: 18.98%\n",
            "Epoch [7/18] - Train Loss: 1.3452\n",
            "Epoch [7/18] - Validation Loss: 1.3480, Accuracy: 24.33%\n",
            "Epoch [8/18] - Train Loss: 1.3311\n",
            "Epoch [8/18] - Validation Loss: 1.3572, Accuracy: 21.66%\n",
            "Epoch [9/18] - Train Loss: 1.3278\n",
            "Epoch [9/18] - Validation Loss: 1.3525, Accuracy: 17.11%\n",
            "Epoch [10/18] - Train Loss: 1.3260\n",
            "Epoch [10/18] - Validation Loss: 1.3454, Accuracy: 19.25%\n",
            "Epoch [11/18] - Train Loss: 1.3230\n",
            "Epoch [11/18] - Validation Loss: 1.3305, Accuracy: 21.39%\n",
            "Epoch [12/18] - Train Loss: 1.3170\n",
            "Epoch [12/18] - Validation Loss: 1.3360, Accuracy: 21.12%\n",
            "Epoch [13/18] - Train Loss: 1.3053\n",
            "Epoch [13/18] - Validation Loss: 1.3379, Accuracy: 20.59%\n",
            "Epoch [14/18] - Train Loss: 1.3078\n",
            "Epoch [14/18] - Validation Loss: 1.3325, Accuracy: 20.59%\n",
            "Epoch [15/18] - Train Loss: 1.3040\n",
            "Epoch [15/18] - Validation Loss: 1.3353, Accuracy: 26.20%\n",
            "Epoch [16/18] - Train Loss: 1.3031\n",
            "Epoch [16/18] - Validation Loss: 1.3345, Accuracy: 42.78%\n",
            "Epoch [17/18] - Train Loss: 1.2958\n",
            "Epoch [17/18] - Validation Loss: 1.3287, Accuracy: 26.74%\n",
            "Epoch [18/18] - Train Loss: 1.2889\n",
            "Epoch [18/18] - Validation Loss: 1.3293, Accuracy: 21.12%\n",
            "Best Hyperparameters:\n",
            "Learning Rate: 0.01\n",
            "Dropout Rate: 0.7\n",
            "Batch Size: 64\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Embedding Dimensions: 300\n",
            "Epochs: 12\n",
            "Best Accuracy: 0.39037433155080214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the best hyperparameters obtained from the iteration above, substitute the hyperparameters for the best model\n",
        "model = SentimentCNN(\n",
        "                     vocab_size=len(word_to_ix),\n",
        "                     embedding_dim= 500,\n",
        "                     filter_sizes=[4, 4, 4],\n",
        "                     num_filters= [150, 150, 150],\n",
        "                     output_dim=4,\n",
        "                     dropout=0.2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor([1.0, 2.0, 2.0, 6.0]))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "172cL-Lt001m"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader for sets\n",
        "batch_size = 128\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "B-wc9avSNvTN"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training and validation loops for the best model\n",
        "\n",
        "\n",
        "num_epochs = 15\n",
        "torch.manual_seed(0)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Calculate and print the average loss for this epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictionsval = []\n",
        "    labelsval = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs, labels = batch\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            predictionsval.extend(predicted.tolist())\n",
        "            labelsval.extend(labels.tolist())\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] - Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iEY_VonQOo5",
        "outputId": "16028073-4a06-4687-d88e-63f3ee448030"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15] - Train Loss: 2.1721\n",
            "Epoch [1/15] - Validation Loss: 1.6184, Accuracy: 42.25%\n",
            "Epoch [2/15] - Train Loss: 1.4729\n",
            "Epoch [2/15] - Validation Loss: 1.3681, Accuracy: 44.92%\n",
            "Epoch [3/15] - Train Loss: 1.4112\n",
            "Epoch [3/15] - Validation Loss: 1.4107, Accuracy: 15.24%\n",
            "Epoch [4/15] - Train Loss: 1.3167\n",
            "Epoch [4/15] - Validation Loss: 1.3421, Accuracy: 27.81%\n",
            "Epoch [5/15] - Train Loss: 1.3082\n",
            "Epoch [5/15] - Validation Loss: 1.3403, Accuracy: 20.05%\n",
            "Epoch [6/15] - Train Loss: 1.2928\n",
            "Epoch [6/15] - Validation Loss: 1.3520, Accuracy: 21.66%\n",
            "Epoch [7/15] - Train Loss: 1.2738\n",
            "Epoch [7/15] - Validation Loss: 1.3150, Accuracy: 24.06%\n",
            "Epoch [8/15] - Train Loss: 1.2649\n",
            "Epoch [8/15] - Validation Loss: 1.2860, Accuracy: 27.81%\n",
            "Epoch [9/15] - Train Loss: 1.2509\n",
            "Epoch [9/15] - Validation Loss: 1.3114, Accuracy: 26.20%\n",
            "Epoch [10/15] - Train Loss: 1.2466\n",
            "Epoch [10/15] - Validation Loss: 1.2974, Accuracy: 28.34%\n",
            "Epoch [11/15] - Train Loss: 1.2386\n",
            "Epoch [11/15] - Validation Loss: 1.2883, Accuracy: 27.81%\n",
            "Epoch [12/15] - Train Loss: 1.2346\n",
            "Epoch [12/15] - Validation Loss: 1.3052, Accuracy: 27.27%\n",
            "Epoch [13/15] - Train Loss: 1.2220\n",
            "Epoch [13/15] - Validation Loss: 1.3004, Accuracy: 47.33%\n",
            "Epoch [14/15] - Train Loss: 1.2257\n",
            "Epoch [14/15] - Validation Loss: 1.3084, Accuracy: 28.34%\n",
            "Epoch [15/15] - Train Loss: 1.2160\n",
            "Epoch [15/15] - Validation Loss: 1.2995, Accuracy: 47.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct, \"/\", total)\n",
        "\n",
        "#however I did not like the results I received wth the obtained parameters, so I decided to test individually:\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mITPpw40wMYG",
        "outputId": "a4ef79f9-4b1e-47ff-f060-b55d943e7533"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176 / 374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate accuracy and F1-macro scores for validation set\n",
        "accuracy = accuracy_score(labelsval, predictionsval)\n",
        "f1_macro = f1_score(labelsval, predictionsval, average='macro')\n",
        "\n",
        "# Create a classification report for detailed metrics\n",
        "report = classification_report(labelsval, predictionsval, target_names=['Anger', 'Sadness', 'Joy', 'Optimism'], output_dict=True)\n",
        "\n",
        "# Create a table to display the results\n",
        "results = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'F1-Macro'],\n",
        "    'Value': [accuracy, f1_macro]\n",
        "})\n",
        "\n",
        "# Display the table\n",
        "print(results)\n",
        "\n",
        "# Display the detailed classification report\n",
        "print(pd.DataFrame(report).transpose())"
      ],
      "metadata": {
        "id": "pwcBAHGjvhqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f0f093-6dc8-4aea-c489-2a7c98c880e6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Metric     Value\n",
            "0  Accuracy  0.470588\n",
            "1  F1-Macro  0.317433\n",
            "              precision    recall  f1-score     support\n",
            "Anger          0.482517  0.862500  0.618834  160.000000\n",
            "Sadness        0.527778  0.213483  0.304000   89.000000\n",
            "Joy            0.531250  0.175258  0.263566   97.000000\n",
            "Optimism       0.100000  0.071429  0.083333   28.000000\n",
            "accuracy       0.470588  0.470588  0.470588    0.470588\n",
            "macro avg      0.410386  0.330667  0.317433  374.000000\n",
            "weighted avg   0.477289  0.470588  0.411681  374.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(model.state_dict(), 'sentiment_cnn_model.pth')\n"
      ],
      "metadata": {
        "id": "JFlYSMRSRTkV"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('sentiment_cnn_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Initialize lists to store predictions and true labels\n",
        "all_predictions = []\n",
        "all_true_labels = []\n",
        "\n",
        "# Iterate through the test data\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_predictions.extend(predicted.tolist())\n",
        "        all_true_labels.extend(labels.tolist())\n",
        "\n",
        "# Convert the predictions and true labels to numpy arrays\n",
        "predictions = np.array(all_predictions)\n",
        "true_labels = np.array(all_true_labels)"
      ],
      "metadata": {
        "id": "UbVQ_cNaBK7p"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# Calculate accuracy and F1-macro scores for test set\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "f1_macro = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "# Create a classification report for detailed metrics\n",
        "report = classification_report(true_labels, predictions, target_names=['Anger', 'Sadness', 'Joy', 'Optimism'], output_dict=True)\n",
        "\n",
        "# Create a table to display the results\n",
        "results = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'F1-Macro'],\n",
        "    'Value': [accuracy, f1_macro]\n",
        "})\n",
        "\n",
        "# Display the table\n",
        "print(results)\n",
        "\n",
        "# Display the detailed classification report\n",
        "print(pd.DataFrame(report).transpose())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnTjem8WCBk0",
        "outputId": "0eb348ca-0df9-453e-b8db-a7fff3278247"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Metric     Value\n",
            "0  Accuracy  0.446868\n",
            "1  F1-Macro  0.323163\n",
            "              precision    recall  f1-score      support\n",
            "Anger          0.443487  0.829749  0.578027   558.000000\n",
            "Sadness        0.618421  0.246073  0.352060   382.000000\n",
            "Joy            0.460000  0.192737  0.271654   358.000000\n",
            "Optimism       0.120000  0.073171  0.090909   123.000000\n",
            "accuracy       0.446868  0.446868  0.446868     0.446868\n",
            "macro avg      0.410477  0.335433  0.323163  1421.000000\n",
            "weighted avg   0.466673  0.446868  0.397931  1421.000000\n"
          ]
        }
      ]
    }
  ]
}